{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26283b4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T04:00:50.706974Z",
     "iopub.status.busy": "2023-02-15T04:00:50.706504Z",
     "iopub.status.idle": "2023-02-15T04:01:00.312378Z",
     "shell.execute_reply": "2023-02-15T04:01:00.311396Z"
    },
    "papermill": {
     "duration": 9.614573,
     "end_time": "2023-02-15T04:01:00.315196",
     "exception": false,
     "start_time": "2023-02-15T04:00:50.700623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from glob import glob\n",
    "import os, shutil\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import copy\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "from IPython import display as ipd\n",
    "import math\n",
    "# visualization\n",
    "import cv2\n",
    "from glob import glob\n",
    "# Sklearn\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix, roc_curve\n",
    "import timm\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from collections import defaultdict\n",
    "# import matplotlib.pyplot as plt\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "import albumentations\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f2fc72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T04:01:00.323377Z",
     "iopub.status.busy": "2023-02-15T04:01:00.323070Z",
     "iopub.status.idle": "2023-02-15T04:01:00.392680Z",
     "shell.execute_reply": "2023-02-15T04:01:00.391701Z"
    },
    "papermill": {
     "duration": 0.077387,
     "end_time": "2023-02-15T04:01:00.396249",
     "exception": false,
     "start_time": "2023-02-15T04:01:00.318862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    seed = 1\n",
    "    model_name = \"tf_efficientnetv2_b2\"\n",
    "    train_bs = 16\n",
    "    valid_bs = train_bs*4\n",
    "    image_size = 1024\n",
    "    epochs = 25\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(CFG.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3db9a287",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T04:01:00.408423Z",
     "iopub.status.busy": "2023-02-15T04:01:00.406895Z",
     "iopub.status.idle": "2023-02-15T04:01:00.569643Z",
     "shell.execute_reply": "2023-02-15T04:01:00.568655Z"
    },
    "papermill": {
     "duration": 0.170662,
     "end_time": "2023-02-15T04:01:00.571876",
     "exception": false,
     "start_time": "2023-02-15T04:01:00.401214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>laterality</th>\n",
       "      <th>view</th>\n",
       "      <th>age</th>\n",
       "      <th>cancer</th>\n",
       "      <th>biopsy</th>\n",
       "      <th>invasive</th>\n",
       "      <th>BIRADS</th>\n",
       "      <th>implant</th>\n",
       "      <th>density</th>\n",
       "      <th>machine_id</th>\n",
       "      <th>difficult_negative_case</th>\n",
       "      <th>split</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>10006</td>\n",
       "      <td>462822612</td>\n",
       "      <td>L</td>\n",
       "      <td>CC</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>10006_L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10006</td>\n",
       "      <td>1459541791</td>\n",
       "      <td>L</td>\n",
       "      <td>MLO</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>10006_L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10006</td>\n",
       "      <td>1864590858</td>\n",
       "      <td>R</td>\n",
       "      <td>MLO</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>10006_R</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>10006</td>\n",
       "      <td>1874946579</td>\n",
       "      <td>R</td>\n",
       "      <td>CC</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>10006_R</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>10011</td>\n",
       "      <td>220375232</td>\n",
       "      <td>L</td>\n",
       "      <td>CC</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>10011_L</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_id  patient_id    image_id laterality view   age  cancer  biopsy  \\\n",
       "0        2       10006   462822612          L   CC  61.0       0       0   \n",
       "1        2       10006  1459541791          L  MLO  61.0       0       0   \n",
       "2        2       10006  1864590858          R  MLO  61.0       0       0   \n",
       "3        2       10006  1874946579          R   CC  61.0       0       0   \n",
       "4        2       10011   220375232          L   CC  55.0       0       0   \n",
       "\n",
       "   invasive  BIRADS  implant density  machine_id  difficult_negative_case  \\\n",
       "0         0     NaN        0     NaN          29                    False   \n",
       "1         0     NaN        0     NaN          29                    False   \n",
       "2         0     NaN        0     NaN          29                    False   \n",
       "3         0     NaN        0     NaN          29                    False   \n",
       "4         0     0.0        0     NaN          21                     True   \n",
       "\n",
       "     split  fold  \n",
       "0  10006_L     0  \n",
       "1  10006_L     0  \n",
       "2  10006_R     2  \n",
       "3  10006_R     2  \n",
       "4  10011_L     5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/10folds/train_10folds.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4da2d5d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T04:01:00.580786Z",
     "iopub.status.busy": "2023-02-15T04:01:00.580161Z",
     "iopub.status.idle": "2023-02-15T04:01:00.589126Z",
     "shell.execute_reply": "2023-02-15T04:01:00.587873Z"
    },
    "papermill": {
     "duration": 0.015645,
     "end_time": "2023-02-15T04:01:00.591231",
     "exception": false,
     "start_time": "2023-02-15T04:01:00.575586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Date :02/15/2023, 04:01:00\n"
     ]
    }
   ],
   "source": [
    "def init_logger(log_file='train1.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "now = datetime.now()\n",
    "datetime_now = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "LOGGER.info(f\"Date :{datetime_now}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd4524e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T04:01:00.599638Z",
     "iopub.status.busy": "2023-02-15T04:01:00.599388Z",
     "iopub.status.idle": "2023-02-15T04:01:00.616882Z",
     "shell.execute_reply": "2023-02-15T04:01:00.615917Z"
    },
    "papermill": {
     "duration": 0.024072,
     "end_time": "2023-02-15T04:01:00.618913",
     "exception": false,
     "start_time": "2023-02-15T04:01:00.594841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train transformCompose([\n",
      "  VerticalFlip(always_apply=False, p=0.5),\n",
      "  ColorJitter(always_apply=False, p=0.5, brightness=[0.8, 1.2], contrast=[0.8, 1.2], saturation=[0.8, 1.2], hue=[-0.2, 0.2]),\n",
      "  ShiftScaleRotate(always_apply=False, p=0.5, shift_limit_x=(-0.0625, 0.0625), shift_limit_y=(-0.0625, 0.0625), scale_limit=(-0.050000000000000044, 0.050000000000000044), rotate_limit=(-10, 10), interpolation=1, border_mode=4, value=None, mask_value=None, rotate_method='largest_box'),\n",
      "  HorizontalFlip(always_apply=False, p=0.5),\n",
      "  Cutout(always_apply=False, p=0.5, num_holes=5, max_h_size=102, max_w_size=102),\n",
      "  ToTensorV2(always_apply=True, p=1.0, transpose_mask=False),\n",
      "], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={})\n"
     ]
    }
   ],
   "source": [
    "from albumentations import DualTransform\n",
    "image_size = 1024\n",
    "def isotropically_resize_image(img, size, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC):\n",
    "    h, w = img.shape[:2]\n",
    "    if max(w, h) == size:\n",
    "        return img\n",
    "    if w > h:\n",
    "        scale = size / w\n",
    "        h = h * scale\n",
    "        w = size\n",
    "    else:\n",
    "        scale = size / h\n",
    "        w = w * scale\n",
    "        h = size\n",
    "    interpolation = interpolation_up if scale > 1 else interpolation_down\n",
    "    resized = cv2.resize(img, (int(w), int(h)), interpolation=interpolation)\n",
    "    return resized\n",
    "\n",
    "\n",
    "class IsotropicResize(DualTransform):\n",
    "    def __init__(self, max_side, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC,\n",
    "                 always_apply=False, p=1):\n",
    "        super(IsotropicResize, self).__init__(always_apply, p)\n",
    "        self.max_side = max_side\n",
    "        self.interpolation_down = interpolation_down\n",
    "        self.interpolation_up = interpolation_up\n",
    "\n",
    "    def apply(self, img, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC, **params):\n",
    "        return isotropically_resize_image(img, size=self.max_side, interpolation_down=interpolation_down,\n",
    "                                          interpolation_up=interpolation_up)\n",
    "\n",
    "    def apply_to_mask(self, img, **params):\n",
    "        return self.apply(img, interpolation_down=cv2.INTER_NEAREST, interpolation_up=cv2.INTER_NEAREST, **params)\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return (\"max_side\", \"interpolation_down\", \"interpolation_up\")\n",
    "    \n",
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        # A.Resize(image_size, image_size),\n",
    "        # IsotropicResize(max_side = image_size),\n",
    "        # A.PadIfNeeded(min_height=image_size, min_width=image_size, border_mode=cv2.BORDER_CONSTANT),\n",
    "        # A.RandomBrightnessContrast(),\n",
    "        A.VerticalFlip(p=0.5),   \n",
    "        A.ColorJitter(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Cutout(max_h_size=int(image_size*0.1), max_w_size=int(image_size*0.1), num_holes=5, p=0.5), \n",
    "        # A.OneOf([\n",
    "        #         A.OpticalDistortion(),\n",
    "        #         A.IAAPiecewiseAffine(),\n",
    "        #     ], p=0.1),\n",
    "        # A.OneOf([\n",
    "        #     A.GaussNoise(),\n",
    "        #     A.MotionBlur(blur_limit=(3, 5)),\n",
    "        # ], p=0.1),\n",
    "        # A.ColorJitter(),\n",
    "        # A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n",
    "        # A.HorizontalFlip(p=0.5),\n",
    "        # A.Cutout(max_h_size=102, max_w_size=102, num_holes=5, p=0.5),\n",
    "        # A.CLAHE(p=1.0),\n",
    "        # albumentations.HorizontalFlip(p=0.5),\n",
    "        # # albumentations.VerticalFlip(p=0.5),\n",
    "        # albumentations.RandomBrightness(limit=0.2, p=0.75),\n",
    "        # albumentations.RandomContrast(limit=0.2, p=0.75),\n",
    "\n",
    "        # albumentations.OneOf([\n",
    "        #     albumentations.OpticalDistortion(distort_limit=1.),\n",
    "        #     albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "        # ], p=0.75),\n",
    "\n",
    "        # albumentations.HueSaturationValue(hue_shift_limit=40, sat_shift_limit=40, val_shift_limit=0, p=0.75),\n",
    "        # albumentations.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.3, rotate_limit=30, border_mode=0, p=0.75),\n",
    "        # A.Cutout(always_apply=False, p=0.5, num_holes=1, max_h_size=409, max_w_size=409),\n",
    "        # A.OneOf([ \n",
    "        # A.OpticalDistortion(distort_limit=1.0), \n",
    "        # A.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "        # A.ElasticTransform(alpha=3), ], p=0.2),\n",
    "        # A.OneOf([\n",
    "        #     # A.GaussNoise(var_limit=[10, 50]),\n",
    "        #     A.GaussianBlur(),\n",
    "        #     A.MotionBlur(),\n",
    "        #     A.MedianBlur(), ], p=0.2),\n",
    "        # A.OneOf([\n",
    "        #     A.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n",
    "        #     A.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=1.0),\n",
    "        #     A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n",
    "        # ], p=0.25),\n",
    "        # A.CoarseDropout(max_holes=8, max_height=image_size//20, max_width=image_size//20,\n",
    "        #                  min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n",
    "        # A.Normalize(mean=0, std=1),\n",
    "        ToTensorV2(),], p=1.0),\n",
    "    \n",
    "    \"valid\": A.Compose([\n",
    "        # IsotropicResize(max_side =image_size),\n",
    "        # A.PadIfNeeded(min_height=image_size, min_width=image_size, border_mode=cv2.BORDER_CONSTANT),\n",
    "        # A.Normalize(mean=0, std=1),\n",
    "        # A.Resize(image_size, image_size),\n",
    "        ToTensorV2(),\n",
    "        ], p=1.0)\n",
    "}\n",
    "\n",
    "LOGGER.info(f\"train transform{data_transforms['train']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b01cf14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T04:01:00.627246Z",
     "iopub.status.busy": "2023-02-15T04:01:00.626993Z",
     "iopub.status.idle": "2023-02-15T04:01:00.760031Z",
     "shell.execute_reply": "2023-02-15T04:01:00.759000Z"
    },
    "papermill": {
     "duration": 0.140238,
     "end_time": "2023-02-15T04:01:00.762834",
     "exception": false,
     "start_time": "2023-02-15T04:01:00.622596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1344, 840]) tensor(0)\n",
      "tensor(255.)\n"
     ]
    }
   ],
   "source": [
    "def pad(array, target_shape):\n",
    "    return np.pad(\n",
    "        array,\n",
    "        [(0, target_shape[i] - array.shape[i]) for i in range(len(array.shape))],\n",
    "        \"constant\",\n",
    "    )\n",
    "\n",
    "def load_img2(img_path):\n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "class BreastDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        if (os.path.exists(f\"/kaggle/input/27300next/output/{row.patient_id}_{row.image_id}.png\")):\n",
    "            img_path = f\"/kaggle/input/27300next/output/{row.patient_id}_{row.image_id}.png\"\n",
    "        else:\n",
    "            img_path = f\"/kaggle/input/1024bicubic/output/{row.patient_id}_{row.image_id}.png\"\n",
    "        img = load_img2(img_path)\n",
    "        label = row['cancer']\n",
    "        # img = np.transpose(img, (2, 0, 1))\n",
    "        data = self.transforms(image=img)\n",
    "        img  = data['image']\n",
    "        # img = img/255\n",
    "        return torch.tensor(img).float(), torch.tensor(label).long()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "fold0 = df[df['fold']==0]\n",
    "train_dataset = BreastDataset(fold0, transforms = data_transforms['train'])\n",
    "image, label = train_dataset[0]\n",
    "print(image.shape, label)\n",
    "print(image.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b89210cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T04:01:00.774153Z",
     "iopub.status.busy": "2023-02-15T04:01:00.772486Z",
     "iopub.status.idle": "2023-02-15T04:01:00.779836Z",
     "shell.execute_reply": "2023-02-15T04:01:00.778893Z"
    },
    "papermill": {
     "duration": 0.014309,
     "end_time": "2023-02-15T04:01:00.781840",
     "exception": false,
     "start_time": "2023-02-15T04:01:00.767531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class ModelOld(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        # ,drop_rate = 0.3, drop_path_rate = 0.2\n",
    "        self.backbone = timm.create_model(CFG.model_name, pretrained=False,drop_rate = 0.3, drop_path_rate = 0.2)\n",
    "        self.fc = nn.Linear(self.backbone.classifier.in_features,2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.fc(self.dropout(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "742f96f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T04:01:00.791491Z",
     "iopub.status.busy": "2023-02-15T04:01:00.790675Z",
     "iopub.status.idle": "2023-02-15T04:01:00.798299Z",
     "shell.execute_reply": "2023-02-15T04:01:00.797390Z"
    },
    "papermill": {
     "duration": 0.014213,
     "end_time": "2023-02-15T04:01:00.800222",
     "exception": false,
     "start_time": "2023-02-15T04:01:00.786009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "878e7e08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T04:01:00.808951Z",
     "iopub.status.busy": "2023-02-15T04:01:00.808688Z",
     "iopub.status.idle": "2023-02-15T04:01:00.817344Z",
     "shell.execute_reply": "2023-02-15T04:01:00.816363Z"
    },
    "papermill": {
     "duration": 0.015197,
     "end_time": "2023-02-15T04:01:00.819227",
     "exception": false,
     "start_time": "2023-02-15T04:01:00.804030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def valid_fn_two(val_dataloader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    truth = []\n",
    "    preds = []\n",
    "    valid_labels = []\n",
    "    start = end = time.time()\n",
    "    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n",
    "    for step, (images, labels) in pbar:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "        valid_labels.append(labels.cpu().numpy())\n",
    "        loss = criterion(outputs, labels)\n",
    "#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "#         print(outputs)\n",
    "        preds.append(F.softmax(outputs).to('cpu').numpy())\n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n",
    "                        gpu_mem=f'{mem:0.2f} GB')\n",
    "    predictions = np.concatenate(preds)\n",
    "    valid_labels = np.concatenate(valid_labels)\n",
    "    return losses.avg, predictions, valid_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61c1ecda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T04:01:00.828617Z",
     "iopub.status.busy": "2023-02-15T04:01:00.828083Z",
     "iopub.status.idle": "2023-02-15T04:01:01.045083Z",
     "shell.execute_reply": "2023-02-15T04:01:01.044035Z"
    },
    "papermill": {
     "duration": 0.22412,
     "end_time": "2023-02-15T04:01:01.047209",
     "exception": false,
     "start_time": "2023-02-15T04:01:00.823089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SEEDING DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5 fold\n",
      "Fold: 2\n",
      "Model name: tf_efficientnetv2_b2\n",
      "Len valid df: 5471\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def pfbeta(labels, predictions, beta=1):\n",
    "    y_true_count = 0\n",
    "    ctp = 0\n",
    "    cfp = 0\n",
    "\n",
    "    for idx in range(len(labels)):\n",
    "        prediction = min(max(predictions[idx], 0), 1)\n",
    "        if (labels[idx]):\n",
    "            y_true_count += 1\n",
    "            ctp += prediction\n",
    "        else:\n",
    "            cfp += prediction\n",
    "\n",
    "    beta_squared = beta * beta\n",
    "    c_precision = ctp / (ctp + cfp)\n",
    "    c_recall = ctp / y_true_count\n",
    "    if (c_precision > 0 and c_recall > 0):\n",
    "        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n",
    "        return result\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def pfbeta_np(labels, preds, beta=1):\n",
    "    preds = preds.clip(0, 1)\n",
    "    y_true_count = labels.sum()\n",
    "    ctp = preds[labels==1].sum()\n",
    "    cfp = preds[labels==0].sum()\n",
    "    beta_squared = beta * beta\n",
    "    c_precision = ctp / (ctp + cfp)\n",
    "    c_recall = ctp / y_true_count\n",
    "    if (c_precision > 0 and c_recall > 0):\n",
    "        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n",
    "        return result\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "def dfs_freeze(module):\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "def dfs_unfreeze(module):\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "def set_seed(seed = 42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print('> SEEDING DONE')\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "def valid_fn_two(val_dataloader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n",
    "    for step, (images, labels) in pbar:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            with autocast(enabled=True):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "#         print(outputs)\n",
    "        preds.append(F.softmax(outputs).to('cpu').numpy())\n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n",
    "                        gpu_mem=f'{mem:0.2f} GB')\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions\n",
    "set_seed(1)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "for fold in [2]:\n",
    "    LOGGER.info(\"5 fold\")\n",
    "    LOGGER.info(f\"Fold: {fold}\")\n",
    "    LOGGER.info(f\"Model name: {CFG.model_name}\")\n",
    "    valid_df = df[df['fold']==fold].reset_index(drop=True)\n",
    "    LOGGER.info(f\"Len valid df: {len(valid_df)}\")\n",
    "    \n",
    "    valid_dataset = BreastDataset(valid_df, transforms=data_transforms['valid'])\n",
    "\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size = CFG.valid_bs, \n",
    "                                  num_workers=1, shuffle=False, pin_memory=True, drop_last=False)\n",
    "    # model = Model(model_name=CFG.model_name).to(device)\n",
    "    best_f1 = 0\n",
    "    best_metric = 0\n",
    "    total_epoch = 30\n",
    "    warmup = 1\n",
    "#     model = ModelOld(model_name=CFG.model_name).to(CFG.device)\n",
    "#     checkpoint = torch.load(\"/kaggle/input/10folds/tf_efficientnetv2_b2_fold_0_model_epoch_2_0.5510_0.151.pth\")\n",
    "#     model.load_state_dict(checkpoint['state_dict'])\n",
    "#     criterion = nn.CrossEntropyLoss().to(CFG.device)\n",
    "#     LOGGER.info(f\"Train bs: {CFG.train_bs}\")\n",
    "#     # LOGGER.info(f\"Model: {model}\")\n",
    "#     LOGGER.info(f\"{model.__class__.__name__}\")\n",
    "#     LOGGER.info(f\"optimizer: {optimizer}\")\n",
    "#     LOGGER.info(f\"total_epoch :{total_epoch}\")\n",
    "#     LOGGER.info(f\"Warmup: {warmup}\")\n",
    "#     for epoch in range(1, total_epoch+1):\n",
    "#         LOGGER.info(f\"Epoch: {epoch}/{total_epoch}\")\n",
    "#         # loss_train = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, CFG.device)\n",
    "#         loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n",
    "#         valid_preds = valid_preds[:, 1]\n",
    "#         valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n",
    "#         valid_preds = np.array(valid_preds).flatten()\n",
    "        \n",
    "#         valid_df['raw_pred'] = valid_preds\n",
    "#         LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n",
    "#         # LOGGER.info(f\"Train loss:{loss_train:.4f}, Valid loss:{loss_valid:.4f}\")\n",
    "#         # print(valid_df.head())\n",
    "#         grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n",
    "#         grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n",
    "#         valid_labels_mean = grp_df['cancer'].values\n",
    "#         valid_preds_mean = grp_df['raw_pred'].values\n",
    "#         # print(valid_labels[:5], valid_preds_mean[:5])\n",
    "#         val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n",
    "#         LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n",
    "#         best_metric_mean_at_epoch = 0\n",
    "#         best_metric1 = 0\n",
    "#         best_threshold_mean = 0\n",
    "#         best_auc = 0\n",
    "#         best_cf = None\n",
    "#         for i in np.arange(0.001, 0.599, 0.001):\n",
    "#             valid_argmax = (valid_preds_mean>i).astype(np.int32)\n",
    "#     #             print(valid_argmax)\n",
    "#             # val_metric = pfbeta(valid_labels_mean, valid_argmax)\n",
    "#             val_metric1 = pfbeta_np(valid_labels_mean, valid_argmax)\n",
    "#             val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n",
    "#             val_f1 = f1_score(valid_labels_mean, valid_argmax)\n",
    "#             val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n",
    "#             cf = confusion_matrix(valid_labels_mean, valid_argmax)\n",
    "#             if val_metric1> best_metric1:\n",
    "#                 best_metric1 = val_metric1\n",
    "#                 # best_metric_mean_at_epoch = val_metric\n",
    "#                 best_threshold_mean = i\n",
    "#                 best_auc = val_auc\n",
    "#                 best_cf = cf\n",
    "#         LOGGER.info(f\"Best metric at epoch {epoch}: {best_metric1:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n",
    "#         LOGGER.info(f\"Cf: {best_cf}\")\n",
    "#         if best_metric1> best_metric:\n",
    "\n",
    "#             LOGGER.info(f\"Model improve: {best_metric:.4f} -> {best_metric1:.4f}\")\n",
    "#             best_metric = best_metric1\n",
    "#         state = {'epoch': epoch, 'state_dict': model.state_dict()}\n",
    "#         # state = {'epoch': epoch, 'state_dict': model.state_dict(),'optimizer': optimizer.state_dict(), 'scheduler':scheduler.state_dict()}\n",
    "#         path = f'foldonefive/{CFG.model_name}_fold_{fold}_model_epoch_{epoch}_{best_metric1:.4f}_{best_threshold_mean:.3f}.pth'\n",
    "#         torch.save(state, path)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25db9bcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T04:01:01.057512Z",
     "iopub.status.busy": "2023-02-15T04:01:01.057236Z",
     "iopub.status.idle": "2023-02-15T04:01:01.282698Z",
     "shell.execute_reply": "2023-02-15T04:01:01.281766Z"
    },
    "papermill": {
     "duration": 0.23332,
     "end_time": "2023-02-15T04:01:01.285059",
     "exception": false,
     "start_time": "2023-02-15T04:01:01.051739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "def valid_fn_two(val_dataloader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n",
    "    for step, (images, labels) in pbar:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            with autocast(enabled=True):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "#         print(outputs)\n",
    "        preds.append(F.softmax(outputs).to('cpu').numpy())\n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n",
    "                        gpu_mem=f'{mem:0.2f} GB')\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions\n",
    "# set_seed(1)\n",
    "# out_file = 'swa_model_fold0_10.pth' \n",
    "# iteration = [\n",
    "#     '/kaggle/input/10folds/tf_efficientnetv2_b2_fold_0_model_epoch_2_0.5510_0.151.pth',\n",
    "#     '/kaggle/input/10folds/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth',\n",
    "# #     '/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth'\n",
    "# ]\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss().to(CFG.device)\n",
    "# best_metric = 0\n",
    "# torch.cuda.empty_cache()\n",
    "# def objective(trial):\n",
    "# #     a1 = 0.4962849464623993 \n",
    "# #     a2 = 0.5037150535376007\n",
    "# #     a1 = 0.1689507073116359 \n",
    "# #     a2 = 0.47142151346976024 \n",
    "# #     a3 = 0.3596277792186039\n",
    "#     a1 = trial.suggest_uniform('a1', 0.01, 0.79)\n",
    "#     a2 = 1-a1\n",
    "# #     a2 = trial.suggest_uniform('a2', 0.1, 1-a1)\n",
    "# #     a3 = 1-a1-a2\n",
    "#     state_dict = None\n",
    "#     for i in iteration:\n",
    "#         f = i\n",
    "#         print(f)\n",
    "#         f = torch.load(f, map_location=lambda storage, loc: storage)\n",
    "#         if state_dict is None:\n",
    "#             print(\"none: \", i)\n",
    "#             state_dict = f['state_dict']\n",
    "#             key = list(f['state_dict'].keys())\n",
    "#             for k in key:\n",
    "#                 state_dict[k] = f['state_dict'][k]*a1\n",
    "#         elif i=='/kaggle/input/10folds/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth': \n",
    "#             print(\"hehe\", i)\n",
    "#             key = list(f['state_dict'].keys())\n",
    "#             for k in key:\n",
    "#                 state_dict[k] = state_dict[k] + a2*f['state_dict'][k]\n",
    "# #         elif i=='/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth':\n",
    "# #             print(\"noob\", i)\n",
    "# #             key = list(f['state_dict'].keys())\n",
    "# #             for k in key:\n",
    "# #                 state_dict[k] = state_dict[k] + a3*f['state_dict'][k]\n",
    "#     print(a1, a2)\n",
    "#     # for k in key:\n",
    "#     #     state_dict[k] = state_dict[k] / len(iteration)\n",
    "#     print('')\n",
    "\n",
    "#     # print(out_file)\n",
    "#     torch.save({'state_dict': state_dict}, out_file)\n",
    "\n",
    "#     model = ModelOld(model_name=CFG.model_name).to(CFG.device)\n",
    "#     checkpoint = torch.load(\"swa_model_fold0_10.pth\")\n",
    "#     model.load_state_dict(checkpoint['state_dict'])\n",
    "# #     model = nn.DataParallel(model)\n",
    "\n",
    "#     loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n",
    "#     valid_preds = valid_preds[:, 1]\n",
    "#     valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n",
    "#     valid_preds = np.array(valid_preds).flatten()\n",
    "    \n",
    "#     valid_df['raw_pred'] = valid_preds\n",
    "#     LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n",
    "#     grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n",
    "#     grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n",
    "#     valid_labels_mean = grp_df['cancer'].values\n",
    "#     valid_preds_mean = grp_df['raw_pred'].values\n",
    "#     # print(valid_labels[:5], valid_preds_mean[:5])\n",
    "#     val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n",
    "#     LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n",
    "#     best_metric_mean_at_epoch = 0\n",
    "#     best_metric = 0\n",
    "    \n",
    "#     best_threshold_mean = 0\n",
    "#     best_auc = 0\n",
    "#     best_cf = None\n",
    "#     for i in np.arange(0.001, 0.599, 0.001):\n",
    "#         valid_argmax = (valid_preds_mean>i).astype(np.int32)\n",
    "#         val_metric = pfbeta_np(valid_labels_mean, valid_argmax)\n",
    "#         val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n",
    "#         val_f1 = f1_score(valid_labels_mean, valid_argmax)\n",
    "#         val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n",
    "#         cf = confusion_matrix(valid_labels_mean, valid_argmax)\n",
    "#         if val_metric> best_metric:\n",
    "#             best_metric = val_metric\n",
    "#             # best_metric_mean_at_epoch = val_metric\n",
    "#             best_threshold_mean = i\n",
    "#             best_auc = val_auc\n",
    "#             best_cf = cf\n",
    "#     state = {'state_dict': model.state_dict()}\n",
    "#     path = f'swa_{CFG.model_name}_fold_{fold}_model_{best_metric:.4f}_{best_threshold_mean:.4f}.pth'\n",
    "#     torch.save(state, path)\n",
    "    \n",
    "#     LOGGER.info(f\"Best metric at: {best_metric:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n",
    "#     LOGGER.info(f\"Cf: {best_cf}\")\n",
    "#     return best_metric\n",
    "\n",
    "# study = optuna.create_study(direction='maximize', sampler = TPESampler(seed=1))\n",
    "# study.optimize(func=objective, n_trials=40)\n",
    "# study.best_params\n",
    "# # 0.5563409550491111 0.4436590449508889 fold 0\n",
    "# # 0.12634002523631388 0.8351954705276587 0.03846450423602743 0.5393 \n",
    "# # 0.583301614081906 0.3673525472043472 0.04934583871374687 fold 2 0.50\n",
    "# # 0.1689507073116359 0.47142151346976024 0.3596277792186039 fold 2 0.5055 0.5055 0.3670  0.7261"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4357cfd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T04:01:01.295566Z",
     "iopub.status.busy": "2023-02-15T04:01:01.295256Z",
     "iopub.status.idle": "2023-02-15T06:22:34.422180Z",
     "shell.execute_reply": "2023-02-15T06:22:34.418924Z"
    },
    "papermill": {
     "duration": 8493.137207,
     "end_time": "2023-02-15T06:22:34.426850",
     "exception": false,
     "start_time": "2023-02-15T04:01:01.289643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-15 04:01:01,312]\u001b[0m A new study created in memory with name: no-name-632d8cb0-de76-48eb-9d29-3b1dd7ffdc11\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SEEDING DONE\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.696428379420678 0.25782924081301933 0.04574237976630263\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:42<00:00,  2.59s/it, eval_loss=0.0837, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0837\n",
      "Val metric mean prob: 0.2452\n",
      "Best metric at: 0.4819 0.3510  0.6972\n",
      "Cf: [[2320   13]\n",
      " [  30   20]]\n",
      "\u001b[32m[I 2023-02-15 04:04:55,087]\u001b[0m Trial 0 finished with value: 0.4819277108433735 and parameters: {'a1': 0.696428379420678, 'a2': 0.25782924081301933}. Best is trial 0 with value: 0.4819277108433735.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.6729840492188729 0.24074261405220249 0.08627333672892462\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:13<00:00,  2.25s/it, eval_loss=0.0838, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0838\n",
      "Val metric mean prob: 0.2468\n",
      "Best metric at: 0.4762 0.3500  0.6970\n",
      "Cf: [[2319   14]\n",
      " [  30   20]]\n",
      "\u001b[32m[I 2023-02-15 04:08:14,920]\u001b[0m Trial 1 finished with value: 0.4761904761904762 and parameters: {'a1': 0.6729840492188729, 'a2': 0.24074261405220249}. Best is trial 0 with value: 0.4819277108433735.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.9424287982974126 0.010604306348408641 0.046966895354178806\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:11<00:00,  2.22s/it, eval_loss=0.0841, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0841\n",
      "Val metric mean prob: 0.2323\n",
      "Best metric at: 0.4494 0.2740  0.6959\n",
      "Cf: [[2314   19]\n",
      " [  30   20]]\n",
      "\u001b[32m[I 2023-02-15 04:11:28,775]\u001b[0m Trial 2 finished with value: 0.449438202247191 and parameters: {'a1': 0.9424287982974126, 'a2': 0.010604306348408641}. Best is trial 0 with value: 0.4819277108433735.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.415315944810793 0.0380519342860986 0.5466321209031084\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:14<00:00,  2.26s/it, eval_loss=0.0850, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0850\n",
      "Val metric mean prob: 0.2612\n",
      "Best metric at: 0.4561 0.2260  0.7519\n",
      "Cf: [[2295   38]\n",
      " [  24   26]]\n",
      "\u001b[32m[I 2023-02-15 04:14:46,010]\u001b[0m Trial 3 finished with value: 0.45614035087719296 and parameters: {'a1': 0.415315944810793, 'a2': 0.0380519342860986}. Best is trial 0 with value: 0.4819277108433735.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.10792999009478718 0.4581500513604083 0.4339199585448045\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:15<00:00,  2.28s/it, eval_loss=0.0865, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0865\n",
      "Val metric mean prob: 0.2549\n",
      "Best metric at: 0.4792 0.3400  0.7251\n",
      "Cf: [[2310   23]\n",
      " [  27   23]]\n",
      "\u001b[32m[I 2023-02-15 04:18:04,880]\u001b[0m Trial 4 finished with value: 0.4791666666666667 and parameters: {'a1': 0.10792999009478718, 'a2': 0.4581500513604083}. Best is trial 0 with value: 0.4819277108433735.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.20624258854778793 0.5932363450711091 0.200521066381103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:48<00:00,  2.66s/it, eval_loss=0.0860, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0860\n",
      "Val metric mean prob: 0.2424\n",
      "Best metric at: 0.4634 0.4400  0.6872\n",
      "Cf: [[2320   13]\n",
      " [  31   19]]\n",
      "\u001b[32m[I 2023-02-15 04:21:56,275]\u001b[0m Trial 5 finished with value: 0.46341463414634143 and parameters: {'a1': 0.20624258854778793, 'a2': 0.5932363450711091}. Best is trial 0 with value: 0.4819277108433735.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.19903416297977206 0.5643442560181996 0.23662158100202835\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:09<00:00,  2.20s/it, eval_loss=0.0860, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0860\n",
      "Val metric mean prob: 0.2448\n",
      "Best metric at: 0.4634 0.4410  0.6872\n",
      "Cf: [[2320   13]\n",
      " [  31   19]]\n",
      "\u001b[32m[I 2023-02-15 04:25:08,511]\u001b[0m Trial 6 finished with value: 0.46341463414634143 and parameters: {'a1': 0.19903416297977206, 'a2': 0.5643442560181996}. Best is trial 0 with value: 0.4819277108433735.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.2973635437518493 0.5464327046415969 0.15620375160655375\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:13<00:00,  2.25s/it, eval_loss=0.0856, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0856\n",
      "Val metric mean prob: 0.2426\n",
      "Best metric at: 0.4719 0.3750  0.7061\n",
      "Cf: [[2315   18]\n",
      " [  29   21]]\n",
      "\u001b[32m[I 2023-02-15 04:28:25,095]\u001b[0m Trial 7 finished with value: 0.4719101123595505 and parameters: {'a1': 0.2973635437518493, 'a2': 0.5464327046415969}. Best is trial 0 with value: 0.4819277108433735.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.015006661988523864 0.12003546043452194 0.8649578775769542\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:10<00:00,  2.22s/it, eval_loss=0.0871, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0871\n",
      "Val metric mean prob: 0.2685\n",
      "Best metric at: 0.5306 0.3130  0.7553\n",
      "Cf: [[2311   22]\n",
      " [  24   26]]\n",
      "\u001b[32m[I 2023-02-15 04:31:38,488]\u001b[0m Trial 8 finished with value: 0.5306122448979592 and parameters: {'a1': 0.015006661988523864, 'a2': 0.12003546043452194}. Best is trial 8 with value: 0.5306122448979592.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.11873459854769772 0.22578475870095613 0.6554806427513461\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:09<00:00,  2.21s/it, eval_loss=0.0861, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0861\n",
      "Val metric mean prob: 0.2672\n",
      "Best metric at: 0.4906 0.2900  0.7536\n",
      "Cf: [[2303   30]\n",
      " [  24   26]]\n",
      "\u001b[32m[I 2023-02-15 04:34:51,245]\u001b[0m Trial 9 finished with value: 0.49056603773584906 and parameters: {'a1': 0.11873459854769772, 'a2': 0.22578475870095613}. Best is trial 8 with value: 0.5306122448979592.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.0565348650358591 0.942241783416399 0.001223351547741891\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:51<00:00,  2.69s/it, eval_loss=0.0860, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0860\n",
      "Val metric mean prob: 0.2097\n",
      "Best metric at: 0.4632 0.3200  0.7151\n",
      "Cf: [[2310   23]\n",
      " [  28   22]]\n",
      "\u001b[32m[I 2023-02-15 04:38:45,653]\u001b[0m Trial 10 finished with value: 0.4631578947368421 and parameters: {'a1': 0.0565348650358591, 'a2': 0.942241783416399}. Best is trial 8 with value: 0.5306122448979592.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.011194607292868086 0.1882112396204835 0.8005941530866484\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:11<00:00,  2.23s/it, eval_loss=0.0868, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0868\n",
      "Val metric mean prob: 0.2686\n",
      "Best metric at: 0.5306 0.3400  0.7553\n",
      "Cf: [[2311   22]\n",
      " [  24   26]]\n",
      "\u001b[32m[I 2023-02-15 04:42:00,792]\u001b[0m Trial 11 finished with value: 0.5306122448979592 and parameters: {'a1': 0.011194607292868086, 'a2': 0.1882112396204835}. Best is trial 8 with value: 0.5306122448979592.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.020317850755860567 0.1293785181217534 0.850303631122386\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:58<00:00,  2.78s/it, eval_loss=0.0870, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0870\n",
      "Val metric mean prob: 0.2690\n",
      "Best metric at: 0.5319 0.3490  0.7459\n",
      "Cf: [[2314   19]\n",
      " [  25   25]]\n",
      "\u001b[32m[I 2023-02-15 04:46:02,632]\u001b[0m Trial 12 finished with value: 0.5319148936170213 and parameters: {'a1': 0.020317850755860567, 'a2': 0.1293785181217534}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.3344341484259708 0.1212299876397081 0.5443358639343212\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:18<00:00,  2.31s/it, eval_loss=0.0850, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0850\n",
      "Val metric mean prob: 0.2643\n",
      "Best metric at: 0.4634 0.3900  0.6872\n",
      "Cf: [[2320   13]\n",
      " [  31   19]]\n",
      "\u001b[32m[I 2023-02-15 04:49:24,399]\u001b[0m Trial 13 finished with value: 0.46341463414634143 and parameters: {'a1': 0.3344341484259708, 'a2': 0.1212299876397081}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.022808062012235533 0.3389859926702643 0.6382059453175002\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:18<00:00,  2.31s/it, eval_loss=0.0866, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0866\n",
      "Val metric mean prob: 0.2635\n",
      "Best metric at: 0.5053 0.3560  0.7355\n",
      "Cf: [[2312   21]\n",
      " [  26   24]]\n",
      "\u001b[32m[I 2023-02-15 04:52:46,040]\u001b[0m Trial 14 finished with value: 0.505263157894737 and parameters: {'a1': 0.022808062012235533, 'a2': 0.3389859926702643}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.21832968996911814 0.11919437945666667 0.6624759305742152\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:19<00:00,  2.32s/it, eval_loss=0.0856, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0856\n",
      "Val metric mean prob: 0.2678\n",
      "Best metric at: 0.4815 0.2680  0.7531\n",
      "Cf: [[2301   32]\n",
      " [  24   26]]\n",
      "\u001b[32m[I 2023-02-15 04:56:08,702]\u001b[0m Trial 15 finished with value: 0.48148148148148145 and parameters: {'a1': 0.21832968996911814, 'a2': 0.11919437945666667}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.4634830027383563 0.08605555921211391 0.45046143804952976\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [04:02<00:00,  2.81s/it, eval_loss=0.0847, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0847\n",
      "Val metric mean prob: 0.2598\n",
      "Best metric at: 0.4750 0.3900  0.6876\n",
      "Cf: [[2322   11]\n",
      " [  31   19]]\n",
      "\u001b[32m[I 2023-02-15 05:00:13,872]\u001b[0m Trial 16 finished with value: 0.4750000000000001 and parameters: {'a1': 0.4634830027383563, 'a2': 0.08605555921211391}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.13462564184122994 0.14233610223327825 0.7230382559254918\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:15<00:00,  2.27s/it, eval_loss=0.0860, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0860\n",
      "Val metric mean prob: 0.2693\n",
      "Best metric at: 0.5098 0.3040  0.7544\n",
      "Cf: [[2307   26]\n",
      " [  24   26]]\n",
      "\u001b[32m[I 2023-02-15 05:03:32,452]\u001b[0m Trial 17 finished with value: 0.5098039215686274 and parameters: {'a1': 0.13462564184122994, 'a2': 0.14233610223327825}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.29459633056385315 0.050081799835791155 0.6553218696003557\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:14<00:00,  2.26s/it, eval_loss=0.0853, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0853\n",
      "Val metric mean prob: 0.2665\n",
      "Best metric at: 0.4848 0.2780  0.7346\n",
      "Cf: [[2308   25]\n",
      " [  26   24]]\n",
      "\u001b[32m[I 2023-02-15 05:06:49,383]\u001b[0m Trial 18 finished with value: 0.48484848484848486 and parameters: {'a1': 0.29459633056385315, 'a2': 0.050081799835791155}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.02502963173252078 0.34398204509637603 0.6309883231711031\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [04:11<00:00,  2.93s/it, eval_loss=0.0866, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0866\n",
      "Val metric mean prob: 0.2633\n",
      "Best metric at: 0.5053 0.3570  0.7355\n",
      "Cf: [[2312   21]\n",
      " [  26   24]]\n",
      "\u001b[32m[I 2023-02-15 05:11:04,036]\u001b[0m Trial 19 finished with value: 0.505263157894737 and parameters: {'a1': 0.02502963173252078, 'a2': 0.34398204509637603}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.14966765726735287 0.012731732346652591 0.8376006103859945\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:15<00:00,  2.27s/it, eval_loss=0.0866, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0866\n",
      "Val metric mean prob: 0.2675\n",
      "Best metric at: 0.5149 0.2650  0.7546\n",
      "Cf: [[2308   25]\n",
      " [  24   26]]\n",
      "\u001b[32m[I 2023-02-15 05:14:22,393]\u001b[0m Trial 20 finished with value: 0.5148514851485149 and parameters: {'a1': 0.14966765726735287, 'a2': 0.012731732346652591}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.012903692241099773 0.17290391048108741 0.8141923972778128\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:13<00:00,  2.25s/it, eval_loss=0.0868, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0868\n",
      "Val metric mean prob: 0.2689\n",
      "Best metric at: 0.5306 0.3370  0.7553\n",
      "Cf: [[2311   22]\n",
      " [  24   26]]\n",
      "\u001b[32m[I 2023-02-15 05:17:40,154]\u001b[0m Trial 21 finished with value: 0.5306122448979592 and parameters: {'a1': 0.012903692241099773, 'a2': 0.17290391048108741}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.013146092767387213 0.1863675723071534 0.8004863349254594\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:12<00:00,  2.24s/it, eval_loss=0.0868, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0868\n",
      "Val metric mean prob: 0.2687\n",
      "Best metric at: 0.5306 0.3390  0.7553\n",
      "Cf: [[2311   22]\n",
      " [  24   26]]\n",
      "\u001b[32m[I 2023-02-15 05:20:55,626]\u001b[0m Trial 22 finished with value: 0.5306122448979592 and parameters: {'a1': 0.013146092767387213, 'a2': 0.1863675723071534}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.09366181319436219 0.11404368335965252 0.7922945034459853\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [04:04<00:00,  2.84s/it, eval_loss=0.0865, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0865\n",
      "Val metric mean prob: 0.2695\n",
      "Best metric at: 0.5253 0.3170  0.7551\n",
      "Cf: [[2310   23]\n",
      " [  24   26]]\n",
      "\u001b[32m[I 2023-02-15 05:25:04,498]\u001b[0m Trial 23 finished with value: 0.5252525252525252 and parameters: {'a1': 0.09366181319436219, 'a2': 0.11404368335965252}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.2011289887807572 0.07450774837150165 0.7243632628477411\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:15<00:00,  2.27s/it, eval_loss=0.0858, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0858\n",
      "Val metric mean prob: 0.2684\n",
      "Best metric at: 0.4952 0.2660  0.7538\n",
      "Cf: [[2304   29]\n",
      " [  24   26]]\n",
      "\u001b[32m[I 2023-02-15 05:28:22,666]\u001b[0m Trial 24 finished with value: 0.49523809523809526 and parameters: {'a1': 0.2011289887807572, 'a2': 0.07450774837150165}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.09574743727705634 0.2892683468639853 0.6149842158589583\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:59<00:00,  2.78s/it, eval_loss=0.0860, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0860\n",
      "Val metric mean prob: 0.2656\n",
      "Best metric at: 0.4948 0.3370  0.7351\n",
      "Cf: [[2310   23]\n",
      " [  26   24]]\n",
      "\u001b[32m[I 2023-02-15 05:32:24,979]\u001b[0m Trial 25 finished with value: 0.49484536082474223 and parameters: {'a1': 0.09574743727705634, 'a2': 0.2892683468639853}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.16025542593187478 0.17664225797373628 0.663102316094389\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:12<00:00,  2.24s/it, eval_loss=0.0858, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0858\n",
      "Val metric mean prob: 0.2682\n",
      "Best metric at: 0.4906 0.2830  0.7536\n",
      "Cf: [[2303   30]\n",
      " [  24   26]]\n",
      "\u001b[32m[I 2023-02-15 05:35:41,026]\u001b[0m Trial 26 finished with value: 0.49056603773584906 and parameters: {'a1': 0.16025542593187478, 'a2': 0.17664225797373628}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.07381576890123422 0.19171496736751925 0.7344692637312465\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [04:00<00:00,  2.79s/it, eval_loss=0.0864, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0864\n",
      "Val metric mean prob: 0.2690\n",
      "Best metric at: 0.5200 0.3230  0.7549\n",
      "Cf: [[2309   24]\n",
      " [  24   26]]\n",
      "\u001b[32m[I 2023-02-15 05:39:44,176]\u001b[0m Trial 27 finished with value: 0.52 and parameters: {'a1': 0.07381576890123422, 'a2': 0.19171496736751925}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.23373535611734206 0.08379123023927895 0.682473413643379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:23<00:00,  2.37s/it, eval_loss=0.0856, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0856\n",
      "Val metric mean prob: 0.2676\n",
      "Best metric at: 0.4950 0.2860  0.7444\n",
      "Cf: [[2307   26]\n",
      " [  25   25]]\n",
      "\u001b[32m[I 2023-02-15 05:43:11,034]\u001b[0m Trial 28 finished with value: 0.495049504950495 and parameters: {'a1': 0.23373535611734206, 'a2': 0.08379123023927895}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.34895367200380045 0.15021364215226077 0.5008326858439388\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:20<00:00,  2.33s/it, eval_loss=0.0850, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0850\n",
      "Val metric mean prob: 0.2635\n",
      "Best metric at: 0.4750 0.4140  0.6876\n",
      "Cf: [[2322   11]\n",
      " [  31   19]]\n",
      "\u001b[32m[I 2023-02-15 05:46:34,821]\u001b[0m Trial 29 finished with value: 0.4750000000000001 and parameters: {'a1': 0.34895367200380045, 'a2': 0.15021364215226077}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.5621296647655908 0.13789831667433994 0.2999720185600693\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:23<00:00,  2.36s/it, eval_loss=0.0843, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0843\n",
      "Val metric mean prob: 0.2550\n",
      "Best metric at: 0.4810 0.3860  0.6879\n",
      "Cf: [[2323   10]\n",
      " [  31   19]]\n",
      "\u001b[32m[I 2023-02-15 05:50:00,991]\u001b[0m Trial 30 finished with value: 0.48101265822784806 and parameters: {'a1': 0.5621296647655908, 'a2': 0.13789831667433994}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.012784045117558693 0.2570229683696003 0.7301929865128409\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:58<00:00,  2.78s/it, eval_loss=0.0866, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0866\n",
      "Val metric mean prob: 0.2671\n",
      "Best metric at: 0.5122 0.4330  0.7076\n",
      "Cf: [[2322   11]\n",
      " [  29   21]]\n",
      "\u001b[32m[I 2023-02-15 05:54:03,361]\u001b[0m Trial 31 finished with value: 0.5121951219512195 and parameters: {'a1': 0.012784045117558693, 'a2': 0.2570229683696003}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.07460135134466488 0.20631570568007457 0.7190829429752605\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:15<00:00,  2.27s/it, eval_loss=0.0862, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0862\n",
      "Val metric mean prob: 0.2689\n",
      "Best metric at: 0.5149 0.3160  0.7546\n",
      "Cf: [[2308   25]\n",
      " [  24   26]]\n",
      "\u001b[32m[I 2023-02-15 05:57:21,739]\u001b[0m Trial 32 finished with value: 0.5148514851485149 and parameters: {'a1': 0.07460135134466488, 'a2': 0.20631570568007457}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.06891381665891431 0.26886663839517116 0.6622195449459145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [04:01<00:00,  2.81s/it, eval_loss=0.0862, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0862\n",
      "Val metric mean prob: 0.2668\n",
      "Best metric at: 0.5000 0.3440  0.7353\n",
      "Cf: [[2311   22]\n",
      " [  26   24]]\n",
      "\u001b[32m[I 2023-02-15 06:01:26,408]\u001b[0m Trial 33 finished with value: 0.4999999999999999 and parameters: {'a1': 0.06891381665891431, 'a2': 0.26886663839517116}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.01386492721814735 0.040716231589281726 0.9454188411925709\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:15<00:00,  2.27s/it, eval_loss=0.0878, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0878\n",
      "Val metric mean prob: 0.2653\n",
      "Best metric at: 0.5200 0.2800  0.7549\n",
      "Cf: [[2309   24]\n",
      " [  24   26]]\n",
      "\u001b[32m[I 2023-02-15 06:04:45,007]\u001b[0m Trial 34 finished with value: 0.52 and parameters: {'a1': 0.01386492721814735, 'a2': 0.040716231589281726}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.14736903268138038 0.22256564765953035 0.6300653196590893\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:16<00:00,  2.28s/it, eval_loss=0.0859, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0859\n",
      "Val metric mean prob: 0.2669\n",
      "Best metric at: 0.4810 0.4410  0.6879\n",
      "Cf: [[2323   10]\n",
      " [  31   19]]\n",
      "\u001b[32m[I 2023-02-15 06:08:04,648]\u001b[0m Trial 35 finished with value: 0.48101265822784806 and parameters: {'a1': 0.14736903268138038, 'a2': 0.22256564765953035}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.11548363423935011 0.06539209124100805 0.8191242745196418\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [04:05<00:00,  2.85s/it, eval_loss=0.0866, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0866\n",
      "Val metric mean prob: 0.2689\n",
      "Best metric at: 0.5200 0.2940  0.7549\n",
      "Cf: [[2309   24]\n",
      " [  24   26]]\n",
      "\u001b[32m[I 2023-02-15 06:12:12,700]\u001b[0m Trial 36 finished with value: 0.52 and parameters: {'a1': 0.11548363423935011, 'a2': 0.06539209124100805}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.06525124751435446 0.16177754687166324 0.7729712056139822\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:33<00:00,  2.48s/it, eval_loss=0.0865, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0865\n",
      "Val metric mean prob: 0.2695\n",
      "Best metric at: 0.5306 0.3350  0.7553\n",
      "Cf: [[2311   22]\n",
      " [  24   26]]\n",
      "\u001b[32m[I 2023-02-15 06:15:48,950]\u001b[0m Trial 37 finished with value: 0.5306122448979592 and parameters: {'a1': 0.06525124751435446, 'a2': 0.16177754687166324}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.17324538499826692 0.020138416042507823 0.8066161989592253\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:23<00:00,  2.36s/it, eval_loss=0.0864, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0864\n",
      "Val metric mean prob: 0.2677\n",
      "Best metric at: 0.5098 0.2590  0.7544\n",
      "Cf: [[2307   26]\n",
      " [  24   26]]\n",
      "\u001b[32m[I 2023-02-15 06:19:15,036]\u001b[0m Trial 38 finished with value: 0.5098039215686274 and parameters: {'a1': 0.17324538499826692, 'a2': 0.020138416042507823}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "none:  /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "hehe /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth\n",
      "/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "noob /kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth\n",
      "0.12368925631665356 0.0984353318525482 0.7778754118307982\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 86/86 [03:16<00:00,  2.28s/it, eval_loss=0.0864, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0864\n",
      "Val metric mean prob: 0.2694\n",
      "Best metric at: 0.5149 0.3020  0.7546\n",
      "Cf: [[2308   25]\n",
      " [  24   26]]\n",
      "\u001b[32m[I 2023-02-15 06:22:34,405]\u001b[0m Trial 39 finished with value: 0.5148514851485149 and parameters: {'a1': 0.12368925631665356, 'a2': 0.0984353318525482}. Best is trial 12 with value: 0.5319148936170213.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a1': 0.020317850755860567, 'a2': 0.1293785181217534}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(1)\n",
    "out_file = 'swa_model_fold2_10.pth' \n",
    "iteration = [\n",
    "    '/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth',\n",
    "    '/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth',\n",
    "    '/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth'\n",
    "]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(CFG.device)\n",
    "best_metric = 0\n",
    "torch.cuda.empty_cache()\n",
    "def objective(trial):\n",
    "#     a1 = 0.12634002523631388\n",
    "#     a2 = 0.8351954705276587\n",
    "#     a3 = 0.03846450423602743\n",
    "    a1 = trial.suggest_uniform('a1', 0.01, 0.99)\n",
    "    a2 = trial.suggest_uniform('a2', 0.01, 1-a1)\n",
    "    a3 = 1-a1-a2\n",
    "    state_dict = None\n",
    "    for i in iteration:\n",
    "        f = i\n",
    "        print(f)\n",
    "        f = torch.load(f, map_location=lambda storage, loc: storage)\n",
    "        if state_dict is None:\n",
    "            print(\"none: \", i)\n",
    "            state_dict = f['state_dict']\n",
    "            key = list(f['state_dict'].keys())\n",
    "            for k in key:\n",
    "                state_dict[k] = f['state_dict'][k]*a1\n",
    "        elif i=='/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth': \n",
    "            print(\"hehe\", i)\n",
    "            key = list(f['state_dict'].keys())\n",
    "            for k in key:\n",
    "                state_dict[k] = state_dict[k] + a2*f['state_dict'][k]\n",
    "        elif i=='/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth':\n",
    "            print(\"noob\", i)\n",
    "            key = list(f['state_dict'].keys())\n",
    "            for k in key:\n",
    "                state_dict[k] = state_dict[k] + a3*f['state_dict'][k]\n",
    "    print(a1, a2, a3)\n",
    "    # for k in key:\n",
    "    #     state_dict[k] = state_dict[k] / len(iteration)\n",
    "    print('')\n",
    "\n",
    "    # print(out_file)\n",
    "    torch.save({'state_dict': state_dict}, out_file)\n",
    "\n",
    "    model = ModelOld(model_name=CFG.model_name).to(CFG.device)\n",
    "    checkpoint = torch.load(\"swa_model_fold2_10.pth\")\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "#     model = nn.DataParallel(model)\n",
    "\n",
    "    loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n",
    "    valid_preds = valid_preds[:, 1]\n",
    "    valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n",
    "    valid_preds = np.array(valid_preds).flatten()\n",
    "    \n",
    "    valid_df['raw_pred'] = valid_preds\n",
    "    LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n",
    "    grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n",
    "    grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n",
    "    valid_labels_mean = grp_df['cancer'].values\n",
    "    valid_preds_mean = grp_df['raw_pred'].values\n",
    "    # print(valid_labels[:5], valid_preds_mean[:5])\n",
    "    val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n",
    "    LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n",
    "    best_metric_mean_at_epoch = 0\n",
    "    best_metric = 0\n",
    "    \n",
    "    best_threshold_mean = 0\n",
    "    best_auc = 0\n",
    "    best_cf = None\n",
    "    for i in np.arange(0.001, 0.599, 0.001):\n",
    "        valid_argmax = (valid_preds_mean>i).astype(np.int32)\n",
    "        val_metric = pfbeta_np(valid_labels_mean, valid_argmax)\n",
    "        val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n",
    "        val_f1 = f1_score(valid_labels_mean, valid_argmax)\n",
    "        val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n",
    "        cf = confusion_matrix(valid_labels_mean, valid_argmax)\n",
    "        if val_metric> best_metric:\n",
    "            best_metric = val_metric\n",
    "            # best_metric_mean_at_epoch = val_metric\n",
    "            best_threshold_mean = i\n",
    "            best_auc = val_auc\n",
    "            best_cf = cf\n",
    "    state = {'state_dict': model.state_dict()}\n",
    "    path = f'swa_{CFG.model_name}_fold_{fold}_model_{best_metric:.4f}_{best_threshold_mean:.3f}.pth'\n",
    "    torch.save(state, path)\n",
    "    \n",
    "    LOGGER.info(f\"Best metric at: {best_metric:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n",
    "    LOGGER.info(f\"Cf: {best_cf}\")\n",
    "    return best_metric\n",
    "\n",
    "study = optuna.create_study(direction='maximize', sampler = TPESampler(seed=666))\n",
    "study.optimize(func=objective, n_trials=40)\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfb2c629",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T06:22:35.576066Z",
     "iopub.status.busy": "2023-02-15T06:22:35.575675Z",
     "iopub.status.idle": "2023-02-15T06:22:35.583038Z",
     "shell.execute_reply": "2023-02-15T06:22:35.582119Z"
    },
    "papermill": {
     "duration": 0.575508,
     "end_time": "2023-02-15T06:22:35.584943",
     "exception": false,
     "start_time": "2023-02-15T06:22:35.009435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set_seed(1)\n",
    "# out_file = 'swa_model_fold1_10.pth' \n",
    "# iteration = [\n",
    "#     '/kaggle/input/10folds/tf_efficientnetv2_b2_fold_1_model_epoch_3_0.5055_0.360.pth',\n",
    "#     '/kaggle/input/10folds/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4865_0.324.pth',\n",
    "# #     '/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth'\n",
    "# ]\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss().to(CFG.device)\n",
    "# best_metric = 0\n",
    "# torch.cuda.empty_cache()\n",
    "# def objective(trial):\n",
    "# #     a1 = 1\n",
    "# #     a2 = 0.0\n",
    "# #     a1 = 0.1689507073116359 \n",
    "# #     a2 = 0.47142151346976024 \n",
    "# #     a3 = 0.3596277792186039\n",
    "#     a1 = trial.suggest_uniform('a1', 0.01, 0.99)\n",
    "#     a2 = 1-a1\n",
    "# #     a2 = trial.suggest_uniform('a2', 0.1, 1-a1)\n",
    "# #     a3 = 1-a1-a2\n",
    "#     state_dict = None\n",
    "#     for i in iteration:\n",
    "#         f = i\n",
    "#         print(f)\n",
    "#         f = torch.load(f, map_location=lambda storage, loc: storage)\n",
    "#         if state_dict is None:\n",
    "#             print(\"none: \", i)\n",
    "#             state_dict = f['state_dict']\n",
    "#             key = list(f['state_dict'].keys())\n",
    "#             for k in key:\n",
    "#                 state_dict[k] = f['state_dict'][k]*a1\n",
    "#         elif i=='/kaggle/input/10folds/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4865_0.324.pth': \n",
    "#             print(\"hehe\", i)\n",
    "#             key = list(f['state_dict'].keys())\n",
    "#             for k in key:\n",
    "#                 state_dict[k] = state_dict[k] + a2*f['state_dict'][k]\n",
    "# #         elif i=='/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth':\n",
    "# #             print(\"noob\", i)\n",
    "# #             key = list(f['state_dict'].keys())\n",
    "# #             for k in key:\n",
    "# #                 state_dict[k] = state_dict[k] + a3*f['state_dict'][k]\n",
    "#     print(a1, a2)\n",
    "#     # for k in key:\n",
    "#     #     state_dict[k] = state_dict[k] / len(iteration)\n",
    "#     print('')\n",
    "\n",
    "#     # print(out_file)\n",
    "#     torch.save({'state_dict': state_dict}, out_file)\n",
    "\n",
    "#     model = ModelOld(model_name=CFG.model_name).to(CFG.device)\n",
    "#     checkpoint = torch.load(\"/kaggle/input/10folds/tf_efficientnetv2_b2_fold_1_model_epoch_3_0.5055_0.360.pth\")\n",
    "#     model.load_state_dict(checkpoint['state_dict'])\n",
    "# #     model = nn.DataParallel(model)\n",
    "\n",
    "#     loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n",
    "#     valid_preds = valid_preds[:, 1]\n",
    "#     valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n",
    "#     valid_preds = np.array(valid_preds).flatten()\n",
    "    \n",
    "#     valid_df['raw_pred'] = valid_preds\n",
    "#     LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n",
    "#     grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n",
    "#     grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n",
    "#     valid_labels_mean = grp_df['cancer'].values\n",
    "#     valid_preds_mean = grp_df['raw_pred'].values\n",
    "#     # print(valid_labels[:5], valid_preds_mean[:5])\n",
    "#     val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n",
    "#     LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n",
    "#     best_metric_mean_at_epoch = 0\n",
    "#     best_metric = 0\n",
    "    \n",
    "#     best_threshold_mean = 0\n",
    "#     best_auc = 0\n",
    "#     best_cf = None\n",
    "#     for i in np.arange(0.001, 0.599, 0.001):\n",
    "#         valid_argmax = (valid_preds_mean>i).astype(np.int32)\n",
    "#         val_metric = pfbeta_np(valid_labels_mean, valid_argmax)\n",
    "#         val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n",
    "#         val_f1 = f1_score(valid_labels_mean, valid_argmax)\n",
    "#         val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n",
    "#         cf = confusion_matrix(valid_labels_mean, valid_argmax)\n",
    "#         if val_metric> best_metric:\n",
    "#             best_metric = val_metric\n",
    "#             # best_metric_mean_at_epoch = val_metric\n",
    "#             best_threshold_mean = i\n",
    "#             best_auc = val_auc\n",
    "#             best_cf = cf\n",
    "#     state = {'state_dict': model.state_dict()}\n",
    "#     path = f'swa_{CFG.model_name}_fold_{fold}_model_{best_metric:.4f}_{best_threshold_mean:.4f}.pth'\n",
    "#     torch.save(state, path)\n",
    "    \n",
    "#     LOGGER.info(f\"Best metric at: {best_metric:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n",
    "#     LOGGER.info(f\"Cf: {best_cf}\")\n",
    "#     return best_metric\n",
    "\n",
    "# study = optuna.create_study(direction='maximize', sampler = TPESampler(seed=666))\n",
    "# study.optimize(func=objective, n_trials=40)\n",
    "# study.best_params\n",
    "# # 0.5563409550491111 0.4436590449508889 fold 0\n",
    "# # 0.12634002523631388 0.8351954705276587 0.03846450423602743 0.5393 \n",
    "# # 0.583301614081906 0.3673525472043472 0.04934583871374687 fold 2 0.50\n",
    "# # 0.1689507073116359 0.47142151346976024 0.3596277792186039 fold 2 0.5055 0.5055 0.3670  0.7261"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8517.393066,
   "end_time": "2023-02-15T06:22:40.408006",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-15T04:00:43.014940",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
