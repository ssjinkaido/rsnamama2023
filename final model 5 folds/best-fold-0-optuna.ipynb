{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:20.757433Z","iopub.status.busy":"2022-12-30T08:23:20.756596Z","iopub.status.idle":"2022-12-30T08:23:20.769292Z","shell.execute_reply":"2022-12-30T08:23:20.768338Z","shell.execute_reply.started":"2022-12-30T08:23:20.757395Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import random\n","from glob import glob\n","import os, shutil\n","from tqdm import tqdm\n","tqdm.pandas()\n","import time\n","import copy\n","import joblib\n","from collections import defaultdict\n","import gc\n","from IPython import display as ipd\n","import math\n","# visualization\n","import cv2\n","from glob import glob\n","# Sklearn\n","from sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\n","from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix, roc_curve\n","import timm\n","# PyTorch \n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","from torch.cuda.amp import autocast, GradScaler\n","import torch.nn.functional as F\n","from torch.optim.swa_utils import AveragedModel, SWALR\n","from transformers import get_cosine_schedule_with_warmup\n","from collections import defaultdict\n","# import matplotlib.pyplot as plt\n","# Albumentations for augmentations\n","import albumentations as A\n","import albumentations\n","import albumentations as albu\n","from albumentations.pytorch import ToTensorV2\n","from datetime import datetime\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:20.771750Z","iopub.status.busy":"2022-12-30T08:23:20.771281Z","iopub.status.idle":"2022-12-30T08:23:20.782962Z","shell.execute_reply":"2022-12-30T08:23:20.782013Z","shell.execute_reply.started":"2022-12-30T08:23:20.771715Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["class CFG:\n","    seed = 1\n","    model_name = \"tf_efficientnetv2_b2\"\n","    train_bs = 16\n","    valid_bs = train_bs*4\n","    image_size = 1024\n","    epochs = 25\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","print(CFG.device)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:20.784720Z","iopub.status.busy":"2022-12-30T08:23:20.784325Z","iopub.status.idle":"2022-12-30T08:23:20.912644Z","shell.execute_reply":"2022-12-30T08:23:20.911668Z","shell.execute_reply.started":"2022-12-30T08:23:20.784684Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>site_id</th>\n","      <th>patient_id</th>\n","      <th>image_id</th>\n","      <th>laterality</th>\n","      <th>view</th>\n","      <th>age</th>\n","      <th>cancer</th>\n","      <th>biopsy</th>\n","      <th>invasive</th>\n","      <th>BIRADS</th>\n","      <th>implant</th>\n","      <th>density</th>\n","      <th>machine_id</th>\n","      <th>difficult_negative_case</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>10006</td>\n","      <td>462822612</td>\n","      <td>L</td>\n","      <td>CC</td>\n","      <td>61.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>29</td>\n","      <td>False</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>10006</td>\n","      <td>1459541791</td>\n","      <td>L</td>\n","      <td>MLO</td>\n","      <td>61.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>29</td>\n","      <td>False</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>10006</td>\n","      <td>1864590858</td>\n","      <td>R</td>\n","      <td>MLO</td>\n","      <td>61.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>29</td>\n","      <td>False</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>10006</td>\n","      <td>1874946579</td>\n","      <td>R</td>\n","      <td>CC</td>\n","      <td>61.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>29</td>\n","      <td>False</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>10011</td>\n","      <td>220375232</td>\n","      <td>L</td>\n","      <td>CC</td>\n","      <td>55.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>21</td>\n","      <td>True</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   site_id  patient_id    image_id laterality view   age  cancer  biopsy  \\\n","0        2       10006   462822612          L   CC  61.0       0       0   \n","1        2       10006  1459541791          L  MLO  61.0       0       0   \n","2        2       10006  1864590858          R  MLO  61.0       0       0   \n","3        2       10006  1874946579          R   CC  61.0       0       0   \n","4        2       10011   220375232          L   CC  55.0       0       0   \n","\n","   invasive  BIRADS  implant density  machine_id  difficult_negative_case  \\\n","0         0     NaN        0     NaN          29                    False   \n","1         0     NaN        0     NaN          29                    False   \n","2         0     NaN        0     NaN          29                    False   \n","3         0     NaN        0     NaN          29                    False   \n","4         0     0.0        0     NaN          21                     True   \n","\n","   fold  \n","0     1  \n","1     1  \n","2     1  \n","3     1  \n","4     0  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\"train_5folds.csv\")\n","df.head()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["58180\n"]}],"source":["is_hol = df['cancer'] == 1\n","df_try = df[is_hol]\n","df1 = df.append([df_try]*3,ignore_index=True)\n","print(len(df1))"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Date :02/24/2023, 14:16:56\n"]}],"source":["def init_logger(log_file='train1.log'):\n","    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=log_file)\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = init_logger()\n","now = datetime.now()\n","datetime_now = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n","LOGGER.info(f\"Date :{datetime_now}\")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["train transformCompose([\n","  VerticalFlip(always_apply=False, p=0.5),\n","  ColorJitter(always_apply=False, p=0.5, brightness=[0.8, 1.2], contrast=[0.8, 1.2], saturation=[0.8, 1.2], hue=[-0.2, 0.2]),\n","  ShiftScaleRotate(always_apply=False, p=0.5, shift_limit_x=(-0.0625, 0.0625), shift_limit_y=(-0.0625, 0.0625), scale_limit=(-0.050000000000000044, 0.050000000000000044), rotate_limit=(-10, 10), interpolation=1, border_mode=4, value=None, mask_value=None, rotate_method='largest_box'),\n","  HorizontalFlip(always_apply=False, p=0.5),\n","  Cutout(always_apply=False, p=0.5, num_holes=1, max_h_size=409, max_w_size=409),\n","  ToTensorV2(always_apply=True, p=1.0, transpose_mask=False),\n","], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={})\n"]}],"source":["from albumentations import DualTransform\n","image_size = 1024\n","def isotropically_resize_image(img, size, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC):\n","    h, w = img.shape[:2]\n","    if max(w, h) == size:\n","        return img\n","    if w > h:\n","        scale = size / w\n","        h = h * scale\n","        w = size\n","    else:\n","        scale = size / h\n","        w = w * scale\n","        h = size\n","    interpolation = interpolation_up if scale > 1 else interpolation_down\n","    resized = cv2.resize(img, (int(w), int(h)), interpolation=interpolation)\n","    return resized\n","\n","\n","class IsotropicResize(DualTransform):\n","    def __init__(self, max_side, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC,\n","                 always_apply=False, p=1):\n","        super(IsotropicResize, self).__init__(always_apply, p)\n","        self.max_side = max_side\n","        self.interpolation_down = interpolation_down\n","        self.interpolation_up = interpolation_up\n","\n","    def apply(self, img, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC, **params):\n","        return isotropically_resize_image(img, size=self.max_side, interpolation_down=interpolation_down,\n","                                          interpolation_up=interpolation_up)\n","\n","    def apply_to_mask(self, img, **params):\n","        return self.apply(img, interpolation_down=cv2.INTER_NEAREST, interpolation_up=cv2.INTER_NEAREST, **params)\n","\n","    def get_transform_init_args_names(self):\n","        return (\"max_side\", \"interpolation_down\", \"interpolation_up\")\n","    \n","data_transforms = {\n","    \"train\": A.Compose([\n","        # A.Resize(image_size, image_size),\n","        # IsotropicResize(max_side = image_size),\n","        # A.PadIfNeeded(min_height=image_size, min_width=image_size, border_mode=cv2.BORDER_CONSTANT),\n","        # A.RandomBrightnessContrast(),\n","        A.VerticalFlip(p=0.5),   \n","        A.ColorJitter(p=0.5),\n","        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n","        A.HorizontalFlip(p=0.5),\n","        A.Cutout(max_h_size=int(image_size*0.4), max_w_size=int(image_size*0.4), num_holes=1, p=0.5), \n","        # A.OneOf([\n","        #         A.OpticalDistortion(),\n","        #         A.IAAPiecewiseAffine(),\n","        #     ], p=0.1),\n","        # A.OneOf([\n","        #     A.GaussNoise(),\n","        #     A.MotionBlur(blur_limit=(3, 5)),\n","        # ], p=0.1),\n","        # A.ColorJitter(),\n","        # A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n","        # A.HorizontalFlip(p=0.5),\n","        # A.Cutout(max_h_size=102, max_w_size=102, num_holes=5, p=0.5),\n","        # A.CLAHE(clip_limit = 15, p=0.5),\n","        # albumentations.HorizontalFlip(p=0.5),\n","        # # albumentations.VerticalFlip(p=0.5),\n","        # albumentations.RandomBrightness(limit=0.2, p=0.75),\n","        # albumentations.RandomContrast(limit=0.2, p=0.75),\n","\n","        # albumentations.OneOf([\n","        #     albumentations.OpticalDistortion(distort_limit=1.),\n","        #     albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n","        # ], p=0.75),\n","\n","        # albumentations.HueSaturationValue(hue_shift_limit=40, sat_shift_limit=40, val_shift_limit=0, p=0.75),\n","        # albumentations.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.3, rotate_limit=30, border_mode=0, p=0.75),\n","        # A.Cutout(always_apply=False, p=0.5, num_holes=1, max_h_size=409, max_w_size=409),\n","        # A.OneOf([ \n","        # A.OpticalDistortion(distort_limit=1.0), \n","        # A.GridDistortion(num_steps=5, distort_limit=1.),\n","        # A.ElasticTransform(alpha=3), ], p=0.2),\n","        # A.OneOf([\n","        #     # A.GaussNoise(var_limit=[10, 50]),\n","        #     A.GaussianBlur(),\n","        #     A.MotionBlur(),\n","        #     A.MedianBlur(), ], p=0.2),\n","        # A.OneOf([\n","        #     A.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n","        #     A.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=1.0),\n","        #     A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n","        # ], p=0.25),\n","        # A.CoarseDropout(max_holes=8, max_height=image_size//20, max_width=image_size//20,\n","        #                  min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n","        # A.Normalize(mean=0, std=1),\n","        ToTensorV2(),], p=1.0),\n","    \n","    \"valid\": A.Compose([\n","        # IsotropicResize(max_side =image_size),\n","        # A.PadIfNeeded(min_height=image_size, min_width=image_size, border_mode=cv2.BORDER_CONSTANT),\n","        # A.Normalize(mean=0, std=1),\n","        # A.Resize(image_size, image_size),\n","        ToTensorV2(),\n","        ], p=1.0)\n","}\n","\n","LOGGER.info(f\"train transform{data_transforms['train']}\")\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:20.915927Z","iopub.status.busy":"2022-12-30T08:23:20.915346Z","iopub.status.idle":"2022-12-30T08:23:20.931477Z","shell.execute_reply":"2022-12-30T08:23:20.930433Z","shell.execute_reply.started":"2022-12-30T08:23:20.915890Z"},"trusted":true},"outputs":[],"source":["# from albumentations import DualTransform\n","# image_size = 1024\n","# def isotropically_resize_image(img, size, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC):\n","#     h, w = img.shape[:2]\n","#     if max(w, h) == size:\n","#         return img\n","#     if w > h:\n","#         scale = size / w\n","#         h = h * scale\n","#         w = size\n","#     else:\n","#         scale = size / h\n","#         w = w * scale\n","#         h = size\n","#     interpolation = interpolation_up if scale > 1 else interpolation_down\n","#     resized = cv2.resize(img, (int(w), int(h)), interpolation=interpolation)\n","#     return resized\n","\n","\n","# class IsotropicResize(DualTransform):\n","#     def __init__(self, max_side, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC,\n","#                  always_apply=False, p=1):\n","#         super(IsotropicResize, self).__init__(always_apply, p)\n","#         self.max_side = max_side\n","#         self.interpolation_down = interpolation_down\n","#         self.interpolation_up = interpolation_up\n","\n","#     def apply(self, img, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC, **params):\n","#         return isotropically_resize_image(img, size=self.max_side, interpolation_down=interpolation_down,\n","#                                           interpolation_up=interpolation_up)\n","\n","#     def apply_to_mask(self, img, **params):\n","#         return self.apply(img, interpolation_down=cv2.INTER_NEAREST, interpolation_up=cv2.INTER_NEAREST, **params)\n","\n","#     def get_transform_init_args_names(self):\n","#         return (\"max_side\", \"interpolation_down\", \"interpolation_up\")\n","    \n","# data_transforms = {\n","#     \"train\": A.Compose([\n","# #         A.Resize(image_size, image_size),\n","#         # IsotropicResize(max_side = image_size),\n","#        A.PadIfNeeded(min_width=image_size, border_mode=cv2.BORDER_CONSTANT),\n","#         albumentations.HorizontalFlip(p=0.5),\n","#         # albumentations.VerticalFlip(p=0.5),\n","#         albumentations.RandomBrightness(limit=0.2, p=0.75),\n","#         albumentations.RandomContrast(limit=0.2, p=0.75),\n","\n","#         albumentations.OneOf([\n","#             albumentations.OpticalDistortion(distort_limit=1.),\n","#             albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n","#         ], p=0.75),\n","\n","#         albumentations.HueSaturationValue(hue_shift_limit=40, sat_shift_limit=40, val_shift_limit=0, p=0.75),\n","#         albumentations.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.3, rotate_limit=30, border_mode=0, p=0.75),\n","#         A.Cutout(always_apply=False, p=0.5, num_holes=1, max_h_size=409, max_w_size=409),\n","#         # A.RandomBrightnessContrast(),\n","#         # A.VerticalFlip(p=0.5),   \n","#         A.ColorJitter(p = 0.7),\n","#         # A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n","#         # A.HorizontalFlip(p=0.5),\n","#         # A.Cutout(max_h_size=int(image_size * 0.1), max_w_size=int(image_size * 0.1), num_holes=5, p=0.5),\n","#         # albumentations.RandomBrightness(limit=0.2, p=0.75),\n","#         # albumentations.RandomContrast(limit=0.2, p=0.75),\n","\n","#         # albumentations.OneOf([\n","#         #     albumentations.OpticalDistortion(distort_limit=1.),\n","#         #     albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n","#         # ], p=0.75),\n","\n","#         # albumentations.HueSaturationValue(hue_shift_limit=40, sat_shift_limit=40, val_shift_limit=0, p=0.75),\n","#         # albumentations.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.3, rotate_limit=30, border_mode=0, p=0.75),\n","#         # A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=10, val_shift_limit=10, p=0.7),\n","#         # A.RandomBrightnessContrast(brightness_limit=(-0.2,0.2), contrast_limit=(-0.2, 0.2), p=0.7),\n","#         # A.CLAHE(p=0.5),\n","#         # albumentations.OneOf([\n","#         # albumentations.OpticalDistortion(distort_limit=1.),\n","#         # albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n","#         # ], p=0.75),\n","#         # A.OneOf([\n","#         # A.GaussianBlur(),\n","#         # A.MotionBlur(),\n","#         # A.MedianBlur(), ], p=0.5),\n","#         # A.IAASharpen(p = 0.2),\n","#         # A.JpegCompression(p=0.2),\n","#         # A.Downscale(scale_min=0.5, scale_max=0.75),\n","#         # A.OneOf([ A.JpegCompression(), A.Downscale(scale_min=0.1, scale_max=0.15), ], p=0.2), \n","#         # A.IAAPiecewiseAffine(),\n","# #         A.OneOf([ \n","# #         A.OpticalDistortion(distort_limit=1.0), \n","# #         A.GridDistortion(num_steps=5, distort_limit=1.),\n","# #         A.ElasticTransform(alpha=3), ], p=0.2),\n","# #         A.OneOf([\n","# #             A.GaussNoise(var_limit=[10, 50]),\n","# #             A.GaussianBlur(),\n","# #             A.MotionBlur(),\n","# #             A.MedianBlur(), ], p=0.2),\n","#         # A.OneOf([\n","#         #     A.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n","#         #     A.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=1.0),\n","#         #     A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n","#         # ], p=0.25),\n","#         # A.CoarseDropout(max_holes=8, max_height=image_size//20, max_width=image_size//20,\n","#         #                  min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n","#         # A.Normalize(mean=0, std=1),\n","#         ToTensorV2(),], p=1.0),\n","    \n","#     \"valid\": A.Compose([\n","#         # IsotropicResize(max_side = image_size),\n","#         A.PadIfNeeded(min_height=image_size, min_width=image_size, border_mode=cv2.BORDER_CONSTANT),\n","#         # A.Normalize(mean=0, std=1),\n","# #         A.Resize(image_size, image_size),\n","#         ToTensorV2(),\n","#         ], p=1.0)\n","# }\n","\n","# LOGGER.info(f\"train transform{data_transforms['train']}\")\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:20.934703Z","iopub.status.busy":"2022-12-30T08:23:20.933649Z","iopub.status.idle":"2022-12-30T08:23:21.010802Z","shell.execute_reply":"2022-12-30T08:23:21.009678Z","shell.execute_reply.started":"2022-12-30T08:23:20.934663Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3, 1344, 840]) tensor(0)\n"]}],"source":["def pad(array, target_shape):\n","    return np.pad(\n","        array,\n","        [(0, target_shape[i] - array.shape[i]) for i in range(len(array.shape))],\n","        \"constant\",\n","    )\n","    \n","def load_img(img_path):\n","    image = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n","    image = image[:, :, None]\n","    # image = cv2.imread(img_path)\n","    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    # print(image.shape)\n","    \n","    # print(image.shape)\n","    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    # image = pad(image, (1024, 800, 3))\n","        # img = img.reshape((*resize))\n","    return image\n","#     image = cv2.resize(image, (320, 320), cv2.INTER_NEAREST)\n","#     image = image.astype(np.float32)\n","#     mx = np.max(image)\n","#     if mx:\n","#         image/=mx\n","#     image = image /255.0\n","    \n","\n","def load_img1(img_path):\n","    image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","    image = image[:, :, None]\n","    return image\n","\n","def load_img2(img_path):\n","    image = cv2.imread(img_path)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    return image\n","class BreastDataset(Dataset):\n","    def __init__(self, df, transforms=None):\n","        self.df = df\n","        self.transforms = transforms\n","        \n","    def __getitem__(self, index):\n","        row = self.df.iloc[index]\n","        img_path = f\"flip/{row.patient_id}_{row.image_id}.png\"\n","        img = load_img2(img_path)\n","        label = row['cancer']\n","        # img = np.transpose(img, (2, 0, 1))\n","        data = self.transforms(image=img)\n","        img  = data['image']\n","        # img = img/255\n","        return torch.tensor(img).float(), torch.tensor(label).long()\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","fold0 = df[df['fold']==0]\n","train_dataset = BreastDataset(fold0, transforms = data_transforms['train'])\n","image, label= train_dataset[0]\n","print(image.shape, label)\n","# print(image.max())"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["\n","# from pylab import rcParams\n","\n","# f, axarr = plt.subplots(1,15, figsize = (20, 20))\n","# imgs = []\n","# for p in range(15):\n","#     img, label = train_dataset[p]\n","#     img = img.transpose(0, 1).transpose(1,2).cpu().numpy()\n","#     img = img.astype(np.uint8)\n","#     imgs.append(img)\n","#     axarr[p].imshow(img)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:21.012682Z","iopub.status.busy":"2022-12-30T08:23:21.012267Z","iopub.status.idle":"2022-12-30T08:23:21.020148Z","shell.execute_reply":"2022-12-30T08:23:21.019023Z","shell.execute_reply.started":"2022-12-30T08:23:21.012626Z"},"trusted":true},"outputs":[],"source":["\n","\n","class ModelNextVit(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.checkpoint = torch.load('nextvit_small_in1k_384.pth')\n","        self.backbone = nextvit_small()\n","        self.backbone.load_state_dict(self.checkpoint['model'])\n","        self.backbone.proj_head = nn.Linear(1024, 2)\n","\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        return x\n","\n","class PAM_Module(nn.Module):\n","    \"\"\" Position attention module\"\"\"\n","    #Ref from SAGAN\n","    def __init__(self, in_dim):\n","        super(PAM_Module, self).__init__()\n","        self.chanel_in = in_dim\n","\n","        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n","        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n","        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1)\n","        self.gamma = nn.Parameter(torch.zeros(1))\n","\n","    def forward(self, x):\n","        \"\"\"\n","            inputs :\n","                x : input feature maps( B X C X H X W)\n","            returns :\n","                out : attention value + input feature\n","                attention: B X (HxW) X (HxW)\n","        \"\"\"\n","        m_batchsize, C, height, width = x.size()\n","        proj_query = self.query_conv(x).view(m_batchsize, -1, width*height).permute(0, 2, 1)\n","        proj_key = self.key_conv(x).view(m_batchsize, -1, width*height)\n","        energy = torch.bmm(proj_query, proj_key)\n","        attention = torch.softmax(energy, dim=-1)\n","        proj_value = self.value_conv(x).view(m_batchsize, -1, width*height)\n","\n","        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n","        out = out.view(m_batchsize, C, height, width)\n","\n","        out = self.gamma*out + x\n","        return out\n","\n","\n","class CAM_Module(nn.Module):\n","    \"\"\" Channel attention module\"\"\"\n","    def __init__(self, in_dim):\n","        super(CAM_Module, self).__init__()\n","        self.chanel_in = in_dim\n","        self.gamma = nn.Parameter(torch.zeros(1))\n","\n","    def forward(self,x):\n","        \"\"\"\n","            inputs :\n","                x : input feature maps( B X C X H X W)\n","            returns :\n","                out : attention value + input feature\n","                attention: B X C X C\n","        \"\"\"\n","        m_batchsize, C, height, width = x.size()\n","        proj_query = x.view(m_batchsize, C, -1)\n","        proj_key = x.view(m_batchsize, C, -1).permute(0, 2, 1)\n","        energy = torch.bmm(proj_query, proj_key)\n","        energy_new = torch.max(energy, -1, keepdim=True)[0].expand_as(energy)-energy\n","        attention = torch.softmax(energy_new, dim=-1)\n","        proj_value = x.view(m_batchsize, C, -1)\n","\n","        out = torch.bmm(attention, proj_value)\n","        out = out.view(m_batchsize, C, height, width)\n","\n","        out = self.gamma*out + x\n","        return out\n","\n","\n","class CBAM(nn.Module):\n","    def __init__(self, in_channels):\n","        # def __init__(self):\n","        super(CBAM, self).__init__()\n","        inter_channels = in_channels // 4\n","        self.conv1_c = nn.Sequential(nn.Conv2d(in_channels, inter_channels, 3, padding=1, bias=False),\n","                                     nn.BatchNorm2d(inter_channels),\n","                                     nn.ReLU())\n","        \n","        self.conv1_s = nn.Sequential(nn.Conv2d(in_channels, inter_channels, 3, padding=1, bias=False),\n","                                     nn.BatchNorm2d(inter_channels),\n","                                     nn.ReLU())\n","\n","        self.channel_gate = CAM_Module(inter_channels)\n","        self.spatial_gate = PAM_Module(inter_channels)\n","\n","        self.conv2_c = nn.Sequential(nn.Conv2d(inter_channels, in_channels, 3, padding=1, bias=False),\n","                                     nn.BatchNorm2d(in_channels),\n","                                     nn.ReLU())\n","        self.conv2_a = nn.Sequential(nn.Conv2d(inter_channels, in_channels, 3, padding=1, bias=False),\n","                                     nn.BatchNorm2d(in_channels),\n","                                     nn.ReLU())\n","\n","    def forward(self, x):\n","        feat1 = self.conv1_c(x)\n","        chnl_att = self.channel_gate(feat1)\n","        chnl_att = self.conv2_c(chnl_att)\n","\n","        feat2 = self.conv1_s(x)\n","        spat_att = self.spatial_gate(feat2)\n","        spat_att = self.conv2_a(spat_att)\n","\n","        x_out = chnl_att + spat_att\n","\n","        return x_out\n","    \n","class Model(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(CFG.model_name, pretrained=True,drop_rate = 0.3, drop_path_rate = 0.2)\n","        self.fc = nn.Linear(self.backbone.classifier.in_features,2)\n","        self.dropout = nn.Dropout(0.5)\n","#         self.backbone.classifier = nn.Identity()\n","        n_features = 1408\n","        target_size = 2\n","        self.local_fe = CBAM(n_features)\n","        self.dropout = nn.Dropout(0.1)\n","        self.classifier = nn.Sequential(nn.Linear(n_features + n_features, n_features),\n","                                        nn.BatchNorm1d(n_features),\n","                                        nn.Dropout(0.1),\n","                                        nn.ReLU(),\n","                                        nn.Linear(n_features, target_size))\n","    def forward(self, x):\n","        enc_feas = self.backbone.forward_features(x)\n","        global_feas = F.adaptive_avg_pool2d(enc_feas, 1)\n","        global_feas = global_feas.reshape(-1, 1408)\n","        global_feas = self.dropout(global_feas)\n","#         print(global_feas.shape)\n","        local_feas = self.local_fe(enc_feas)\n","        local_feas = torch.sum(local_feas, dim=[2,3])\n","        local_feas = self.dropout(local_feas)\n","#         print(local_feas.shape)\n","        all_feas = torch.cat([global_feas, local_feas], dim=1)\n","#         print(all_feas.shape)\n","        x = self.classifier(all_feas)\n","#         x = self.fc(self.dropout(x))\n","        return x\n","\n","class ModelNfNet(nn.Module):\n","    def __init__(self, model_name='dm_nfnet_f0'):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(model_name, pretrained=True,drop_rate = 0.3, drop_path_rate = 0.2)\n","        self.fc = nn.Linear(self.backbone.head.fc.in_features,2)\n","        self.backbone.head.fc = nn.Identity()\n","        self.dropout = nn.Dropout(0.5)\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.fc(self.dropout(x))\n","        return x\n","\n","class SpatialAttention(nn.Module):\n","    def __init__(self, kernel_size=7):\n","        super(SpatialAttention, self).__init__()\n","\n","        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n","        padding = 3 if kernel_size == 7 else 1\n","\n","        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        avg_out = torch.mean(x, dim=1, keepdim=True)\n","        max_out, _ = torch.max(x, dim=1, keepdim=True)\n","        x = torch.cat([avg_out, max_out], dim=1)\n","        x = self.conv(x)\n","        return self.sigmoid(x)\n","\n","class ModelEffNetAttention(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(model_name, pretrained=True,drop_rate = 0.4, drop_path_rate = 0.2)\n","        self.attention = SpatialAttention()\n","        self.fc = nn.Linear(self.backbone.classifier.in_features,2)\n","        # self.backbone.classifier = nn.Identity()\n","        self.dropout = nn.Dropout(0.5)\n","    def forward(self, x):\n","        x = self.backbone.forward_features(x)\n","        att = self.attention(x)\n","        x = x*att\n","        x = self.backbone.global_pool(x)\n","        x = self.fc(self.dropout(x))\n","        return x\n","\n","class ModelOld(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(CFG.model_name, pretrained=True,drop_rate = 0.3, drop_path_rate = 0.2)\n","        self.fc = nn.Linear(self.backbone.classifier.in_features,2)\n","        self.dropout = nn.Dropout(0.5)\n","        self.backbone.classifier = nn.Identity()\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.fc(self.dropout(x))\n","        return x\n","    \n","class ModelOldOneClass(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(CFG.model_name, pretrained=True,drop_rate = 0.3, drop_path_rate = 0.2)\n","        self.fc = nn.Linear(self.backbone.classifier.in_features,1)\n","        self.dropout = nn.Dropout(0.5)\n","        self.backbone.classifier = nn.Identity()\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.fc(self.dropout(x))\n","        return x\n","\n","class ModelNew(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(CFG.model_name, pretrained=True,drop_rate = 0.4, drop_path_rate = 0.2)\n","        self.fc = nn.Linear(self.backbone.classifier.in_features,2)\n","        self.dropout = nn.Dropout(0.5)\n","        self.backbone.classifier = nn.Identity()\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.fc(self.dropout(x))\n","        return x\n","\n","class ModelNoDropRate(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(CFG.model_name, pretrained=True)\n","        self.fc = nn.Linear(self.backbone.classifier.in_features,2)\n","        self.dropout = nn.Dropout(0.5)\n","        self.backbone.classifier = nn.Identity()\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.fc(self.dropout(x))\n","        return x\n","\n","def gem(x, p=3, eps=1e-6):\n","    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1.0 / p)\n","\n","class GeM(nn.Module):\n","    def __init__(self, p=3, eps=1e-6):\n","        super(GeM, self).__init__()\n","        # if p_trainable:\n","        self.p = nn.Parameter(torch.ones(1) * p)\n","        # else:\n","            # self.p = p\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        ret = gem(x, p=self.p, eps=self.eps)\n","        return ret\n","\n","    def __repr__(self):\n","        return (self.__class__.__name__  + f\"(p={self.p.data.tolist()[0]:.4f},eps={self.eps})\")\n","\n","class ModelOneChannelAvgGem(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(CFG.model_name, pretrained=True, num_classes = 0, global_pool=\"\",in_chans = 1,drop_rate = 0.3, drop_path_rate = 0.2)\n","        self.fc = nn.Linear(1408,2)\n","        self.dropout = nn.Dropout(0.5)\n","        self.global_pool = GeM()\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.global_pool(x)\n","        x = x[:,:,0,0]\n","\n","        x = self.fc(self.dropout(x))\n","        return x\n","\n","class ModelOneChannelAvgPool(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(CFG.model_name, pretrained=True, in_chans = 1,drop_rate = 0.3, drop_path_rate = 0.2)\n","        self.fc = nn.Linear(1408,2)\n","        self.dropout = nn.Dropout(0.5)\n","        self.backbone.classifier = nn.Identity()\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.fc(self.dropout(x))\n","        return x\n","\n","class ModelThreeChannelAvgGem(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(CFG.model_name, pretrained=True, num_classes = 0, global_pool=\"\",in_chans = 3,drop_rate = 0.3, drop_path_rate = 0.2)\n","        self.fc = nn.Linear(1408,2)\n","        self.dropout = nn.Dropout(0.5)\n","        self.global_pool = GeM()\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.global_pool(x)\n","        x = x[:,:,0,0]\n","\n","        x = self.fc(self.dropout(x))\n","        return x\n","\n","class ModelThreeChannelAvgPool(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(CFG.model_name, pretrained=True, num_classes = 0, global_pool=\"\",in_chans = 3,drop_rate = 0.3, drop_path_rate = 0.2)\n","        self.fc = nn.Linear(1408,2)\n","        self.dropout = nn.Dropout(0.5)\n","        # self.backbone.classifier = nn.Identity()\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = F.adaptive_avg_pool2d(x, 1)\n","        x = x[:,:,0,0]\n","\n","        x = self.fc(self.dropout(x))\n","        return x\n","\n","class ModelCVN(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model('convnext_tiny', pretrained=True,drop_rate = 0.3, drop_path_rate = 0.2, num_classes = 0)\n","        self.fc = nn.Linear(768,2)\n","        self.dropout = nn.Dropout(0.5)\n","        self.backbone.fc = nn.Identity()\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.fc(self.dropout(x))\n","        return x\n","# inp = torch.rand(2,3, 1344, 840).to(CFG.device)\n","# model = ModelCVN(CFG.model_name).to(CFG.device)\n","# output = model(inp)\n","# print(output.shape)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:21.022923Z","iopub.status.busy":"2022-12-30T08:23:21.022147Z","iopub.status.idle":"2022-12-30T08:23:21.032555Z","shell.execute_reply":"2022-12-30T08:23:21.031346Z","shell.execute_reply.started":"2022-12-30T08:23:21.022887Z"},"trusted":true},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim.optimizer import Optimizer, required\n","import math\n","\n","class AdamP(Optimizer):\n","    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n","                 weight_decay=0, delta=0.1, wd_ratio=0.1, nesterov=False):\n","        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay,\n","                        delta=delta, wd_ratio=wd_ratio, nesterov=nesterov)\n","        super(AdamP, self).__init__(params, defaults)\n","\n","    def _channel_view(self, x):\n","        return x.view(x.size(0), -1)\n","\n","    def _layer_view(self, x):\n","        return x.view(1, -1)\n","\n","    def _cosine_similarity(self, x, y, eps, view_func):\n","        x = view_func(x)\n","        y = view_func(y)\n","\n","        return F.cosine_similarity(x, y, dim=1, eps=eps).abs_()\n","\n","    def _projection(self, p, grad, perturb, delta, wd_ratio, eps):\n","        wd = 1\n","        expand_size = [-1] + [1] * (len(p.shape) - 1)\n","        for view_func in [self._channel_view, self._layer_view]:\n","\n","            cosine_sim = self._cosine_similarity(grad, p.data, eps, view_func)\n","\n","            if cosine_sim.max() < delta / math.sqrt(view_func(p.data).size(1)):\n","                p_n = p.data / view_func(p.data).norm(dim=1).view(expand_size).add_(eps)\n","                perturb -= p_n * view_func(p_n * perturb).sum(dim=1).view(expand_size)\n","                wd = wd_ratio\n","\n","                return perturb, wd\n","\n","        return perturb, wd\n","\n","    def step(self, closure=None):\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","\n","                grad = p.grad.data\n","                beta1, beta2 = group['betas']\n","                nesterov = group['nesterov']\n","\n","                state = self.state[p]\n","\n","                # State initialization\n","                if len(state) == 0:\n","                    state['step'] = 0\n","                    state['exp_avg'] = torch.zeros_like(p.data)\n","                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n","\n","                # Adam\n","                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n","\n","                state['step'] += 1\n","                bias_correction1 = 1 - beta1 ** state['step']\n","                bias_correction2 = 1 - beta2 ** state['step']\n","\n","                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n","                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n","\n","                denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n","                step_size = group['lr'] / bias_correction1\n","\n","                if nesterov:\n","                    perturb = (beta1 * exp_avg + (1 - beta1) * grad) / denom\n","                else:\n","                    perturb = exp_avg / denom\n","\n","                # Projection\n","                wd_ratio = 1\n","                if len(p.shape) > 1:\n","                    perturb, wd_ratio = self._projection(p, grad, perturb, group['delta'], group['wd_ratio'], group['eps'])\n","\n","                # Weight decay\n","                if group['weight_decay'] > 0:\n","                    p.data.mul_(1 - group['lr'] * group['weight_decay'] * wd_ratio)\n","\n","                # Step\n","                p.data.add_(perturb, alpha=-step_size)\n","\n","        return loss\n","\n","class SGDP(Optimizer):\n","    def __init__(self, params, lr=required, momentum=0, dampening=0,\n","                 weight_decay=0, nesterov=False, eps=1e-8, delta=0.1, wd_ratio=0.1):\n","        defaults = dict(lr=lr, momentum=momentum, dampening=dampening, weight_decay=weight_decay,\n","                        nesterov=nesterov, eps=eps, delta=delta, wd_ratio=wd_ratio)\n","        super(SGDP, self).__init__(params, defaults)\n","\n","    def _channel_view(self, x):\n","        return x.view(x.size(0), -1)\n","\n","    def _layer_view(self, x):\n","        return x.view(1, -1)\n","\n","    def _cosine_similarity(self, x, y, eps, view_func):\n","        x = view_func(x)\n","        y = view_func(y)\n","\n","        return F.cosine_similarity(x, y, dim=1, eps=eps).abs_()\n","\n","    def _projection(self, p, grad, perturb, delta, wd_ratio, eps):\n","        wd = 1\n","        expand_size = [-1] + [1] * (len(p.shape) - 1)\n","        for view_func in [self._channel_view, self._layer_view]:\n","\n","            cosine_sim = self._cosine_similarity(grad, p.data, eps, view_func)\n","\n","            if cosine_sim.max() < delta / math.sqrt(view_func(p.data).size(1)):\n","                p_n = p.data / view_func(p.data).norm(dim=1).view(expand_size).add_(eps)\n","                perturb -= p_n * view_func(p_n * perturb).sum(dim=1).view(expand_size)\n","                wd = wd_ratio\n","\n","                return perturb, wd\n","\n","        return perturb, wd\n","\n","    def step(self, closure=None):\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","            momentum = group['momentum']\n","            dampening = group['dampening']\n","            nesterov = group['nesterov']\n","\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                grad = p.grad.data\n","                state = self.state[p]\n","\n","                # State initialization\n","                if len(state) == 0:\n","                    state['momentum'] = torch.zeros_like(p.data)\n","\n","                # SGD\n","                buf = state['momentum']\n","                buf.mul_(momentum).add_(grad, alpha=1 - dampening)\n","                if nesterov:\n","                    d_p = grad + momentum * buf\n","                else:\n","                    d_p = buf\n","\n","                # Projection\n","                wd_ratio = 1\n","                if len(p.shape) > 1:\n","                    d_p, wd_ratio = self._projection(p, grad, d_p, group['delta'], group['wd_ratio'], group['eps'])\n","\n","                # Weight decay\n","                if group['weight_decay'] > 0:\n","                    p.data.mul_(1 - group['lr'] * group['weight_decay'] * wd_ratio / (1-momentum))\n","\n","                # Step\n","                p.data.add_(d_p, alpha=-group['lr'])\n","\n","        return loss\n","\n","class SAM(torch.optim.Optimizer):\n","    def __init__(self, params, base_optimizer, rho=0.05, **kwargs):\n","        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n","\n","        defaults = dict(rho=rho, **kwargs)\n","        super(SAM, self).__init__(params, defaults)\n","\n","        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n","        self.param_groups = self.base_optimizer.param_groups\n","\n","    @torch.no_grad()\n","    def first_step(self, zero_grad=False):\n","        grad_norm = self._grad_norm()\n","        for group in self.param_groups:\n","            scale = group[\"rho\"] / (grad_norm + 1e-12)\n","\n","            for p in group[\"params\"]:\n","                if p.grad is None: continue\n","                e_w = p.grad * scale.to(p)\n","                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n","                self.state[p][\"e_w\"] = e_w\n","\n","        if zero_grad: self.zero_grad()\n","\n","    @torch.no_grad()\n","    def second_step(self, zero_grad=False):\n","        for group in self.param_groups:\n","            for p in group[\"params\"]:\n","                if p.grad is None: continue\n","                p.sub_(self.state[p][\"e_w\"])  # get back to \"w\" from \"w + e(w)\"\n","\n","        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n","\n","        if zero_grad: self.zero_grad()\n","\n","    def step(self, closure=None):\n","        raise NotImplementedError(\"SAM doesn't work like the other optimizers, you should first call `first_step` and the `second_step`; see the documentation for more info.\")\n","\n","    def _grad_norm(self):\n","        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n","        norm = torch.norm(\n","                    torch.stack([\n","                        p.grad.norm(p=2).to(shared_device)\n","                        for group in self.param_groups for p in group[\"params\"]\n","                        if p.grad is not None\n","                    ]),\n","                    p=2\n","               )\n","        return norm"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["from torch.optim.lr_scheduler import _LRScheduler\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","\n","class GradualWarmupScheduler(_LRScheduler):\n","    \"\"\" Gradually warm-up(increasing) learning rate in optimizer.\n","    Proposed in 'Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour'.\n","    Args:\n","        optimizer (Optimizer): Wrapped optimizer.\n","        multiplier: target learning rate = base lr * multiplier if multiplier > 1.0. if multiplier = 1.0, lr starts from 0 and ends up with the base_lr.\n","        total_epoch: target learning rate is reached at total_epoch, gradually\n","        after_scheduler: after target_epoch, use this scheduler(eg. ReduceLROnPlateau)\n","    \"\"\"\n","\n","    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n","        self.multiplier = multiplier\n","        if self.multiplier < 1.:\n","            raise ValueError('multiplier should be greater thant or equal to 1.')\n","        self.total_epoch = total_epoch\n","        self.after_scheduler = after_scheduler\n","        self.finished = False\n","        super(GradualWarmupScheduler, self).__init__(optimizer)\n","\n","    def get_lr(self):\n","        if self.last_epoch > self.total_epoch:\n","            if self.after_scheduler:\n","                if not self.finished:\n","                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n","                    self.finished = True\n","                return self.after_scheduler.get_last_lr()\n","            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n","\n","        if self.multiplier == 1.0:\n","            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n","        else:\n","            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n","\n","    def step_ReduceLROnPlateau(self, metrics, epoch=None):\n","        if epoch is None:\n","            epoch = self.last_epoch + 1\n","        self.last_epoch = epoch if epoch != 0 else 1  # ReduceLROnPlateau is called at the end of epoch, whereas others are called at beginning\n","        if self.last_epoch <= self.total_epoch:\n","            warmup_lr = [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n","            for param_group, lr in zip(self.optimizer.param_groups, warmup_lr):\n","                param_group['lr'] = lr\n","        else:\n","            if epoch is None:\n","                self.after_scheduler.step(metrics, None)\n","            else:\n","                self.after_scheduler.step(metrics, epoch - self.total_epoch)\n","\n","    def step(self, epoch=None, metrics=None):\n","        if type(self.after_scheduler) != ReduceLROnPlateau:\n","            if self.finished and self.after_scheduler:\n","                if epoch is None:\n","                    self.after_scheduler.step(None)\n","                else:\n","                    self.after_scheduler.step(epoch - self.total_epoch)\n","                self._last_lr = self.after_scheduler.get_last_lr()\n","            else:\n","                return super(GradualWarmupScheduler, self).step(epoch)\n","        else:\n","            self.step_ReduceLROnPlateau(metrics, epoch)\n","\n","class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n","    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n","        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n","    def get_lr(self):\n","        if self.last_epoch > self.total_epoch:\n","            if self.after_scheduler:\n","                if not self.finished:\n","                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n","                    self.finished = True\n","                return self.after_scheduler.get_lr()\n","            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n","        if self.multiplier == 1.0:\n","            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n","        else:\n","            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n","\n","class Lookahead(optim.Optimizer):\n","    def __init__(self, base_optimizer, alpha=0.5, k=6):\n","        if not 0.0 <= alpha <= 1.0:\n","            raise ValueError(f'Invalid slow update rate: {alpha}')\n","        if not 1 <= k:\n","            raise ValueError(f'Invalid lookahead steps: {k}')\n","        defaults = dict(lookahead_alpha=alpha, lookahead_k=k, lookahead_step=0)\n","        self.base_optimizer = base_optimizer\n","        self.param_groups = self.base_optimizer.param_groups\n","        self.defaults = base_optimizer.defaults\n","        self.defaults.update(defaults)\n","        self.state = defaultdict(dict)\n","        # manually add our defaults to the param groups\n","        for name, default in defaults.items():\n","            for group in self.param_groups:\n","                group.setdefault(name, default)\n","\n","    def update_slow(self, group):\n","        for fast_p in group[\"params\"]:\n","            if fast_p.grad is None:\n","                continue\n","            param_state = self.state[fast_p]\n","            if 'slow_buffer' not in param_state:\n","                param_state['slow_buffer'] = torch.empty_like(fast_p.data)\n","                param_state['slow_buffer'].copy_(fast_p.data)\n","            slow = param_state['slow_buffer']\n","            slow.add_(group['lookahead_alpha'], fast_p.data - slow)\n","            fast_p.data.copy_(slow)\n","\n","    def sync_lookahead(self):\n","        for group in self.param_groups:\n","            self.update_slow(group)\n","\n","    def step(self, closure=None):\n","        #assert id(self.param_groups) == id(self.base_optimizer.param_groups)\n","        loss = self.base_optimizer.step(closure)\n","        for group in self.param_groups:\n","            group['lookahead_step'] += 1\n","            if group['lookahead_step'] % group['lookahead_k'] == 0:\n","                self.update_slow(group)\n","        return loss\n","\n","    def state_dict(self):\n","        fast_state_dict = self.base_optimizer.state_dict()\n","        slow_state = {\n","            (id(k) if isinstance(k, torch.Tensor) else k): v\n","            for k, v in self.state.items()\n","        }\n","        fast_state = fast_state_dict['state']\n","        param_groups = fast_state_dict['param_groups']\n","        return {\n","            'state': fast_state,\n","            'slow_state': slow_state,\n","            'param_groups': param_groups,\n","        }\n","\n","    def load_state_dict(self, state_dict):\n","        fast_state_dict = {\n","            'state': state_dict['state'],\n","            'param_groups': state_dict['param_groups'],\n","        }\n","        self.base_optimizer.load_state_dict(fast_state_dict)\n","\n","        # We want to restore the slow state, but share param_groups reference\n","        # with base_optimizer. This is a bit redundant but least code\n","        slow_state_new = False\n","        if 'slow_state' not in state_dict:\n","            print('Loading state_dict from optimizer without Lookahead applied.')\n","            state_dict['slow_state'] = defaultdict(dict)\n","            slow_state_new = True\n","        slow_state_dict = {\n","            'state': state_dict['slow_state'],\n","            'param_groups': state_dict['param_groups'],  # this is pointless but saves code\n","        }\n","        super(Lookahead, self).load_state_dict(slow_state_dict)\n","        self.param_groups = self.base_optimizer.param_groups  # make both ref same container\n","        if slow_state_new:\n","            # reapply defaults to catch missing lookahead specific ones\n","            for name, default in self.defaults.items():\n","                for group in self.param_groups:\n","                    group.setdefault(name, default)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def log_t(u, t):\n","    \"\"\"Compute log_t for `u'.\"\"\"\n","    if t==1.0:\n","        return u.log()\n","    else:\n","        return (u.pow(1.0 - t) - 1.0) / (1.0 - t)\n","\n","def exp_t(u, t):\n","    \"\"\"Compute exp_t for `u'.\"\"\"\n","    if t==1:\n","        return u.exp()\n","    else:\n","        return (1.0 + (1.0-t)*u).relu().pow(1.0 / (1.0 - t))\n","\n","def compute_normalization_fixed_point(activations, t, num_iters):\n","\n","    \"\"\"Returns the normalization value for each example (t > 1.0).\n","    Args:\n","      activations: A multi-dimensional tensor with last dimension `num_classes`.\n","      t: Temperature 2 (> 1.0 for tail heaviness).\n","      num_iters: Number of iterations to run the method.\n","    Return: A tensor of same shape as activation with the last dimension being 1.\n","    \"\"\"\n","    mu, _ = torch.max(activations, -1, keepdim=True)\n","    normalized_activations_step_0 = activations - mu\n","\n","    normalized_activations = normalized_activations_step_0\n","\n","    for _ in range(num_iters):\n","        logt_partition = torch.sum(\n","                exp_t(normalized_activations, t), -1, keepdim=True)\n","        normalized_activations = normalized_activations_step_0 * \\\n","                logt_partition.pow(1.0-t)\n","\n","    logt_partition = torch.sum(\n","            exp_t(normalized_activations, t), -1, keepdim=True)\n","    normalization_constants = - log_t(1.0 / logt_partition, t) + mu\n","\n","    return normalization_constants\n","\n","def compute_normalization_binary_search(activations, t, num_iters):\n","\n","    \"\"\"Returns the normalization value for each example (t < 1.0).\n","    Args:\n","      activations: A multi-dimensional tensor with last dimension `num_classes`.\n","      t: Temperature 2 (< 1.0 for finite support).\n","      num_iters: Number of iterations to run the method.\n","    Return: A tensor of same rank as activation with the last dimension being 1.\n","    \"\"\"\n","\n","    mu, _ = torch.max(activations, -1, keepdim=True)\n","    normalized_activations = activations - mu\n","\n","    effective_dim = \\\n","        torch.sum(\n","                (normalized_activations > -1.0 / (1.0-t)).to(torch.int32),\n","            dim=-1, keepdim=True).to(activations.dtype)\n","\n","    shape_partition = activations.shape[:-1] + (1,)\n","    lower = torch.zeros(shape_partition, dtype=activations.dtype, device=activations.device)\n","    upper = -log_t(1.0/effective_dim, t) * torch.ones_like(lower)\n","\n","    for _ in range(num_iters):\n","        logt_partition = (upper + lower)/2.0\n","        sum_probs = torch.sum(\n","                exp_t(normalized_activations - logt_partition, t),\n","                dim=-1, keepdim=True)\n","        update = (sum_probs < 1.0).to(activations.dtype)\n","        lower = torch.reshape(\n","                lower * update + (1.0-update) * logt_partition,\n","                shape_partition)\n","        upper = torch.reshape(\n","                upper * (1.0 - update) + update * logt_partition,\n","                shape_partition)\n","\n","    logt_partition = (upper + lower)/2.0\n","    return logt_partition + mu\n","\n","class ComputeNormalization(torch.autograd.Function):\n","    \"\"\"\n","    Class implementing custom backward pass for compute_normalization. See compute_normalization.\n","    \"\"\"\n","    @staticmethod\n","    def forward(ctx, activations, t, num_iters):\n","        if t < 1.0:\n","            normalization_constants = compute_normalization_binary_search(activations, t, num_iters)\n","        else:\n","            normalization_constants = compute_normalization_fixed_point(activations, t, num_iters)\n","\n","        ctx.save_for_backward(activations, normalization_constants)\n","        ctx.t=t\n","        return normalization_constants\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        activations, normalization_constants = ctx.saved_tensors\n","        t = ctx.t\n","        normalized_activations = activations - normalization_constants \n","        probabilities = exp_t(normalized_activations, t)\n","        escorts = probabilities.pow(t)\n","        escorts = escorts / escorts.sum(dim=-1, keepdim=True)\n","        grad_input = escorts * grad_output\n","        \n","        return grad_input, None, None\n","\n","def compute_normalization(activations, t, num_iters=5):\n","    \"\"\"Returns the normalization value for each example. \n","    Backward pass is implemented.\n","    Args:\n","      activations: A multi-dimensional tensor with last dimension `num_classes`.\n","      t: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n","      num_iters: Number of iterations to run the method.\n","    Return: A tensor of same rank as activation with the last dimension being 1.\n","    \"\"\"\n","    return ComputeNormalization.apply(activations, t, num_iters)\n","\n","def tempered_sigmoid(activations, t, num_iters = 5):\n","    \"\"\"Tempered sigmoid function.\n","    Args:\n","      activations: Activations for the positive class for binary classification.\n","      t: Temperature tensor > 0.0.\n","      num_iters: Number of iterations to run the method.\n","    Returns:\n","      A probabilities tensor.\n","    \"\"\"\n","    internal_activations = torch.stack([activations,\n","        torch.zeros_like(activations)],\n","        dim=-1)\n","    internal_probabilities = tempered_softmax(internal_activations, t, num_iters)\n","    return internal_probabilities[..., 0]\n","\n","\n","def tempered_softmax(activations, t, num_iters=5):\n","    \"\"\"Tempered softmax function.\n","    Args:\n","      activations: A multi-dimensional tensor with last dimension `num_classes`.\n","      t: Temperature > 1.0.\n","      num_iters: Number of iterations to run the method.\n","    Returns:\n","      A probabilities tensor.\n","    \"\"\"\n","    if t == 1.0:\n","        return activations.softmax(dim=-1)\n","\n","    normalization_constants = compute_normalization(activations, t, num_iters)\n","    return exp_t(activations - normalization_constants, t)\n","\n","def bi_tempered_binary_logistic_loss(activations,\n","        labels,\n","        t1,\n","        t2,\n","        label_smoothing = 0.0,\n","        num_iters=5,\n","        reduction='mean'):\n","\n","    \"\"\"Bi-Tempered binary logistic loss.\n","    Args:\n","      activations: A tensor containing activations for class 1.\n","      labels: A tensor with shape as activations, containing probabilities for class 1\n","      t1: Temperature 1 (< 1.0 for boundedness).\n","      t2: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n","      label_smoothing: Label smoothing\n","      num_iters: Number of iterations to run the method.\n","    Returns:\n","      A loss tensor.\n","    \"\"\"\n","    internal_activations = torch.stack([activations,\n","        torch.zeros_like(activations)],\n","        dim=-1)\n","    internal_labels = torch.stack([labels.to(activations.dtype),\n","        1.0 - labels.to(activations.dtype)],\n","        dim=-1)\n","    return bi_tempered_logistic_loss(internal_activations, \n","            internal_labels,\n","            t1,\n","            t2,\n","            label_smoothing = label_smoothing,\n","            num_iters = num_iters,\n","            reduction = reduction)\n","\n","def bi_tempered_logistic_loss(activations,\n","        labels,\n","        t1,\n","        t2,\n","        label_smoothing=0.0,\n","        num_iters=5,\n","        reduction = 'mean'):\n","\n","    \"\"\"Bi-Tempered Logistic Loss.\n","    Args:\n","      activations: A multi-dimensional tensor with last dimension `num_classes`.\n","      labels: A tensor with shape and dtype as activations (onehot), \n","        or a long tensor of one dimension less than activations (pytorch standard)\n","      t1: Temperature 1 (< 1.0 for boundedness).\n","      t2: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n","      label_smoothing: Label smoothing parameter between [0, 1). Default 0.0.\n","      num_iters: Number of iterations to run the method. Default 5.\n","      reduction: ``'none'`` | ``'mean'`` | ``'sum'``. Default ``'mean'``.\n","        ``'none'``: No reduction is applied, return shape is shape of\n","        activations without the last dimension.\n","        ``'mean'``: Loss is averaged over minibatch. Return shape (1,)\n","        ``'sum'``: Loss is summed over minibatch. Return shape (1,)\n","    Returns:\n","      A loss tensor.\n","    \"\"\"\n","\n","    if len(labels.shape)<len(activations.shape): #not one-hot\n","        labels_onehot = torch.zeros_like(activations)\n","        labels_onehot.scatter_(1, labels[..., None], 1)\n","    else:\n","        labels_onehot = labels\n","\n","    if label_smoothing > 0:\n","        num_classes = labels_onehot.shape[-1]\n","        labels_onehot = ( 1 - label_smoothing * num_classes / (num_classes - 1) ) \\\n","                * labels_onehot + \\\n","                label_smoothing / (num_classes - 1)\n","\n","    probabilities = tempered_softmax(activations, t2, num_iters)\n","\n","    loss_values = labels_onehot * log_t(labels_onehot + 1e-10, t1) \\\n","            - labels_onehot * log_t(probabilities, t1) \\\n","            - labels_onehot.pow(2.0 - t1) / (2.0 - t1) \\\n","            + probabilities.pow(2.0 - t1) / (2.0 - t1)\n","    loss_values = loss_values.sum(dim = -1) #sum over classes\n","\n","    if reduction == 'none':\n","        return loss_values\n","    if reduction == 'sum':\n","        return loss_values.sum()\n","    if reduction == 'mean':\n","        return loss_values.mean()\n","\n","class BiTemperedLogisticLoss(nn.Module): \n","    def __init__(self, t1, t2, smoothing=0.0): \n","        super(BiTemperedLogisticLoss, self).__init__() \n","        self.t1 = t1\n","        self.t2 = t2\n","        self.smoothing = smoothing\n","    def forward(self, logit_label, truth_label):\n","        loss_label = bi_tempered_logistic_loss(\n","            logit_label, truth_label,\n","            t1=self.t1, t2=self.t2,\n","            label_smoothing=self.smoothing,\n","            reduction='none'\n","        )\n","        \n","        loss_label = loss_label.mean()\n","        return loss_label"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:21.036233Z","iopub.status.busy":"2022-12-30T08:23:21.035928Z","iopub.status.idle":"2022-12-30T08:23:21.059619Z","shell.execute_reply":"2022-12-30T08:23:21.058523Z","shell.execute_reply.started":"2022-12-30T08:23:21.036197Z"},"trusted":true},"outputs":[],"source":["\n","def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    # switch to train mode\n","    model.train()\n","    start = end = time.time()\n","    truth = []\n","    pred = []\n","    global_step = 0\n","    scaler = GradScaler()\n","    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc='Train')\n","    for step, (images, labels) in pbar:\n","        optimizer.zero_grad()\n","        data_time.update(time.time() - end)\n","        images = images.to(device)\n","        \n","        \n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with autocast(enabled=True):\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            # loss.backward()\n","            # optimizer.first_step(zero_grad=True)\n","            # criterion(model(images), labels).backward()\n","            # optimizer.second_step(zero_grad=True)\n","            # record loss\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        # global_step += 1\n","        scheduler.step()\n","            # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        # if step % 4 == 0 or step == (len(train_loader)-1):\n","        #     print('Epoch: [{0}][{1}/{2}] '\n","        #               'Data {data_time.val:.6f} ({data_time.avg:.6f}) '\n","        #               'Elapsed {remain:s} '\n","        #               'Loss: {loss.val:.6f}({loss.avg:.6f}) '\n","        #               'LR: {lr:.6f}  '\n","        #               .format(\n","        #                epoch+1, step, len(train_loader), batch_time=batch_time,\n","        #                data_time=data_time, loss=losses,\n","        #                remain=timeSince(start, float(step+1)/len(train_loader)),\n","        #                lr=scheduler.get_lr()[0],\n","        #                ))\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","        current_lr = optimizer.param_groups[0]['lr']\n","        pbar.set_postfix(train_loss=f'{losses.avg:0.4f}',\n","                        lr=f'{current_lr:0.8f}',\n","                        gpu_mem=f'{mem:0.2f} GB')\n","\n","    return losses.avg\n","\n","def valid_fn_no_sigmoid(val_dataloader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    truth = []\n","    preds = []\n","    valid_labels = []\n","    start = end = time.time()\n","    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n","    for step, (images, labels) in pbar:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            outputs = model(images)\n","        valid_labels.append(labels.cpu().numpy())\n","        loss = criterion(outputs, labels)\n","#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n","        losses.update(loss.item(), batch_size)\n","#         print(outputs)\n","        preds.append((outputs).to('cpu').numpy())\n","        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n","                        gpu_mem=f'{mem:0.2f} GB')\n","    predictions = np.concatenate(preds)\n","    valid_labels = np.concatenate(valid_labels)\n","    return losses.avg, predictions, valid_labels\n","\n","\n","def valid_fn(val_dataloader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    truth = []\n","    preds = []\n","    valid_labels = []\n","    start = end = time.time()\n","    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n","    for step, (images, labels) in pbar:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            outputs = model(images)\n","        valid_labels.append(labels.cpu().numpy())\n","        loss = criterion(outputs, labels)\n","#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n","        losses.update(loss.item(), batch_size)\n","#         print(outputs)\n","        preds.append(torch.sigmoid(outputs).to('cpu').numpy())\n","        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n","                        gpu_mem=f'{mem:0.2f} GB')\n","    predictions = np.concatenate(preds)\n","    valid_labels = np.concatenate(valid_labels)\n","    return losses.avg, predictions, valid_labels\n","def valid_fn_two(val_dataloader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    truth = []\n","    preds = []\n","    valid_labels = []\n","    start = end = time.time()\n","    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n","    for step, (images, labels) in pbar:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            outputs = model(images)\n","        valid_labels.append(labels.cpu().numpy())\n","        loss = criterion(outputs, labels)\n","#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n","        losses.update(loss.item(), batch_size)\n","#         print(outputs)\n","        preds.append(F.softmax(outputs).to('cpu').numpy())\n","        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n","                        gpu_mem=f'{mem:0.2f} GB')\n","    predictions = np.concatenate(preds)\n","    valid_labels = np.concatenate(valid_labels)\n","    return losses.avg, predictions, valid_labels\n","\n","def valid_fn_two_flip(val_dataloader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    truth = []\n","    preds = []\n","    valid_labels = []\n","    start = end = time.time()\n","    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n","    for step, (images, labels) in pbar:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        images = torch.flip(images, [3])\n","        with torch.no_grad():\n","            outputs = model(images)\n","        valid_labels.append(labels.cpu().numpy())\n","        loss = criterion(outputs, labels)\n","#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n","        losses.update(loss.item(), batch_size)\n","#         print(outputs)\n","        preds.append(F.softmax(outputs).to('cpu').numpy())\n","        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n","                        gpu_mem=f'{mem:0.2f} GB')\n","    predictions = np.concatenate(preds)\n","    valid_labels = np.concatenate(valid_labels)\n","    return losses.avg, predictions, valid_labels\n","\n","def valid_fn_flip(val_dataloader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    truth = []\n","    preds = []\n","    valid_labels = []\n","    start = end = time.time()\n","    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n","    for step, (images, labels) in pbar:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        images = torch.flip(images, [3])\n","        with torch.no_grad():\n","            outputs = model(images)\n","        valid_labels.append(labels.cpu().numpy())\n","        loss = criterion(outputs, labels)\n","#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n","        losses.update(loss.item(), batch_size)\n","#         print(outputs)\n","        preds.append(torch.sigmoid(outputs).to('cpu').numpy())\n","        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n","                        gpu_mem=f'{mem:0.2f} GB')\n","    predictions = np.concatenate(preds)\n","    valid_labels = np.concatenate(valid_labels)\n","    return losses.avg, predictions, valid_labels"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:32:56.198968Z","iopub.status.busy":"2022-12-30T08:32:56.198538Z","iopub.status.idle":"2022-12-30T08:38:54.946641Z","shell.execute_reply":"2022-12-30T08:38:54.945288Z","shell.execute_reply.started":"2022-12-30T08:32:56.198933Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["seed: 1\n","5 fold\n","Fold: 2\n","Model name: tf_efficientnetv2_b2\n","Len train df: 46421\n","Len valid df: 11012\n"]},{"name":"stdout","output_type":"stream","text":["> SEEDING DONE\n"]},{"name":"stderr","output_type":"stream","text":["Train bs: 16\n","ModelOld\n","optimizer: AdamW (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    eps: 1e-08\n","    foreach: None\n","    initial_lr: 0.0001\n","    lr: 0.0\n","    maximize: False\n","    weight_decay: 0.0004\n",")\n","total_epoch :15\n","Warmup: 1\n"]}],"source":["\n","def pfbeta(labels, predictions, beta=1):\n","    y_true_count = 0\n","    ctp = 0\n","    cfp = 0\n","\n","    for idx in range(len(labels)):\n","        prediction = min(max(predictions[idx], 0), 1)\n","        if (labels[idx]):\n","            y_true_count += 1\n","            ctp += prediction\n","        else:\n","            cfp += prediction\n","\n","    beta_squared = beta * beta\n","    c_precision = ctp / (ctp + cfp)\n","    c_recall = ctp / y_true_count\n","    if (c_precision > 0 and c_recall > 0):\n","        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n","        return result\n","    else:\n","        return 0\n","\n","def pfbeta_np(labels, preds, beta=1):\n","    preds = preds.clip(0, 1)\n","    y_true_count = labels.sum()\n","    ctp = preds[labels==1].sum()\n","    cfp = preds[labels==0].sum()\n","    beta_squared = beta * beta\n","    c_precision = ctp / (ctp + cfp)\n","    c_recall = ctp / y_true_count\n","    if (c_precision > 0 and c_recall > 0):\n","        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n","        return result\n","    else:\n","        return 0.0\n","    \n","def dfs_freeze(module):\n","    for param in module.parameters():\n","        param.requires_grad = False\n","        \n","def dfs_unfreeze(module):\n","    for param in module.parameters():\n","        param.requires_grad = True\n","    \n","def set_seed(seed = 42):\n","    '''Sets the seed of the entire notebook so results are the same every time we run.\n","    This is for REPRODUCIBILITY.'''\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    # When running on the CuDNN backend, two further options must be set\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    # Set a fixed value for the hash seed\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    print('> SEEDING DONE')\n","\n","def valid_fn_two(val_dataloader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n","    for step, (images, labels) in pbar:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            with autocast(enabled=True):\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n","        losses.update(loss.item(), batch_size)\n","#         print(outputs)\n","        preds.append(F.softmax(outputs).to('cpu').numpy())\n","        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n","                        gpu_mem=f'{mem:0.2f} GB')\n","    predictions = np.concatenate(preds)\n","    return losses.avg, predictions\n","#always seed1, change seed now\n","# set_seed(1)\n","seed = 1\n","LOGGER.info(f\"seed: {seed}\")\n","set_seed(seed)\n","gc.collect()\n","torch.cuda.empty_cache()\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","for fold in [2]:\n","    # LOGGER.info(\"New dataset\")\n","    # LOGGER.info(\"site 1\")\n","    LOGGER.info(\"5 fold\")\n","    LOGGER.info(f\"Fold: {fold}\")\n","    LOGGER.info(f\"Model name: {CFG.model_name}\")\n","    # model = ModelNfNet().to(device)\n","    # model = ModelEffNetAttention(model_name=CFG.model_name).to(device)\n","    # model = ModelOneChannelAvgGem(model_name=CFG.model_name).to(CFG.device)\n","    \n","    # model = ModelVIT().to(CFG.device)\n","    train_df = df1[df1['fold']!=fold].reset_index(drop=True)\n","    # train_df = train_df[train_df['site_id']==1].reset_index(drop=True)\n","    valid_df = df[df['fold']==fold].reset_index(drop=True)\n","    # valid_df = valid_df[valid_df['site_id']==1].reset_index(drop=True)\n","    # print(len(valid_df))\n","    LOGGER.info(f\"Len train df: {len(train_df)}\")\n","    LOGGER.info(f\"Len valid df: {len(valid_df)}\")\n","    train_dataset = BreastDataset(train_df, transforms=data_transforms['train'])\n","\n","    train_loader = DataLoader(train_dataset, batch_size = CFG.train_bs,\n","                                  num_workers=1, shuffle=True, drop_last=True)\n","    \n","    valid_dataset = BreastDataset(valid_df, transforms=data_transforms['valid'])\n","\n","    valid_loader = DataLoader(valid_dataset, batch_size = CFG.valid_bs, \n","                                  num_workers=1, shuffle=False, drop_last=False)\n","    # model = Model(model_name=CFG.model_name).to(device)\n","    LEN_DL_TRAIN = len(train_loader)\n","    best_f1 = 0\n","    best_metric = 0\n","    total_epoch = 15\n","    warmup = 1\n","    model = ModelOld(model_name=CFG.model_name).to(device)\n","    # model = ModelCVN(model_name=CFG.model_name).to(device)\n","    # checkpoint = torch.load(\"swa_tf_efficientnetv2_b2_fold_1_model_0.5128_0.3670.pth\")\n","    # model.load_state_dict(checkpoint['state_dict'])\n","    optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-4, weight_decay = 4e-4)\n","    # optimizer = Lion(model.parameters(), lr = 1e-5, weight_decay = 5e-4)\n","    # optimizer.load_state_dict(checkpoint['optimizer'])\n","    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps = warmup*LEN_DL_TRAIN, num_training_steps =total_epoch*LEN_DL_TRAIN)\n","    # scheduler = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n","    # scheduler.load_state_dict(checkpoint['scheduler'])\n","    # criterion = nn.BCEWithLogitsLoss().to(CFG.device)\n","    criterion = nn.CrossEntropyLoss().to(CFG.device)\n","    LOGGER.info(f\"Train bs: {CFG.train_bs}\")\n","    # LOGGER.info(f\"Model: {model}\")\n","    LOGGER.info(f\"{model.__class__.__name__}\")\n","    LOGGER.info(f\"optimizer: {optimizer}\")\n","    LOGGER.info(f\"total_epoch :{total_epoch}\")\n","    LOGGER.info(f\"Warmup: {warmup}\")\n","    # for epoch in range(1, total_epoch+1):\n","    #     LOGGER.info(f\"Epoch: {epoch}/{total_epoch}\")\n","    #     loss_train = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, CFG.device)\n","    #     loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","    #     # loss_train, train_preds = valid_fn_two(train_loader, model, criterion, CFG.device)\n","    #     # loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","    #     valid_preds = valid_preds[:, 1]\n","    #     valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n","    #     valid_preds = np.array(valid_preds).flatten()\n","        \n","    #     valid_df['raw_pred'] = valid_preds\n","    #     # LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n","    #     LOGGER.info(f\"Train loss:{loss_train:.4f}, Valid loss:{loss_valid:.4f}\")\n","    #     grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n","    #     grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n","    #     valid_labels_mean = grp_df['cancer'].values\n","    #     valid_preds_mean = grp_df['raw_pred'].values\n","    #     # print(valid_labels[:5], valid_preds_mean[:5])\n","    #     val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n","    #     LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n","    #     best_metric_mean_at_epoch = 0\n","    #     best_metric1 = 0\n","    #     best_threshold_mean = 0\n","    #     best_auc = 0\n","    #     best_cf = None\n","    #     for i in np.arange(0.001, 0.599, 0.001):\n","    #         valid_argmax = (valid_preds_mean>i).astype(np.int32)\n","    # #             print(valid_argmax)\n","    #         # val_metric = pfbeta(valid_labels_mean, valid_argmax)\n","    #         val_metric1 = pfbeta_np(valid_labels_mean, valid_argmax)\n","    #         val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n","    #         val_f1 = f1_score(valid_labels_mean, valid_argmax)\n","    #         val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n","    #         cf = confusion_matrix(valid_labels_mean, valid_argmax)\n","    #         if val_metric1> best_metric1:\n","    #             best_metric1 = val_metric1\n","    #             # best_metric_mean_at_epoch = val_metric\n","    #             best_threshold_mean = i\n","    #             best_auc = val_auc\n","    #             best_cf = cf\n","    #     LOGGER.info(f\"Best metric at epoch {epoch}: {best_metric1:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n","    #     LOGGER.info(f\"Cf: {best_cf}\")\n","    #     if best_metric1> best_metric:\n","\n","    #         LOGGER.info(f\"Model improve: {best_metric:.4f} -> {best_metric1:.4f}\")\n","    #         best_metric = best_metric1\n","    #     state = {'epoch': epoch, 'state_dict': model.state_dict()}\n","    #     # state = {'epoch': epoch, 'state_dict': model.state_dict(),'optimizer': optimizer.state_dict(), 'scheduler':scheduler.state_dict()}\n","    #     path = f'fold{fold}/{CFG.model_name}_fold_{fold}_model_epoch_{epoch}_{best_metric1:.4f}_{best_threshold_mean:.3f}.pth'\n","    #     torch.save(state, path)\n","\n","        "]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["# for fold in [0]:\n","#     valid_df = df[df['fold']==fold].reset_index(drop=True)   \n","#     valid_dataset = BreastDataset(valid_df, transforms=data_transforms['valid'])\n","\n","#     valid_loader = DataLoader(valid_dataset, batch_size = CFG.valid_bs, \n","#                                   num_workers=1, shuffle=False, drop_last=False)\n","#     # model = Model(model_name=CFG.model_name).to(device)\n","#     LEN_DL_TRAIN = len(train_loader)\n","#     best_f1 = 0\n","#     best_metric = 0\n","#     total_epoch = 15\n","#     warmup = 1\n","#     model = ModelOld(model_name=CFG.model_name).to(device)\n","#     checkpoint = torch.load(\"foldsensemble/swa_tf_efficientnetv2_b2_fold_0_model_0.5269_0.3540.pth\")\n","#     model.load_state_dict(checkpoint['state_dict'])\n","#     for epoch in range(1, 2):\n","#         LOGGER.info(f\"Epoch: {epoch}/{total_epoch}\")\n","#         loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","#         # loss_train, train_preds = valid_fn_two(train_loader, model, criterion, CFG.device)\n","#         # loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","#         valid_preds = valid_preds[:, 1]\n","#         valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n","#         valid_preds = np.array(valid_preds).flatten()\n","        \n","#         valid_df['raw_pred'] = valid_preds"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["# for fold in [1]:\n","#     valid_df1 = df[df['fold']==fold].reset_index(drop=True)   \n","#     valid_dataset = BreastDataset(valid_df1, transforms=data_transforms['valid'])\n","\n","#     valid_loader = DataLoader(valid_dataset, batch_size = CFG.valid_bs, \n","#                                   num_workers=1, shuffle=False, drop_last=False)\n","#     # model = Model(model_name=CFG.model_name).to(device)\n","#     LEN_DL_TRAIN = len(train_loader)\n","#     best_f1 = 0\n","#     best_metric = 0\n","#     total_epoch = 15\n","#     warmup = 1\n","#     model = ModelOld(model_name=CFG.model_name).to(device)\n","#     checkpoint = torch.load(\"swa_tf_efficientnetv2_b2_fold_1_model_0.5078_0.3050.pth\")\n","#     model.load_state_dict(checkpoint['state_dict'])\n","#     for epoch in range(1, 2):\n","#         LOGGER.info(f\"Epoch: {epoch}/{total_epoch}\")\n","#         loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","#         # loss_train, train_preds = valid_fn_two(train_loader, model, criterion, CFG.device)\n","#         # loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","#         valid_preds = valid_preds[:, 1]\n","#         valid_df1['prediction_id'] = valid_df1['patient_id'].astype(str) + '_' + valid_df1['laterality'].astype(str)\n","#         valid_preds = np.array(valid_preds).flatten()\n","        \n","#         valid_df1['raw_pred'] = valid_preds"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["# for fold in [2]:\n","#     valid_df2 = df[df['fold']==fold].reset_index(drop=True)   \n","#     valid_dataset = BreastDataset(valid_df2, transforms=data_transforms['valid'])\n","\n","#     valid_loader = DataLoader(valid_dataset, batch_size = CFG.valid_bs, \n","#                                   num_workers=1, shuffle=False, drop_last=False)\n","#     # model = Model(model_name=CFG.model_name).to(device)\n","#     LEN_DL_TRAIN = len(train_loader)\n","#     best_f1 = 0\n","#     best_metric = 0\n","#     total_epoch = 15\n","#     warmup = 1\n","#     model = ModelOld(model_name=CFG.model_name).to(device)\n","#     checkpoint = torch.load(\"foldsensemble/swa_tf_efficientnetv2_b2_fold_2_model_0.5281_0.454.pth\")\n","#     model.load_state_dict(checkpoint['state_dict'])\n","#     for epoch in range(1, 2):\n","#         LOGGER.info(f\"Epoch: {epoch}/{total_epoch}\")\n","#         loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","#         # loss_train, train_preds = valid_fn_two(train_loader, model, criterion, CFG.device)\n","#         # loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","#         valid_preds = valid_preds[:, 1]\n","#         valid_df2['prediction_id'] = valid_df2['patient_id'].astype(str) + '_' + valid_df2['laterality'].astype(str)\n","#         valid_preds = np.array(valid_preds).flatten()\n","        \n","#         valid_df2['raw_pred'] = valid_preds"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["# for fold in [3]:\n","#     valid_df3 = df[df['fold']==fold].reset_index(drop=True)   \n","#     valid_dataset = BreastDataset(valid_df3, transforms=data_transforms['valid'])\n","\n","#     valid_loader = DataLoader(valid_dataset, batch_size = CFG.valid_bs, \n","#                                   num_workers=1, shuffle=False, drop_last=False)\n","#     # model = Model(model_name=CFG.model_name).to(device)\n","#     LEN_DL_TRAIN = len(train_loader)\n","#     best_f1 = 0\n","#     best_metric = 0\n","#     total_epoch = 15\n","#     warmup = 1\n","#     model = ModelOld(model_name=CFG.model_name).to(device)\n","#     checkpoint = torch.load(\"swa_tf_efficientnetv2_b2_fold_3_model_0.5325_0.428.pth\")\n","#     model.load_state_dict(checkpoint['state_dict'])\n","#     for epoch in range(1, 2):\n","#         LOGGER.info(f\"Epoch: {epoch}/{total_epoch}\")\n","#         loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","#         # loss_train, train_preds = valid_fn_two(train_loader, model, criterion, CFG.device)\n","#         # loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","#         valid_preds = valid_preds[:, 1]\n","#         valid_df3['prediction_id'] = valid_df3['patient_id'].astype(str) + '_' + valid_df3['laterality'].astype(str)\n","#         valid_preds = np.array(valid_preds).flatten()\n","        \n","#         valid_df3['raw_pred'] = valid_preds"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["# final_valid_df = pd.concat([valid_df, valid_df1, valid_df2, valid_df3], axis = 0).reset_index(drop=True)\n","# print(final_valid_df.head())"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["# print(len(final_valid_df))"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["# from sklearn import metrics\n","# def np_binary_cross_entropy_loss(probability, truth):\n","#     probability = probability.astype(np.float64)\n","#     probability = np.nan_to_num(probability, nan=1, posinf=1, neginf=0)\n","\n","#     p = np.clip(probability, 1e-5, 1 - 1e-5)\n","#     y = truth\n","\n","#     loss = -y * np.log(p) - (1 - y) * np.log(1 - p)\n","#     loss = loss.mean()\n","#     return loss\n","\n","# def get_f1score(probability, truth, threshold = np.linspace(0.2, 0.5, 10000)):\n","#     f1score = []\n","#     precision=[]\n","#     recall=[]\n","#     for t in threshold:\n","#         predict = (probability > t).astype(np.float32)\n","\n","#         tp = ((predict >= 0.5) & (truth >= 0.5)).sum()\n","#         fp = ((predict >= 0.5) & (truth < 0.5)).sum()\n","#         fn = ((predict < 0.5) & (truth >= 0.5)).sum()\n","\n","#         r = tp / (tp + fn + 1e-3)\n","#         p = tp / (tp + fp + 1e-3)\n","#         f1 = 2 * r * p / (r + p + 1e-3)\n","#         f1score.append(f1)\n","#         precision.append(p)\n","#         recall.append(r)\n","#     f1score = np.array(f1score)\n","#     precision = np.array(precision)\n","#     recall = np.array(recall)\n","#     return f1score, precision, recall, threshold\n","\n","\n","# def compute_metric(cancer_p, cancer_t):\n","\n","#     fpr, tpr, thresholds = metrics.roc_curve(cancer_t, cancer_p)\n","#     auc = metrics.auc(fpr, tpr)\n","\n","#     f1score, precision, recall, threshold = get_f1score(cancer_p, cancer_t)\n","#     i = f1score.argmax()\n","#     f1score, precision, recall, threshold = f1score[i], precision[i], recall[i], threshold[i]\n","\n","#     specificity = ((cancer_p < threshold ) & ((cancer_t <= 0.5))).sum() / (cancer_t <= 0.5).sum()\n","#     sensitivity = ((cancer_p >= threshold) & ((cancer_t >= 0.5))).sum() / (cancer_t >= 0.5).sum()\n","\n","#     return {\n","#         'auc': auc,\n","#         'threshold': threshold,\n","#         'f1score': f1score,\n","#         'precision': precision,\n","#         'recall': recall,\n","#         'sensitivity': sensitivity,\n","#         'specificity': specificity,\n","#     }\n","\n","# def compute_pfbeta(labels, predictions, beta=1):\n","#     y_true_count = 0\n","#     ctp = 0\n","#     cfp = 0\n","\n","#     for idx in range(len(labels)):\n","#         prediction = min(max(predictions[idx], 0), 1)\n","#         if (labels[idx]):\n","#             y_true_count += 1\n","#             ctp += prediction\n","#             #cfp += 1 - prediction\n","#         else:\n","#             cfp += prediction\n","\n","#     beta_squared = beta * beta\n","#     c_precision = ctp / (ctp + cfp+1e-8)\n","#     c_recall = ctp / y_true_count\n","#     if (c_precision > 0 and c_recall > 0):\n","#         result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n","#         return result\n","#     else:\n","#         return 0\n","\n","# def print_all_metric(valid_df):\n","\n","# \tprint(f'{\"    \": <16}    \\tauc      @th     f1      | \tprec    recall  | \tsens    spec ')\n","# \t#log.write(f'{\"    \": <16}    \\t0.77902\t0.44898\t0.28654 | \t0.32461\t0.25726 | \t0.25726\t0.98794\\n')\n","# \tfor site_id in [0,1,2]:\n","\n","# \t\t#log.write(f'*** site_id [{site_id}] ***\\n')\n","# \t\t#log.write(f'\\n')\n","\n","# \t\tif site_id>0:\n","# \t\t\tsite_df = valid_df[valid_df.site_id == site_id].reset_index(drop=True)\n","# \t\telse:\n","# \t\t\tsite_df = valid_df\n","# \t\t# ---\n","\n","# \t\tgb = site_df\n","# \t\tm = compute_metric(gb.raw_pred, gb.cancer)\n","# \t\ttext = f'{\"single image\": <16} [{site_id}]'\n","# \t\ttext += f'\\t{m[\"auc\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"threshold\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"f1score\"]:0.5f} | '\n","# \t\ttext += f'\\t{m[\"precision\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"recall\"]:0.5f} | '\n","# \t\ttext += f'\\t{m[\"sensitivity\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"specificity\"]:0.5f}'\n","# \t\t#text += '\\n'\n","# \t\tprint(text)\n","\n","\n","# \t\t# ---\n","\n","# \t\tgb = site_df[['patient_id', 'laterality', 'cancer', 'raw_pred']].groupby(['patient_id', 'laterality']).mean()\n","# \t\tm = compute_metric(gb.raw_pred, gb.cancer)\n","# \t\ttext = f'{\"grouby mean()\": <16} [{site_id}]'\n","# \t\ttext += f'\\t{m[\"auc\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"threshold\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"f1score\"]:0.5f} | '\n","# \t\ttext += f'\\t{m[\"precision\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"recall\"]:0.5f} | '\n","# \t\ttext += f'\\t{m[\"sensitivity\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"specificity\"]:0.5f}'\n","# \t\t#text += '\\n'\n","# \t\tprint(text)\n","\n","# \t\t# ---\n","# \t\tgb = site_df[['patient_id', 'laterality', 'cancer', 'raw_pred']].groupby(['patient_id', 'laterality']).max()\n","# \t\tm = compute_metric(gb.raw_pred, gb.cancer)\n","# \t\ttext = f'{\"grouby max()\": <16} [{site_id}]'\n","# \t\ttext += f'\\t{m[\"auc\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"threshold\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"f1score\"]:0.5f} | '\n","# \t\ttext += f'\\t{m[\"precision\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"recall\"]:0.5f} | '\n","# \t\ttext += f'\\t{m[\"sensitivity\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"specificity\"]:0.5f}'\n","# \t\t#text += '\\n'\n","# \t\tprint(text)\n","# \t\tprint(f'--------------\\n')\n","\n","\n","# # valid_df.loc[:, 'cancer_t'] = valid_preds\n","# print_all_metric(final_valid_df)"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["\n","# grp_df = final_valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n","# grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n","# valid_labels_mean = grp_df['cancer'].values\n","# valid_preds_mean = grp_df['raw_pred'].values\n","# # print(valid_labels[:5], valid_preds_mean[:5])\n","# val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n","# LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n","# best_metric_mean_at_epoch = 0\n","# best_metric1 = 0\n","# best_threshold_mean = 0\n","# best_auc = 0\n","# best_cf = None\n","# for i in np.arange(0.001, 0.599, 0.001):\n","#     valid_argmax = (valid_preds_mean>i).astype(np.int32)\n","# #             print(valid_argmax)\n","#     # val_metric = pfbeta(valid_labels_mean, valid_argmax)\n","#     val_metric1 = pfbeta_np(valid_labels_mean, valid_argmax)\n","#     val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n","#     val_f1 = f1_score(valid_labels_mean, valid_argmax)\n","#     val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n","#     cf = confusion_matrix(valid_labels_mean, valid_argmax)\n","#     if val_metric1> best_metric1:\n","#         best_metric1 = val_metric1\n","#         # best_metric_mean_at_epoch = val_metric\n","#         best_threshold_mean = i\n","#         best_auc = val_auc\n","#         best_cf = cf\n","# LOGGER.info(f\"Best metric at epoch {epoch}: {best_metric1:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["import optuna\n","from optuna.samplers import TPESampler"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2023-02-24 15:00:07,570]\u001b[0m A new study created in memory with name: no-name-53710a50-c91b-403f-8002-fe3c3577b842\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["> SEEDING DONE\n","none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.15198443381740748 0.25672863401172846 0.03670370164741394 0.0014337924369785331 0.5531494380864715\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:00<00:00,  1.05s/it, eval_loss=0.0860, gpu_mem=7.81 GB]\n","Valid loss:0.0860\n","Val metric mean prob: 0.2583\n","Best metric at: 0.5057 0.3750  0.7168\n","Cf: [[4636   30]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 15:04:12,869]\u001b[0m Trial 0 finished with value: 0.5057471264367815 and parameters: {'a1': 0.15198443381740748, 'a2': 0.25672863401172846, 'a3': 0.03670370164741394, 'a4': 0.0014337924369785331}. Best is trial 0 with value: 0.5057471264367815.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.8270655972088143 0.15944838645109546 0.009101767328684767 0.0008576087380599103 0.0035266402733455183\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1085, gpu_mem=7.81 GB]\n","Valid loss:0.1085\n","Val metric mean prob: 0.1980\n","Best metric at: 0.5087 0.4910  0.7169\n","Cf: [[4637   29]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 15:07:26,810]\u001b[0m Trial 1 finished with value: 0.508670520231214 and parameters: {'a1': 0.8270655972088143, 'a2': 0.15944838645109546, 'a3': 0.009101767328684767, 'a4': 0.0008576087380599103}. Best is trial 1 with value: 0.508670520231214.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.2672438107409991 0.4715927941741754 0.024373899913704793 2.0244973795325485e-05 0.2367692501973254\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.07s/it, eval_loss=0.0890, gpu_mem=7.81 GB]\n","Valid loss:0.0890\n","Val metric mean prob: 0.2453\n","Best metric at: 0.5029 0.4090  0.7167\n","Cf: [[4635   31]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 15:10:38,357]\u001b[0m Trial 2 finished with value: 0.5028571428571429 and parameters: {'a1': 0.2672438107409991, 'a2': 0.4715927941741754, 'a3': 0.024373899913704793, 'a4': 2.0244973795325485e-05}. Best is trial 1 with value: 0.508670520231214.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.5841280021678498 0.1430333685445009 0.26881573790989616 0.00034421248119655704 0.0036786788965566335\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.07s/it, eval_loss=0.1018, gpu_mem=7.81 GB]\n","Valid loss:0.1018\n","Val metric mean prob: 0.2059\n","Best metric at: 0.5056 0.4610  0.7215\n","Cf: [[4633   33]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 15:13:50,848]\u001b[0m Trial 3 finished with value: 0.5056179775280899 and parameters: {'a1': 0.5841280021678498, 'a2': 0.1430333685445009, 'a3': 0.26881573790989616, 'a4': 0.00034421248119655704}. Best is trial 1 with value: 0.508670520231214.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6752797077033628 0.1791797060334395 0.038926992984716316 0.00029731246186449195 0.10631628081661694\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.1059, gpu_mem=7.81 GB]\n","Valid loss:0.1059\n","Val metric mean prob: 0.1942\n","Best metric at: 0.5257 0.4710  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 15:17:04,109]\u001b[0m Trial 4 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6752797077033628, 'a2': 0.1791797060334395, 'a3': 0.038926992984716316, 'a4': 0.00029731246186449195}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.22147588990729727 0.14569581858541253 0.2468773591389835 7.060071016743199e-05 0.3858803316581393\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:02<00:00,  1.06s/it, eval_loss=0.0872, gpu_mem=7.81 GB]\n","Valid loss:0.0872\n","Val metric mean prob: 0.2559\n","Best metric at: 0.5087 0.3910  0.7169\n","Cf: [[4637   29]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 15:20:14,765]\u001b[0m Trial 5 finished with value: 0.508670520231214 and parameters: {'a1': 0.22147588990729727, 'a2': 0.14569581858541253, 'a3': 0.2468773591389835, 'a4': 7.060071016743199e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6051909111102163 0.3477634626798341 0.028689970386416158 6.1064455684995e-05 0.018294591367848466\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1037, gpu_mem=7.81 GB]\n","Valid loss:0.1037\n","Val metric mean prob: 0.2006\n","Best metric at: 0.5202 0.4650  0.7220\n","Cf: [[4638   28]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 15:23:29,332]\u001b[0m Trial 6 finished with value: 0.5202312138728323 and parameters: {'a1': 0.6051909111102163, 'a2': 0.3477634626798341, 'a3': 0.028689970386416158, 'a4': 6.1064455684995e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.1789510733541227 0.6696568449965448 0.03396382373271594 0.0012007812849331675 0.11622747663168348\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.0880, gpu_mem=7.81 GB]\n","Valid loss:0.0880\n","Val metric mean prob: 0.2651\n","Best metric at: 0.5032 0.4750  0.6933\n","Cf: [[4650   16]\n"," [  61   39]]\n","\u001b[32m[I 2023-02-24 15:26:41,748]\u001b[0m Trial 7 finished with value: 0.5032258064516129 and parameters: {'a1': 0.1789510733541227, 'a2': 0.6696568449965448, 'a3': 0.03396382373271594, 'a4': 0.0012007812849331675}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.5137923651117912 0.29166616513704713 0.10312621521240645 1.0174411943425079e-05 0.09140508012681184\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.0996, gpu_mem=7.81 GB]\n","Valid loss:0.0996\n","Val metric mean prob: 0.2084\n","Best metric at: 0.5085 0.4490  0.7216\n","Cf: [[4634   32]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 15:29:55,188]\u001b[0m Trial 8 finished with value: 0.5084745762711864 and parameters: {'a1': 0.5137923651117912, 'a2': 0.29166616513704713, 'a3': 0.10312621521240645, 'a4': 1.0174411943425079e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.5193321925594401 0.429820760381167 0.0383980149357977 2.1659021216872664e-05 0.012427373102378344\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:00<00:00,  1.05s/it, eval_loss=0.1004, gpu_mem=7.81 GB]\n","Valid loss:0.1004\n","Val metric mean prob: 0.2088\n","Best metric at: 0.5085 0.4500  0.7216\n","Cf: [[4634   32]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 15:33:04,920]\u001b[0m Trial 9 finished with value: 0.5084745762711864 and parameters: {'a1': 0.5193321925594401, 'a2': 0.429820760381167, 'a3': 0.0383980149357977, 'a4': 2.1659021216872664e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.8933211646877505 0.0025052535520788954 0.0019754080692958934 0.018995182013937875 0.08320299167693687\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1097, gpu_mem=7.81 GB]\n","Valid loss:0.1097\n","Val metric mean prob: 0.1979\n","Best metric at: 0.4970 0.4970  0.7071\n","Cf: [[4639   27]\n"," [  58   42]]\n","\u001b[32m[I 2023-02-24 15:36:18,888]\u001b[0m Trial 10 finished with value: 0.4970414201183433 and parameters: {'a1': 0.8933211646877505, 'a2': 0.0025052535520788954, 'a3': 0.0019754080692958934, 'a4': 0.018995182013937875}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7023233041817935 0.006043086356797067 0.09234225911841062 0.00013077897403380924 0.19916057136896506\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.1065, gpu_mem=7.81 GB]\n","Valid loss:0.1065\n","Val metric mean prob: 0.1910\n","Best metric at: 0.5165 0.4500  0.7312\n","Cf: [[4631   35]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 15:39:31,720]\u001b[0m Trial 11 finished with value: 0.5164835164835165 and parameters: {'a1': 0.7023233041817935, 'a2': 0.006043086356797067, 'a3': 0.09234225911841062, 'a4': 0.00013077897403380924}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7112197359424666 0.06013474654754408 0.06891545688899561 0.00012695365919678105 0.15960310696179694\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.1067, gpu_mem=7.81 GB]\n","Valid loss:0.1067\n","Val metric mean prob: 0.1921\n","Best metric at: 0.5165 0.4550  0.7312\n","Cf: [[4631   35]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 15:42:45,273]\u001b[0m Trial 12 finished with value: 0.5164835164835165 and parameters: {'a1': 0.7112197359424666, 'a2': 0.06013474654754408, 'a3': 0.06891545688899561, 'a4': 0.00012695365919678105}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.9843007709016036 0.005409569648461145 0.004624568576447919 4.878005836373335e-05 0.005616310815123586\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:07<00:00,  1.09s/it, eval_loss=0.1126, gpu_mem=7.81 GB]\n","Valid loss:0.1126\n","Val metric mean prob: 0.2039\n","Best metric at: 0.4884 0.5050  0.7068\n","Cf: [[4636   30]\n"," [  58   42]]\n","\u001b[32m[I 2023-02-24 15:46:01,321]\u001b[0m Trial 13 finished with value: 0.4883720930232558 and parameters: {'a1': 0.9843007709016036, 'a2': 0.005409569648461145, 'a3': 0.004624568576447919, 'a4': 4.878005836373335e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.37922540796875615 0.3615915343831175 0.13622478090970558 0.00025647733055960775 0.12270179940786119\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:01<00:00,  1.06s/it, eval_loss=0.0932, gpu_mem=7.81 GB]\n","Valid loss:0.0932\n","Val metric mean prob: 0.2292\n","Best metric at: 0.4938 0.4780  0.6976\n","Cf: [[4644   22]\n"," [  60   40]]\n","\u001b[32m[I 2023-02-24 15:49:11,290]\u001b[0m Trial 14 finished with value: 0.49382716049382713 and parameters: {'a1': 0.37922540796875615, 'a2': 0.3615915343831175, 'a3': 0.13622478090970558, 'a4': 0.00025647733055960775}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.3736137588660356 0.23534243611791844 0.1550382209335127 0.0059998350996526145 0.23000574898288073\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.0924, gpu_mem=7.81 GB]\n","Valid loss:0.0924\n","Val metric mean prob: 0.2271\n","Best metric at: 0.4969 0.4660  0.6977\n","Cf: [[4645   21]\n"," [  60   40]]\n","\u001b[32m[I 2023-02-24 15:52:26,087]\u001b[0m Trial 15 finished with value: 0.49689440993788825 and parameters: {'a1': 0.3736137588660356, 'a2': 0.23534243611791844, 'a3': 0.1550382209335127, 'a4': 0.0059998350996526145}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6549923379804404 0.09403353001017391 0.06644638935932783 0.1769337928380665 0.007593949811991324\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.06s/it, eval_loss=0.1019, gpu_mem=7.81 GB]\n","Valid loss:0.1019\n","Val metric mean prob: 0.1907\n","Best metric at: 0.5028 0.4310  0.7214\n","Cf: [[4632   34]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 15:55:37,723]\u001b[0m Trial 16 finished with value: 0.5027932960893855 and parameters: {'a1': 0.6549923379804404, 'a2': 0.09403353001017391, 'a3': 0.06644638935932783, 'a4': 0.1769337928380665}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.024055765101244853 0.5734177352396657 0.344636788328781 0.0003558223812102809 0.05753388894909823\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.0918, gpu_mem=7.81 GB]\n","Valid loss:0.0918\n","Val metric mean prob: 0.2963\n","Best metric at: 0.4815 0.4210  0.6925\n","Cf: [[4643   23]\n"," [  61   39]]\n","\u001b[32m[I 2023-02-24 15:58:51,324]\u001b[0m Trial 17 finished with value: 0.4814814814814815 and parameters: {'a1': 0.024055765101244853, 'a2': 0.5734177352396657, 'a3': 0.344636788328781, 'a4': 0.0003558223812102809}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7865985437670389 0.06422602227614585 0.05078333827935331 6.103595494925742e-05 0.09833105972251273\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:02<00:00,  1.06s/it, eval_loss=0.1081, gpu_mem=7.81 GB]\n","Valid loss:0.1081\n","Val metric mean prob: 0.1943\n","Best metric at: 0.5089 0.4920  0.7122\n","Cf: [[4640   26]\n"," [  57   43]]\n","\u001b[32m[I 2023-02-24 16:02:03,140]\u001b[0m Trial 18 finished with value: 0.5088757396449703 and parameters: {'a1': 0.7865985437670389, 'a2': 0.06422602227614585, 'a3': 0.05078333827935331, 'a4': 6.103595494925742e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6093396082891043 0.2117979605896841 0.020157982900214595 1.114030020774296e-05 0.1586933079207893\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.07s/it, eval_loss=0.1039, gpu_mem=7.81 GB]\n","Valid loss:0.1039\n","Val metric mean prob: 0.1955\n","Best metric at: 0.5143 0.4590  0.7218\n","Cf: [[4636   30]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 16:05:15,107]\u001b[0m Trial 19 finished with value: 0.5142857142857143 and parameters: {'a1': 0.6093396082891043, 'a2': 0.2117979605896841, 'a3': 0.020157982900214595, 'a4': 1.114030020774296e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.42457517464908867 0.2962560335209548 0.06874838896280241 3.542318042420431e-05 0.2103849796867299\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.08s/it, eval_loss=0.0952, gpu_mem=7.81 GB]\n","Valid loss:0.0952\n","Val metric mean prob: 0.2170\n","Best metric at: 0.5085 0.4310  0.7216\n","Cf: [[4634   32]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 16:08:29,846]\u001b[0m Trial 20 finished with value: 0.5084745762711864 and parameters: {'a1': 0.42457517464908867, 'a2': 0.2962560335209548, 'a3': 0.06874838896280241, 'a4': 3.542318042420431e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7083868611793904 0.1206674668845732 0.04991886778206659 0.00012928265647057794 0.12089752149749922\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:02<00:00,  1.06s/it, eval_loss=0.1067, gpu_mem=7.81 GB]\n","Valid loss:0.1067\n","Val metric mean prob: 0.1931\n","Best metric at: 0.5169 0.4700  0.7266\n","Cf: [[4634   32]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 16:11:41,329]\u001b[0m Trial 21 finished with value: 0.5168539325842696 and parameters: {'a1': 0.7083868611793904, 'a2': 0.1206674668845732, 'a3': 0.04991886778206659, 'a4': 0.00012928265647057794}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7082954374851707 0.1747913998848967 0.016919346293595802 0.00012233465468209883 0.09987148168165474\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1067, gpu_mem=7.81 GB]\n","Valid loss:0.1067\n","Val metric mean prob: 0.1936\n","Best metric at: 0.5227 0.4730  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 16:14:55,181]\u001b[0m Trial 22 finished with value: 0.5227272727272727 and parameters: {'a1': 0.7082954374851707, 'a2': 0.1747913998848967, 'a3': 0.016919346293595802, 'a4': 0.00012233465468209883}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.5549725301049014 0.19317788542713793 0.018872678813067947 0.00042521149274707106 0.2325516941621456\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:01<00:00,  1.05s/it, eval_loss=0.1016, gpu_mem=7.81 GB]\n","Valid loss:0.1016\n","Val metric mean prob: 0.1975\n","Best metric at: 0.5085 0.4440  0.7216\n","Cf: [[4634   32]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 16:18:04,978]\u001b[0m Trial 23 finished with value: 0.5084745762711864 and parameters: {'a1': 0.5549725301049014, 'a2': 0.19317788542713793, 'a3': 0.018872678813067947, 'a4': 0.00042521149274707106}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6246023768552995 0.19097087385727926 0.018154032204237416 0.00010057249696476423 0.16617214458621904\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:02<00:00,  1.06s/it, eval_loss=0.1045, gpu_mem=7.81 GB]\n","Valid loss:0.1045\n","Val metric mean prob: 0.1943\n","Best metric at: 0.5169 0.4560  0.7266\n","Cf: [[4634   32]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 16:21:16,453]\u001b[0m Trial 24 finished with value: 0.5168539325842696 and parameters: {'a1': 0.6246023768552995, 'a2': 0.19097087385727926, 'a3': 0.018154032204237416, 'a4': 0.00010057249696476423}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7813861590691425 0.10579332856902243 0.011751002218406697 3.7455196159202555e-05 0.10103205494726912\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:02<00:00,  1.06s/it, eval_loss=0.1082, gpu_mem=7.81 GB]\n","Valid loss:0.1082\n","Val metric mean prob: 0.1936\n","Best metric at: 0.5119 0.4970  0.7123\n","Cf: [[4641   25]\n"," [  57   43]]\n","\u001b[32m[I 2023-02-24 16:24:27,100]\u001b[0m Trial 25 finished with value: 0.511904761904762 and parameters: {'a1': 0.7813861590691425, 'a2': 0.10579332856902243, 'a3': 0.011751002218406697, 'a4': 3.7455196159202555e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6575604736897904 0.18166378761310248 0.0012336909365943914 0.0002201203050965181 0.15932192745541618\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1056, gpu_mem=7.81 GB]\n","Valid loss:0.1056\n","Val metric mean prob: 0.1927\n","Best metric at: 0.5227 0.4660  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 16:27:40,658]\u001b[0m Trial 26 finished with value: 0.5227272727272727 and parameters: {'a1': 0.6575604736897904, 'a2': 0.18166378761310248, 'a3': 0.0012336909365943914, 'a4': 0.0002201203050965181}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.47116940129543655 0.17661058980793504 0.1262244228005419 0.00023395510413895906 0.2257616309919475\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.08s/it, eval_loss=0.0972, gpu_mem=7.81 GB]\n","Valid loss:0.0972\n","Val metric mean prob: 0.2101\n","Best metric at: 0.5169 0.4330  0.7266\n","Cf: [[4634   32]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 16:30:55,684]\u001b[0m Trial 27 finished with value: 0.5168539325842696 and parameters: {'a1': 0.47116940129543655, 'a2': 0.17661058980793504, 'a3': 0.1262244228005419, 'a4': 0.00023395510413895906}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6742211551999292 0.17230188996473664 0.0017219538907443778 0.0006896763768935058 0.15106532456769628\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:01<00:00,  1.06s/it, eval_loss=0.1060, gpu_mem=7.81 GB]\n","Valid loss:0.1060\n","Val metric mean prob: 0.1923\n","Best metric at: 0.5198 0.4630  0.7267\n","Cf: [[4635   31]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 16:34:06,135]\u001b[0m Trial 28 finished with value: 0.5197740112994351 and parameters: {'a1': 0.6742211551999292, 'a2': 0.17230188996473664, 'a3': 0.0017219538907443778, 'a4': 0.0006896763768935058}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7704254789671042 0.1277398379506823 0.014005004574448952 0.0017019844767091183 0.0861276940310554\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.09s/it, eval_loss=0.1080, gpu_mem=7.81 GB]\n","Valid loss:0.1080\n","Val metric mean prob: 0.1939\n","Best metric at: 0.5119 0.4960  0.7123\n","Cf: [[4641   25]\n"," [  57   43]]\n","\u001b[32m[I 2023-02-24 16:37:21,423]\u001b[0m Trial 29 finished with value: 0.511904761904762 and parameters: {'a1': 0.7704254789671042, 'a2': 0.1277398379506823, 'a3': 0.014005004574448952, 'a4': 0.0017019844767091183}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.842388684163357 0.027116043302113348 0.0009759434397698534 0.00023700252790367901 0.12928232656685612\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1091, gpu_mem=7.81 GB]\n","Valid loss:0.1091\n","Val metric mean prob: 0.1952\n","Best metric at: 0.5087 0.4870  0.7169\n","Cf: [[4637   29]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 16:40:35,808]\u001b[0m Trial 30 finished with value: 0.508670520231214 and parameters: {'a1': 0.842388684163357, 'a2': 0.027116043302113348, 'a3': 0.0009759434397698534, 'a4': 0.00023700252790367901}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6619703102074843 0.21382268111261415 0.029914428166037597 9.407764070300415e-05 0.09419850287316094\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.08s/it, eval_loss=0.1054, gpu_mem=7.81 GB]\n","Valid loss:0.1054\n","Val metric mean prob: 0.1952\n","Best metric at: 0.5227 0.4680  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 16:43:49,325]\u001b[0m Trial 31 finished with value: 0.5227272727272727 and parameters: {'a1': 0.6619703102074843, 'a2': 0.21382268111261415, 'a3': 0.029914428166037597, 'a4': 9.407764070300415e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7264245058933214 0.15696176671795226 0.009520481812546708 0.00015172878298602653 0.1069415167931936\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1071, gpu_mem=7.81 GB]\n","Valid loss:0.1071\n","Val metric mean prob: 0.1932\n","Best metric at: 0.5146 0.4880  0.7171\n","Cf: [[4639   27]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 16:47:03,183]\u001b[0m Trial 32 finished with value: 0.5146198830409356 and parameters: {'a1': 0.7264245058933214, 'a2': 0.15696176671795226, 'a3': 0.009520481812546708, 'a4': 0.00015172878298602653}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6598846198914557 0.20189440011142265 0.025460614310724584 0.0005206013335047414 0.11223976435289228\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1055, gpu_mem=7.81 GB]\n","Valid loss:0.1055\n","Val metric mean prob: 0.1944\n","Best metric at: 0.5227 0.4670  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 16:50:16,696]\u001b[0m Trial 33 finished with value: 0.5227272727272727 and parameters: {'a1': 0.6598846198914557, 'a2': 0.20189440011142265, 'a3': 0.025460614310724584, 'a4': 0.0005206013335047414}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.5785249399332036 0.22495480781529759 0.035628233466646723 0.00018172034191201074 0.16071029844294002\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.08s/it, eval_loss=0.1026, gpu_mem=7.81 GB]\n","Valid loss:0.1026\n","Val metric mean prob: 0.1981\n","Best metric at: 0.5109 0.4390  0.7310\n","Cf: [[4629   37]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 16:53:31,437]\u001b[0m Trial 34 finished with value: 0.5108695652173914 and parameters: {'a1': 0.5785249399332036, 'a2': 0.22495480781529759, 'a3': 0.035628233466646723, 'a4': 0.00018172034191201074}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6420433429338734 0.1795920266526508 0.024432699967920978 7.3263812983472e-05 0.1538586666325713\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.06s/it, eval_loss=0.1049, gpu_mem=7.81 GB]\n","Valid loss:0.1049\n","Val metric mean prob: 0.1940\n","Best metric at: 0.5227 0.4620  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 16:56:45,419]\u001b[0m Trial 35 finished with value: 0.5227272727272727 and parameters: {'a1': 0.6420433429338734, 'a2': 0.1795920266526508, 'a3': 0.024432699967920978, 'a4': 7.3263812983472e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.5559429852823026 0.1535462916401795 0.04835800970258762 0.0006130055716171901 0.24153970780331308\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1014, gpu_mem=7.81 GB]\n","Valid loss:0.1014\n","Val metric mean prob: 0.1976\n","Best metric at: 0.5143 0.4460  0.7218\n","Cf: [[4636   30]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 16:59:59,401]\u001b[0m Trial 36 finished with value: 0.5142857142857143 and parameters: {'a1': 0.5559429852823026, 'a2': 0.1535462916401795, 'a3': 0.04835800970258762, 'a4': 0.0006130055716171901}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7468635672408704 0.16645653933191548 0.01329511850606352 8.560637884866448e-05 0.0732991685423019\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.07s/it, eval_loss=0.1075, gpu_mem=7.81 GB]\n","Valid loss:0.1075\n","Val metric mean prob: 0.1942\n","Best metric at: 0.5114 0.4800  0.7217\n","Cf: [[4635   31]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 17:03:11,557]\u001b[0m Trial 37 finished with value: 0.5113636363636364 and parameters: {'a1': 0.7468635672408704, 'a2': 0.16645653933191548, 'a3': 0.01329511850606352, 'a4': 8.560637884866448e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.8222402511301071 0.09403140715408878 0.007396775228643513 0.0003025977605024138 0.07602896872665817\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1087, gpu_mem=7.81 GB]\n","Valid loss:0.1087\n","Val metric mean prob: 0.1957\n","Best metric at: 0.5146 0.4920  0.7171\n","Cf: [[4639   27]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 17:06:25,016]\u001b[0m Trial 38 finished with value: 0.5146198830409356 and parameters: {'a1': 0.8222402511301071, 'a2': 0.09403140715408878, 'a3': 0.007396775228643513, 'a4': 0.0003025977605024138}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6766151150569817 0.15175586930997326 0.030349711016512987 2.9824136616329382e-05 0.14124948047991573\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.08s/it, eval_loss=0.1059, gpu_mem=7.81 GB]\n","Valid loss:0.1059\n","Val metric mean prob: 0.1930\n","Best metric at: 0.5227 0.4670  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 17:09:39,840]\u001b[0m Trial 39 finished with value: 0.5227272727272727 and parameters: {'a1': 0.6766151150569817, 'a2': 0.15175586930997326, 'a3': 0.030349711016512987, 'a4': 2.9824136616329382e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6072798560002892 0.2136722270480093 0.036799394629198054 7.519329282542466e-05 0.14217332902967797\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:02<00:00,  1.06s/it, eval_loss=0.1037, gpu_mem=7.81 GB]\n","Valid loss:0.1037\n","Val metric mean prob: 0.1966\n","Best metric at: 0.5143 0.4610  0.7218\n","Cf: [[4636   30]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 17:12:50,723]\u001b[0m Trial 40 finished with value: 0.5142857142857143 and parameters: {'a1': 0.6072798560002892, 'a2': 0.2136722270480093, 'a3': 0.036799394629198054, 'a4': 7.519329282542466e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6623284533244862 0.19002588849628765 0.023660773607491005 0.0004815138564919198 0.12350337071524323\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.08s/it, eval_loss=0.1056, gpu_mem=7.81 GB]\n","Valid loss:0.1056\n","Val metric mean prob: 0.1940\n","Best metric at: 0.5227 0.4670  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 17:16:05,580]\u001b[0m Trial 41 finished with value: 0.5227272727272727 and parameters: {'a1': 0.6623284533244862, 'a2': 0.19002588849628765, 'a3': 0.023660773607491005, 'a4': 0.0004815138564919198}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7380741803363526 0.14101373641741508 0.016102439814590072 0.000917748930255465 0.10389189450138675\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.1073, gpu_mem=7.81 GB]\n","Valid loss:0.1073\n","Val metric mean prob: 0.1932\n","Best metric at: 0.5114 0.4770  0.7217\n","Cf: [[4635   31]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 17:19:18,273]\u001b[0m Trial 42 finished with value: 0.5113636363636364 and parameters: {'a1': 0.7380741803363526, 'a2': 0.14101373641741508, 'a3': 0.016102439814590072, 'a4': 0.000917748930255465}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6249545607068531 0.2030442984367026 0.027138854689871234 0.00016669303390935223 0.14469559313266375\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.09s/it, eval_loss=0.1045, gpu_mem=7.81 GB]\n","Valid loss:0.1045\n","Val metric mean prob: 0.1951\n","Best metric at: 0.5143 0.4600  0.7218\n","Cf: [[4636   30]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 17:22:33,278]\u001b[0m Trial 43 finished with value: 0.5142857142857143 and parameters: {'a1': 0.6249545607068531, 'a2': 0.2030442984367026, 'a3': 0.027138854689871234, 'a4': 0.00016669303390935223}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.5457428988092852 0.24191437221775827 0.0413217691812183 0.0004286806457181594 0.1705922791460201\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:02<00:00,  1.06s/it, eval_loss=0.1011, gpu_mem=7.81 GB]\n","Valid loss:0.1011\n","Val metric mean prob: 0.2011\n","Best metric at: 0.5111 0.4420  0.7264\n","Cf: [[4632   34]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 17:25:44,630]\u001b[0m Trial 44 finished with value: 0.5111111111111112 and parameters: {'a1': 0.5457428988092852, 'a2': 0.24191437221775827, 'a3': 0.0413217691812183, 'a4': 0.0004286806457181594}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6665191469686422 0.1666850775212383 0.02554743282022599 0.00021004491355243004 0.14103829777634108\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.09s/it, eval_loss=0.1058, gpu_mem=7.81 GB]\n","Valid loss:0.1058\n","Val metric mean prob: 0.1931\n","Best metric at: 0.5227 0.4680  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 17:28:59,929]\u001b[0m Trial 45 finished with value: 0.5227272727272727 and parameters: {'a1': 0.6665191469686422, 'a2': 0.1666850775212383, 'a3': 0.02554743282022599, 'a4': 0.00021004491355243004}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.4962912965662184 0.26072311814833626 0.061142630671261425 0.00010383872665530193 0.1817391158875286\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.0987, gpu_mem=7.81 GB]\n","Valid loss:0.0987\n","Val metric mean prob: 0.2070\n","Best metric at: 0.5085 0.4410  0.7216\n","Cf: [[4634   32]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 17:32:14,096]\u001b[0m Trial 46 finished with value: 0.5084745762711864 and parameters: {'a1': 0.4962912965662184, 'a2': 0.26072311814833626, 'a3': 0.061142630671261425, 'a4': 0.00010383872665530193}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.5882790137385869 0.2044520223886969 0.0010666207181116057 0.001522177632386751 0.20468016552221782\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.07s/it, eval_loss=0.1030, gpu_mem=7.81 GB]\n","Valid loss:0.1030\n","Val metric mean prob: 0.1952\n","Best metric at: 0.5165 0.4440  0.7312\n","Cf: [[4631   35]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 17:35:25,943]\u001b[0m Trial 47 finished with value: 0.5164835164835165 and parameters: {'a1': 0.5882790137385869, 'a2': 0.2044520223886969, 'a3': 0.0010666207181116057, 'a4': 0.001522177632386751}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7054079126326982 0.17923614063661167 0.0057577543729568316 0.00037200702309996854 0.10922618533463332\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:07<00:00,  1.09s/it, eval_loss=0.1068, gpu_mem=7.81 GB]\n","Valid loss:0.1068\n","Val metric mean prob: 0.1931\n","Best metric at: 0.5227 0.4720  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 17:38:41,673]\u001b[0m Trial 48 finished with value: 0.5227272727272727 and parameters: {'a1': 0.7054079126326982, 'a2': 0.17923614063661167, 'a3': 0.0057577543729568316, 'a4': 0.00037200702309996854}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7490671477606945 0.1638057906394168 0.009480724102462184 5.435564166630015e-05 0.07759198185576022\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.1076, gpu_mem=7.81 GB]\n","Valid loss:0.1076\n","Val metric mean prob: 0.1940\n","Best metric at: 0.5114 0.4800  0.7217\n","Cf: [[4635   31]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 17:41:54,592]\u001b[0m Trial 49 finished with value: 0.5113636363636364 and parameters: {'a1': 0.7490671477606945, 'a2': 0.1638057906394168, 'a3': 0.009480724102462184, 'a4': 5.435564166630015e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.8159475018339916 0.07559114144741452 0.03151050329418665 0.00011597852757536728 0.07683487489683191\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1084, gpu_mem=7.81 GB]\n","Valid loss:0.1084\n","Val metric mean prob: 0.1957\n","Best metric at: 0.5116 0.4890  0.7170\n","Cf: [[4638   28]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 17:45:08,648]\u001b[0m Trial 50 finished with value: 0.5116279069767442 and parameters: {'a1': 0.8159475018339916, 'a2': 0.07559114144741452, 'a3': 0.03151050329418665, 'a4': 0.00011597852757536728}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6816778922920586 0.18148494831495993 0.024483414080555817 7.077850009932237e-05 0.11228296681232638\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.1061, gpu_mem=7.81 GB]\n","Valid loss:0.1061\n","Val metric mean prob: 0.1936\n","Best metric at: 0.5257 0.4720  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 17:48:21,503]\u001b[0m Trial 51 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6816778922920586, 'a2': 0.18148494831495993, 'a3': 0.024483414080555817, 'a4': 7.077850009932237e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7047394768434988 0.18448016508916587 0.019781358863160355 0.00017316395465355938 0.09082583524952142\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1067, gpu_mem=7.81 GB]\n","Valid loss:0.1067\n","Val metric mean prob: 0.1939\n","Best metric at: 0.5227 0.4740  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 17:51:35,720]\u001b[0m Trial 52 finished with value: 0.5227272727272727 and parameters: {'a1': 0.7047394768434988, 'a2': 0.18448016508916587, 'a3': 0.019781358863160355, 'a4': 0.00017316395465355938}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6513399234383933 0.1992251135922145 0.030544249442939625 4.912194457448999e-05 0.11884159158187807\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.08s/it, eval_loss=0.1052, gpu_mem=7.81 GB]\n","Valid loss:0.1052\n","Val metric mean prob: 0.1947\n","Best metric at: 0.5227 0.4650  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 17:54:50,524]\u001b[0m Trial 53 finished with value: 0.5227272727272727 and parameters: {'a1': 0.6513399234383933, 'a2': 0.1992251135922145, 'a3': 0.030544249442939625, 'a4': 4.912194457448999e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6122901487279888 0.2207899585783122 0.0402516386413226 0.00029855819419695375 0.12636969585817942\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.1039, gpu_mem=7.81 GB]\n","Valid loss:0.1039\n","Val metric mean prob: 0.1968\n","Best metric at: 0.5143 0.4640  0.7218\n","Cf: [[4636   30]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 17:58:03,634]\u001b[0m Trial 54 finished with value: 0.5142857142857143 and parameters: {'a1': 0.6122901487279888, 'a2': 0.2207899585783122, 'a3': 0.0402516386413226, 'a4': 0.00029855819419695375}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7005189232444268 0.18120418156432594 0.023723644402085502 9.016954103329046e-05 0.0944630812481285\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.09s/it, eval_loss=0.1066, gpu_mem=7.81 GB]\n","Valid loss:0.1066\n","Val metric mean prob: 0.1938\n","Best metric at: 0.5227 0.4740  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 18:01:19,181]\u001b[0m Trial 55 finished with value: 0.5227272727272727 and parameters: {'a1': 0.7005189232444268, 'a2': 0.18120418156432594, 'a3': 0.023723644402085502, 'a4': 9.016954103329046e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.5743539840642083 0.14309524576792998 0.05439251381772206 2.0443997106781132e-05 0.22813781235303282\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:01<00:00,  1.06s/it, eval_loss=0.1023, gpu_mem=7.81 GB]\n","Valid loss:0.1023\n","Val metric mean prob: 0.1963\n","Best metric at: 0.5140 0.4470  0.7265\n","Cf: [[4633   33]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 18:04:29,554]\u001b[0m Trial 56 finished with value: 0.5139664804469275 and parameters: {'a1': 0.5743539840642083, 'a2': 0.14309524576792998, 'a3': 0.05439251381772206, 'a4': 2.0443997106781132e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6342001684811509 0.20247416646549563 0.013862182097073964 0.00014486851850630398 0.1493186144377732\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1047, gpu_mem=7.81 GB]\n","Valid loss:0.1047\n","Val metric mean prob: 0.1944\n","Best metric at: 0.5227 0.4600  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 18:07:43,497]\u001b[0m Trial 57 finished with value: 0.5227272727272727 and parameters: {'a1': 0.6342001684811509, 'a2': 0.20247416646549563, 'a3': 0.013862182097073964, 'a4': 0.00014486851850630398}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.5174116949776719 0.24698780320732067 0.07459124276480361 4.288663650492845e-05 0.16096637241369888\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.0999, gpu_mem=7.81 GB]\n","Valid loss:0.0999\n","Val metric mean prob: 0.2050\n","Best metric at: 0.5111 0.4410  0.7264\n","Cf: [[4632   34]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 18:10:57,660]\u001b[0m Trial 58 finished with value: 0.5111111111111112 and parameters: {'a1': 0.5174116949776719, 'a2': 0.24698780320732067, 'a3': 0.07459124276480361, 'a4': 4.288663650492845e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7683248265157883 0.16917511982762304 0.02181160549667334 0.0002652032987801979 0.04042324486113516\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.1079, gpu_mem=7.81 GB]\n","Valid loss:0.1079\n","Val metric mean prob: 0.1953\n","Best metric at: 0.5087 0.4870  0.7169\n","Cf: [[4637   29]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 18:14:10,669]\u001b[0m Trial 59 finished with value: 0.508670520231214 and parameters: {'a1': 0.7683248265157883, 'a2': 0.16917511982762304, 'a3': 0.02181160549667334, 'a4': 0.0002652032987801979}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.8632697327540602 0.03936742323801515 0.027543835381605083 6.967053771332421e-05 0.06974933808860628\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:07<00:00,  1.09s/it, eval_loss=0.1094, gpu_mem=7.81 GB]\n","Valid loss:0.1094\n","Val metric mean prob: 0.1977\n","Best metric at: 0.5059 0.4970  0.7121\n","Cf: [[4639   27]\n"," [  57   43]]\n","\u001b[32m[I 2023-02-24 18:17:26,408]\u001b[0m Trial 60 finished with value: 0.5058823529411766 and parameters: {'a1': 0.8632697327540602, 'a2': 0.03936742323801515, 'a3': 0.027543835381605083, 'a4': 6.967053771332421e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6443669806941877 0.18686139829362977 0.04228144281267939 7.346043847486185e-05 0.12641671776102822\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.07s/it, eval_loss=0.1050, gpu_mem=7.81 GB]\n","Valid loss:0.1050\n","Val metric mean prob: 0.1949\n","Best metric at: 0.5198 0.4630  0.7267\n","Cf: [[4635   31]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 18:20:38,170]\u001b[0m Trial 61 finished with value: 0.5197740112994351 and parameters: {'a1': 0.6443669806941877, 'a2': 0.18686139829362977, 'a3': 0.04228144281267939, 'a4': 7.346043847486185e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6735721412954364 0.1787904774056179 0.018929820740311427 9.493759062902844e-05 0.1286126229680052\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.09s/it, eval_loss=0.1060, gpu_mem=7.81 GB]\n","Valid loss:0.1060\n","Val metric mean prob: 0.1932\n","Best metric at: 0.5257 0.4710  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 18:23:53,516]\u001b[0m Trial 62 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6735721412954364, 'a2': 0.1787904774056179, 'a3': 0.018929820740311427, 'a4': 9.493759062902844e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6844823286468669 0.19402050805598717 0.017201757497190863 0.00014362742559185317 0.10415177837436326\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:02<00:00,  1.06s/it, eval_loss=0.1062, gpu_mem=7.81 GB]\n","Valid loss:0.1062\n","Val metric mean prob: 0.1938\n","Best metric at: 0.5257 0.4730  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 18:27:04,282]\u001b[0m Trial 63 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6844823286468669, 'a2': 0.19402050805598717, 'a3': 0.017201757497190863, 'a4': 0.00014362742559185317}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6937983137071725 0.1729100408593 0.015449480301058985 0.00011733344971121192 0.11772483168275731\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.08s/it, eval_loss=0.1065, gpu_mem=7.81 GB]\n","Valid loss:0.1065\n","Val metric mean prob: 0.1931\n","Best metric at: 0.5227 0.4700  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 18:30:19,149]\u001b[0m Trial 64 finished with value: 0.5227272727272727 and parameters: {'a1': 0.6937983137071725, 'a2': 0.1729100408593, 'a3': 0.015449480301058985, 'a4': 0.00011733344971121192}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7343074627467084 0.16168097777339185 0.01769140125789645 0.00021655352700068433 0.08610360469500257\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.09s/it, eval_loss=0.1072, gpu_mem=7.81 GB]\n","Valid loss:0.1072\n","Val metric mean prob: 0.1939\n","Best metric at: 0.5146 0.4870  0.7171\n","Cf: [[4639   27]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 18:33:34,504]\u001b[0m Trial 65 finished with value: 0.5146198830409356 and parameters: {'a1': 0.7343074627467084, 'a2': 0.16168097777339185, 'a3': 0.01769140125789645, 'a4': 0.00021655352700068433}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7796587962374149 0.17011252153070255 0.0030965688095197976 9.86514558955062e-05 0.04703346196646729\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.06s/it, eval_loss=0.1082, gpu_mem=7.81 GB]\n","Valid loss:0.1082\n","Val metric mean prob: 0.1950\n","Best metric at: 0.5116 0.4880  0.7170\n","Cf: [[4638   28]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 18:36:46,026]\u001b[0m Trial 66 finished with value: 0.5116279069767442 and parameters: {'a1': 0.7796587962374149, 'a2': 0.17011252153070255, 'a3': 0.0030965688095197976, 'a4': 9.86514558955062e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.5942103629864498 0.22741482098382765 0.008726176146999403 5.027882892796193e-05 0.16959836105379517\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:07<00:00,  1.09s/it, eval_loss=0.1034, gpu_mem=7.81 GB]\n","Valid loss:0.1034\n","Val metric mean prob: 0.1960\n","Best metric at: 0.5143 0.4580  0.7218\n","Cf: [[4636   30]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 18:40:01,576]\u001b[0m Trial 67 finished with value: 0.5142857142857143 and parameters: {'a1': 0.5942103629864498, 'a2': 0.22741482098382765, 'a3': 0.008726176146999403, 'a4': 5.027882892796193e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7248361602327629 0.18832860428758494 0.01150358875076664 0.0001343501162462149 0.07519729661263934\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.07s/it, eval_loss=0.1070, gpu_mem=7.81 GB]\n","Valid loss:0.1070\n","Val metric mean prob: 0.1941\n","Best metric at: 0.5176 0.4900  0.7172\n","Cf: [[4640   26]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 18:43:14,062]\u001b[0m Trial 68 finished with value: 0.5176470588235295 and parameters: {'a1': 0.7248361602327629, 'a2': 0.18832860428758494, 'a3': 0.01150358875076664, 'a4': 0.0001343501162462149}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6882005971276836 0.1939144807504859 0.02121929734335063 2.9970068879651466e-05 0.09663565470960027\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.1063, gpu_mem=7.81 GB]\n","Valid loss:0.1063\n","Val metric mean prob: 0.1941\n","Best metric at: 0.5257 0.4740  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 18:46:27,269]\u001b[0m Trial 69 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6882005971276836, 'a2': 0.1939144807504859, 'a3': 0.02121929734335063, 'a4': 2.9970068879651466e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6908988409313237 0.19766930892169288 0.02057000059812123 2.6381331150824573e-05 0.09083546821771138\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.07s/it, eval_loss=0.1063, gpu_mem=7.81 GB]\n","Valid loss:0.1063\n","Val metric mean prob: 0.1943\n","Best metric at: 0.5257 0.4750  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 18:49:39,329]\u001b[0m Trial 70 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6908988409313237, 'a2': 0.19766930892169288, 'a3': 0.02057000059812123, 'a4': 2.6381331150824573e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.687620285428793 0.19529697829722914 0.02033448816140594 1.4687946054628993e-05 0.09673356016651724\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.08s/it, eval_loss=0.1062, gpu_mem=7.81 GB]\n","Valid loss:0.1062\n","Val metric mean prob: 0.1941\n","Best metric at: 0.5257 0.4740  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 18:52:54,034]\u001b[0m Trial 71 finished with value: 0.5257142857142858 and parameters: {'a1': 0.687620285428793, 'a2': 0.19529697829722914, 'a3': 0.02033448816140594, 'a4': 1.4687946054628993e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6931918112811827 0.193167449470196 0.021078939129934273 1.3423582413165255e-05 0.09254837653627386\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:07<00:00,  1.09s/it, eval_loss=0.1065, gpu_mem=7.81 GB]\n","Valid loss:0.1065\n","Val metric mean prob: 0.1940\n","Best metric at: 0.5227 0.4720  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 18:56:10,057]\u001b[0m Trial 72 finished with value: 0.5227272727272727 and parameters: {'a1': 0.6931918112811827, 'a2': 0.193167449470196, 'a3': 0.021078939129934273, 'a4': 1.3423582413165255e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7963916308793209 0.17539192874143125 0.018229071908870156 2.9727368539814926e-05 0.009957641101837921\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.07s/it, eval_loss=0.1083, gpu_mem=7.81 GB]\n","Valid loss:0.1083\n","Val metric mean prob: 0.1966\n","Best metric at: 0.5146 0.4960  0.7171\n","Cf: [[4639   27]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 18:59:22,597]\u001b[0m Trial 73 finished with value: 0.5146198830409356 and parameters: {'a1': 0.7963916308793209, 'a2': 0.17539192874143125, 'a3': 0.018229071908870156, 'a4': 2.9727368539814926e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7536107605066135 0.19522289563149745 0.021617193198769598 2.6619843121341515e-05 0.02952253081999815\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.08s/it, eval_loss=0.1074, gpu_mem=7.81 GB]\n","Valid loss:0.1074\n","Val metric mean prob: 0.1958\n","Best metric at: 0.5172 0.4840  0.7219\n","Cf: [[4637   29]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 19:02:37,727]\u001b[0m Trial 74 finished with value: 0.5172413793103449 and parameters: {'a1': 0.7536107605066135, 'a2': 0.19522289563149745, 'a3': 0.021617193198769598, 'a4': 2.6619843121341515e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.679309054937126 0.20921521656190437 0.01607950798407954 3.9881045031857305e-05 0.09535633947185823\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.07s/it, eval_loss=0.1061, gpu_mem=7.81 GB]\n","Valid loss:0.1061\n","Val metric mean prob: 0.1942\n","Best metric at: 0.5257 0.4720  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 19:05:49,905]\u001b[0m Trial 75 finished with value: 0.5257142857142858 and parameters: {'a1': 0.679309054937126, 'a2': 0.20921521656190437, 'a3': 0.01607950798407954, 'a4': 3.9881045031857305e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6824006380799754 0.21237306658450628 0.014597034727670186 1.6434708598007062e-05 0.09061282589925011\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1062, gpu_mem=7.81 GB]\n","Valid loss:0.1062\n","Val metric mean prob: 0.1942\n","Best metric at: 0.5257 0.4720  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 19:09:03,479]\u001b[0m Trial 76 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6824006380799754, 'a2': 0.21237306658450628, 'a3': 0.014597034727670186, 'a4': 1.6434708598007062e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6205841848517795 0.22373627115844574 0.03524005336455534 3.885413469519499e-05 0.12040063649052427\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.08s/it, eval_loss=0.1042, gpu_mem=7.81 GB]\n","Valid loss:0.1042\n","Val metric mean prob: 0.1964\n","Best metric at: 0.5143 0.4660  0.7218\n","Cf: [[4636   30]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 19:12:18,309]\u001b[0m Trial 77 finished with value: 0.5142857142857143 and parameters: {'a1': 0.6205841848517795, 'a2': 0.22373627115844574, 'a3': 0.03524005336455534, 'a4': 3.885413469519499e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7265944917127704 0.19161075948245132 0.016404404378159924 9.449105652053978e-06 0.06538089532096635\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1070, gpu_mem=7.81 GB]\n","Valid loss:0.1070\n","Val metric mean prob: 0.1945\n","Best metric at: 0.5176 0.4900  0.7172\n","Cf: [[4640   26]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 19:15:32,534]\u001b[0m Trial 78 finished with value: 0.5176470588235295 and parameters: {'a1': 0.7265944917127704, 'a2': 0.19161075948245132, 'a3': 0.016404404378159924, 'a4': 9.449105652053978e-06}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6830071831880451 0.2079615915003262 0.027010888103170514 1.6853729774424084e-05 0.08200348347868378\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.08s/it, eval_loss=0.1061, gpu_mem=7.81 GB]\n","Valid loss:0.1061\n","Val metric mean prob: 0.1946\n","Best metric at: 0.5257 0.4720  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 19:18:47,303]\u001b[0m Trial 79 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6830071831880451, 'a2': 0.2079615915003262, 'a3': 0.027010888103170514, 'a4': 1.6853729774424084e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.8014857316834075 0.17770733069424802 0.010252905235774826 2.1756464189776972e-05 0.010532275922379849\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.1083, gpu_mem=7.81 GB]\n","Valid loss:0.1083\n","Val metric mean prob: 0.1967\n","Best metric at: 0.5116 0.4910  0.7170\n","Cf: [[4638   28]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 19:22:00,019]\u001b[0m Trial 80 finished with value: 0.5116279069767442 and parameters: {'a1': 0.8014857316834075, 'a2': 0.17770733069424802, 'a3': 0.010252905235774826, 'a4': 2.1756464189776972e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.672570340499892 0.2133499034591051 0.021801083568911913 1.4765745449340317e-05 0.0922639067266417\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.09s/it, eval_loss=0.1058, gpu_mem=7.81 GB]\n","Valid loss:0.1058\n","Val metric mean prob: 0.1946\n","Best metric at: 0.5257 0.4740  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 19:25:15,412]\u001b[0m Trial 81 finished with value: 0.5257142857142858 and parameters: {'a1': 0.672570340499892, 'a2': 0.2133499034591051, 'a3': 0.021801083568911913, 'a4': 1.4765745449340317e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6314030700202911 0.2102406187759532 0.006024285562173996 2.6656580896775923e-05 0.15230536906068495\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:02<00:00,  1.06s/it, eval_loss=0.1047, gpu_mem=7.81 GB]\n","Valid loss:0.1047\n","Val metric mean prob: 0.1943\n","Best metric at: 0.5227 0.4600  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 19:28:25,922]\u001b[0m Trial 82 finished with value: 0.5227272727272727 and parameters: {'a1': 0.6314030700202911, 'a2': 0.2102406187759532, 'a3': 0.006024285562173996, 'a4': 2.6656580896775923e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6827754143967089 0.19577837233405657 0.013583431373304195 1.7913848432165607e-05 0.10784486804749821\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:07<00:00,  1.09s/it, eval_loss=0.1062, gpu_mem=7.81 GB]\n","Valid loss:0.1062\n","Val metric mean prob: 0.1936\n","Best metric at: 0.5257 0.4720  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 19:31:41,584]\u001b[0m Trial 83 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6827754143967089, 'a2': 0.19577837233405657, 'a3': 0.013583431373304195, 'a4': 1.7913848432165607e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7467932837779019 0.1993974766679745 0.01938970985179248 3.5776077746356076e-05 0.03438375362458478\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1074, gpu_mem=7.81 GB]\n","Valid loss:0.1074\n","Val metric mean prob: 0.1956\n","Best metric at: 0.5143 0.4820  0.7218\n","Cf: [[4636   30]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 19:34:55,654]\u001b[0m Trial 84 finished with value: 0.5142857142857143 and parameters: {'a1': 0.7467932837779019, 'a2': 0.1993974766679745, 'a3': 0.01938970985179248, 'a4': 3.5776077746356076e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7102798274022614 0.18521598753555032 0.015444184990466358 1.1699789591088853e-05 0.08904830028213086\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.07s/it, eval_loss=0.1068, gpu_mem=7.81 GB]\n","Valid loss:0.1068\n","Val metric mean prob: 0.1938\n","Best metric at: 0.5227 0.4740  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 19:38:08,225]\u001b[0m Trial 85 finished with value: 0.5227272727272727 and parameters: {'a1': 0.7102798274022614, 'a2': 0.18521598753555032, 'a3': 0.015444184990466358, 'a4': 1.1699789591088853e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7658308755427105 0.1869407777417932 0.01881373367126716 6.031843298012785e-05 0.028354294611249047\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:07<00:00,  1.09s/it, eval_loss=0.1078, gpu_mem=7.81 GB]\n","Valid loss:0.1078\n","Val metric mean prob: 0.1957\n","Best metric at: 0.5087 0.4870  0.7169\n","Cf: [[4637   29]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 19:41:24,279]\u001b[0m Trial 86 finished with value: 0.508670520231214 and parameters: {'a1': 0.7658308755427105, 'a2': 0.1869407777417932, 'a3': 0.01881373367126716, 'a4': 6.031843298012785e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6450035794567197 0.1526936385634463 0.03361878188244098 2.366833571201283e-05 0.16866033176168096\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.1050, gpu_mem=7.81 GB]\n","Valid loss:0.1050\n","Val metric mean prob: 0.1935\n","Best metric at: 0.5198 0.4600  0.7267\n","Cf: [[4635   31]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 19:44:37,522]\u001b[0m Trial 87 finished with value: 0.5197740112994351 and parameters: {'a1': 0.6450035794567197, 'a2': 0.1526936385634463, 'a3': 0.03361878188244098, 'a4': 2.366833571201283e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7288896552620069 0.1976774423858356 0.01673838210882015 3.1491875153943665e-05 0.056663028368183425\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.09s/it, eval_loss=0.1071, gpu_mem=7.81 GB]\n","Valid loss:0.1071\n","Val metric mean prob: 0.1948\n","Best metric at: 0.5176 0.4900  0.7172\n","Cf: [[4640   26]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 19:47:52,958]\u001b[0m Trial 88 finished with value: 0.5176470588235295 and parameters: {'a1': 0.7288896552620069, 'a2': 0.1976774423858356, 'a3': 0.01673838210882015, 'a4': 3.1491875153943665e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6034468789862806 0.21939043565054406 0.030248723962297355 4.0865000751898505e-05 0.1468730964001261\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.06s/it, eval_loss=0.1036, gpu_mem=7.81 GB]\n","Valid loss:0.1036\n","Val metric mean prob: 0.1966\n","Best metric at: 0.5143 0.4610  0.7218\n","Cf: [[4636   30]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 19:51:04,481]\u001b[0m Trial 89 finished with value: 0.5142857142857143 and parameters: {'a1': 0.6034468789862806, 'a2': 0.21939043565054406, 'a3': 0.030248723962297355, 'a4': 4.0865000751898505e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6843375768904149 0.2071971572287132 0.024471738419851487 1.6059652612952224e-05 0.08397746780840751\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1062, gpu_mem=7.81 GB]\n","Valid loss:0.1062\n","Val metric mean prob: 0.1946\n","Best metric at: 0.5257 0.4730  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 19:54:18,757]\u001b[0m Trial 90 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6843375768904149, 'a2': 0.2071971572287132, 'a3': 0.024471738419851487, 'a4': 1.6059652612952224e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.655023587517771 0.2085762330384155 0.02627041460882264 1.8388682552398113e-05 0.11011137615243846\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:07<00:00,  1.09s/it, eval_loss=0.1054, gpu_mem=7.81 GB]\n","Valid loss:0.1054\n","Val metric mean prob: 0.1947\n","Best metric at: 0.5227 0.4670  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 19:57:34,583]\u001b[0m Trial 91 finished with value: 0.5227272727272727 and parameters: {'a1': 0.655023587517771, 'a2': 0.2085762330384155, 'a3': 0.02627041460882264, 'a4': 1.8388682552398113e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6756816189930217 0.2044245912353998 0.028562127844167205 1.1966387367529643e-05 0.09131969554004377\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.07s/it, eval_loss=0.1059, gpu_mem=7.81 GB]\n","Valid loss:0.1059\n","Val metric mean prob: 0.1945\n","Best metric at: 0.5257 0.4730  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 20:00:46,881]\u001b[0m Trial 92 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6756816189930217, 'a2': 0.2044245912353998, 'a3': 0.028562127844167205, 'a4': 1.1966387367529643e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7167901659616648 0.18095989962945702 0.02254549529511276 1.6277766751390793e-05 0.07968816134701404\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.08s/it, eval_loss=0.1069, gpu_mem=7.81 GB]\n","Valid loss:0.1069\n","Val metric mean prob: 0.1942\n","Best metric at: 0.5227 0.4760  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 20:04:01,905]\u001b[0m Trial 93 finished with value: 0.5227272727272727 and parameters: {'a1': 0.7167901659616648, 'a2': 0.18095989962945702, 'a3': 0.02254549529511276, 'a4': 1.6277766751390793e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6261340789374773 0.2331097920468725 0.013135091694334376 2.5102423339569286e-05 0.12759593489797627\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.1046, gpu_mem=7.81 GB]\n","Valid loss:0.1046\n","Val metric mean prob: 0.1954\n","Best metric at: 0.5198 0.4600  0.7267\n","Cf: [[4635   31]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 20:07:14,716]\u001b[0m Trial 94 finished with value: 0.5197740112994351 and parameters: {'a1': 0.6261340789374773, 'a2': 0.2331097920468725, 'a3': 0.013135091694334376, 'a4': 2.5102423339569286e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6763665821536241 0.21922117556634088 0.026012632731011266 9.298332899857138e-06 0.0783903112161239\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1059, gpu_mem=7.81 GB]\n","Valid loss:0.1059\n","Val metric mean prob: 0.1951\n","Best metric at: 0.5257 0.4740  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 20:10:28,473]\u001b[0m Trial 95 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6763665821536241, 'a2': 0.21922117556634088, 'a3': 0.026012632731011266, 'a4': 9.298332899857138e-06}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6931438183451142 0.1950855891117063 0.020583495757089492 1.8819654679233562e-05 0.0911682771314108\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1065, gpu_mem=7.81 GB]\n","Valid loss:0.1065\n","Val metric mean prob: 0.1940\n","Best metric at: 0.5257 0.4750  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 20:13:42,577]\u001b[0m Trial 96 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6931438183451142, 'a2': 0.1950855891117063, 'a3': 0.020583495757089492, 'a4': 1.8819654679233562e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7595105257518409 0.18345539476350034 0.02007839658623937 4.526141020147994e-05 0.036910421488217944\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1076, gpu_mem=7.81 GB]\n","Valid loss:0.1076\n","Val metric mean prob: 0.1955\n","Best metric at: 0.5172 0.4840  0.7219\n","Cf: [[4637   29]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 20:16:56,990]\u001b[0m Trial 97 finished with value: 0.5172413793103449 and parameters: {'a1': 0.7595105257518409, 'a2': 0.18345539476350034, 'a3': 0.02007839658623937, 'a4': 4.526141020147994e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6042447978960186 0.16352827986204957 0.03650263031184101 5.5881181056969706e-05 0.19566841074903385\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.09s/it, eval_loss=0.1036, gpu_mem=7.81 GB]\n","Valid loss:0.1036\n","Val metric mean prob: 0.1948\n","Best metric at: 0.5165 0.4470  0.7312\n","Cf: [[4631   35]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 20:20:12,183]\u001b[0m Trial 98 finished with value: 0.5164835164835165 and parameters: {'a1': 0.6042447978960186, 'a2': 0.16352827986204957, 'a3': 0.03650263031184101, 'a4': 5.5881181056969706e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.5727508224723048 0.2335457436658237 0.009109419463740864 3.309855368363532e-05 0.184560915844447\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.07s/it, eval_loss=0.1024, gpu_mem=7.81 GB]\n","Valid loss:0.1024\n","Val metric mean prob: 0.1975\n","Best metric at: 0.5109 0.4380  0.7310\n","Cf: [[4629   37]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 20:23:24,686]\u001b[0m Trial 99 finished with value: 0.5108695652173914 and parameters: {'a1': 0.5727508224723048, 'a2': 0.2335457436658237, 'a3': 0.009109419463740864, 'a4': 3.309855368363532e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6481241217240905 0.21404019874312352 0.03241940996020449 1.36913626017975e-05 0.1054025782099797\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.08s/it, eval_loss=0.1051, gpu_mem=7.81 GB]\n","Valid loss:0.1051\n","Val metric mean prob: 0.1953\n","Best metric at: 0.5227 0.4660  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 20:26:39,644]\u001b[0m Trial 100 finished with value: 0.5227272727272727 and parameters: {'a1': 0.6481241217240905, 'a2': 0.21404019874312352, 'a3': 0.03241940996020449, 'a4': 1.36913626017975e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6688169028625413 0.2133236898961561 0.027675921518460492 2.135404549880578e-05 0.09016213167734335\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:00<00:00,  1.05s/it, eval_loss=0.1056, gpu_mem=7.81 GB]\n","Valid loss:0.1056\n","Val metric mean prob: 0.1950\n","Best metric at: 0.5227 0.4700  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 20:29:48,655]\u001b[0m Trial 101 finished with value: 0.5227272727272727 and parameters: {'a1': 0.6688169028625413, 'a2': 0.2133236898961561, 'a3': 0.027675921518460492, 'a4': 2.135404549880578e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6998579300563046 0.2028009785590304 0.022616463252970342 1.501482947658091e-05 0.07470961330221809\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:07<00:00,  1.09s/it, eval_loss=0.1067, gpu_mem=7.81 GB]\n","Valid loss:0.1067\n","Val metric mean prob: 0.1944\n","Best metric at: 0.5257 0.4770  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 20:33:04,775]\u001b[0m Trial 102 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6998579300563046, 'a2': 0.2028009785590304, 'a3': 0.022616463252970342, 'a4': 1.501482947658091e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7186841398244683 0.19071476292027179 0.023185780568625164 1.1880552151801697e-05 0.06740343613448292\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.08s/it, eval_loss=0.1069, gpu_mem=7.81 GB]\n","Valid loss:0.1069\n","Val metric mean prob: 0.1945\n","Best metric at: 0.5227 0.4780  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 20:36:19,390]\u001b[0m Trial 103 finished with value: 0.5227272727272727 and parameters: {'a1': 0.7186841398244683, 'a2': 0.19071476292027179, 'a3': 0.023185780568625164, 'a4': 1.1880552151801697e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6679530179955813 0.21612298051418236 0.01504761406766802 2.4459705079984738e-05 0.10085192771748837\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:01<00:00,  1.06s/it, eval_loss=0.1056, gpu_mem=7.81 GB]\n","Valid loss:0.1056\n","Val metric mean prob: 0.1946\n","Best metric at: 0.5227 0.4680  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 20:39:29,338]\u001b[0m Trial 104 finished with value: 0.5227272727272727 and parameters: {'a1': 0.6679530179955813, 'a2': 0.21612298051418236, 'a3': 0.01504761406766802, 'a4': 2.4459705079984738e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7439050576420775 0.20763285824239003 0.01734131908039091 1.4156470359211798e-05 0.031106608564782368\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:08<00:00,  1.09s/it, eval_loss=0.1073, gpu_mem=7.81 GB]\n","Valid loss:0.1073\n","Val metric mean prob: 0.1955\n","Best metric at: 0.5172 0.4860  0.7219\n","Cf: [[4637   29]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 20:42:46,278]\u001b[0m Trial 105 finished with value: 0.5172413793103449 and parameters: {'a1': 0.7439050576420775, 'a2': 0.20763285824239003, 'a3': 0.01734131908039091, 'a4': 1.4156470359211798e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6376886992800113 0.1704752374718264 0.006025331978514983 3.892180956807523e-05 0.18577180946007926\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.1048, gpu_mem=7.81 GB]\n","Valid loss:0.1048\n","Val metric mean prob: 0.1930\n","Best metric at: 0.5198 0.4570  0.7267\n","Cf: [[4635   31]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 20:45:59,739]\u001b[0m Trial 106 finished with value: 0.5197740112994351 and parameters: {'a1': 0.6376886992800113, 'a2': 0.1704752374718264, 'a3': 0.006025331978514983, 'a4': 3.892180956807523e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.692267375410491 0.19836927709196822 0.011805701273063369 1.9784154045046886e-05 0.09753786207043237\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:07<00:00,  1.09s/it, eval_loss=0.1065, gpu_mem=7.81 GB]\n","Valid loss:0.1065\n","Val metric mean prob: 0.1937\n","Best metric at: 0.5257 0.4750  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 20:49:15,312]\u001b[0m Trial 107 finished with value: 0.5257142857142858 and parameters: {'a1': 0.692267375410491, 'a2': 0.19836927709196822, 'a3': 0.011805701273063369, 'a4': 1.9784154045046886e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7865797999626485 0.1899180821116004 0.01716594574087167 1.6988067201927776e-05 0.006319184117677504\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:02<00:00,  1.06s/it, eval_loss=0.1081, gpu_mem=7.81 GB]\n","Valid loss:0.1081\n","Val metric mean prob: 0.1966\n","Best metric at: 0.5116 0.4940  0.7170\n","Cf: [[4638   28]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 20:52:26,061]\u001b[0m Trial 108 finished with value: 0.5116279069767442 and parameters: {'a1': 0.7865797999626485, 'a2': 0.1899180821116004, 'a3': 0.01716594574087167, 'a4': 1.6988067201927776e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.658924554776283 0.210070462011626 0.028752501419152622 2.8244470754761516e-05 0.10222423732218365\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.09s/it, eval_loss=0.1054, gpu_mem=7.81 GB]\n","Valid loss:0.1054\n","Val metric mean prob: 0.1949\n","Best metric at: 0.5227 0.4680  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 20:55:41,775]\u001b[0m Trial 109 finished with value: 0.5227272727272727 and parameters: {'a1': 0.658924554776283, 'a2': 0.210070462011626, 'a3': 0.028752501419152622, 'a4': 2.8244470754761516e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6147971403767891 0.22606933056852271 0.004957828536986815 6.93927815732193e-05 0.15410630773612813\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.1041, gpu_mem=7.81 GB]\n","Valid loss:0.1041\n","Val metric mean prob: 0.1952\n","Best metric at: 0.5169 0.4560  0.7266\n","Cf: [[4634   32]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 20:58:54,776]\u001b[0m Trial 110 finished with value: 0.5168539325842696 and parameters: {'a1': 0.6147971403767891, 'a2': 0.22606933056852271, 'a3': 0.004957828536986815, 'a4': 6.93927815732193e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6795278787354716 0.19575751773540312 0.012154264126212878 1.1189099023095861e-05 0.11254915030388932\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:01<00:00,  1.05s/it, eval_loss=0.1062, gpu_mem=7.81 GB]\n","Valid loss:0.1062\n","Val metric mean prob: 0.1935\n","Best metric at: 0.5257 0.4710  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 21:02:04,467]\u001b[0m Trial 111 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6795278787354716, 'a2': 0.19575751773540312, 'a3': 0.012154264126212878, 'a4': 1.1189099023095861e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7129184953841164 0.20188666709719097 0.019251631725284702 1.938283342668913e-05 0.0659238229599812\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:07<00:00,  1.09s/it, eval_loss=0.1068, gpu_mem=7.81 GB]\n","Valid loss:0.1068\n","Val metric mean prob: 0.1945\n","Best metric at: 0.5227 0.4760  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 21:05:20,678]\u001b[0m Trial 112 finished with value: 0.5227272727272727 and parameters: {'a1': 0.7129184953841164, 'a2': 0.20188666709719097, 'a3': 0.019251631725284702, 'a4': 1.938283342668913e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7394298328911938 0.17732241112986416 0.024479618424812 2.2251823427856154e-05 0.05874588573070219\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.07s/it, eval_loss=0.1073, gpu_mem=7.81 GB]\n","Valid loss:0.1073\n","Val metric mean prob: 0.1946\n","Best metric at: 0.5146 0.4880  0.7171\n","Cf: [[4639   27]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 21:08:32,984]\u001b[0m Trial 113 finished with value: 0.5146198830409356 and parameters: {'a1': 0.7394298328911938, 'a2': 0.17732241112986416, 'a3': 0.024479618424812, 'a4': 2.2251823427856154e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.687387251127517 0.18627795214442103 0.012465265961083303 3.327958058612198e-05 0.11383625118639258\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.08s/it, eval_loss=0.1063, gpu_mem=7.81 GB]\n","Valid loss:0.1063\n","Val metric mean prob: 0.1933\n","Best metric at: 0.5257 0.4730  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 21:11:46,642]\u001b[0m Trial 114 finished with value: 0.5257142857142858 and parameters: {'a1': 0.687387251127517, 'a2': 0.18627795214442103, 'a3': 0.012465265961083303, 'a4': 3.327958058612198e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6409708029177774 0.15786673783894972 0.03909352977058653 8.60779283727275e-05 0.1619828515443136\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.07s/it, eval_loss=0.1048, gpu_mem=7.81 GB]\n","Valid loss:0.1048\n","Val metric mean prob: 0.1939\n","Best metric at: 0.5169 0.4590  0.7266\n","Cf: [[4634   32]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 21:14:58,946]\u001b[0m Trial 115 finished with value: 0.5168539325842696 and parameters: {'a1': 0.6409708029177774, 'a2': 0.15786673783894972, 'a3': 0.03909352977058653, 'a4': 8.60779283727275e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7124255716844119 0.19580205773593082 0.021619195204004137 4.706420144530727e-05 0.07010611117420784\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.09s/it, eval_loss=0.1068, gpu_mem=7.81 GB]\n","Valid loss:0.1068\n","Val metric mean prob: 0.1944\n","Best metric at: 0.5227 0.4760  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 21:18:14,182]\u001b[0m Trial 116 finished with value: 0.5227272727272727 and parameters: {'a1': 0.7124255716844119, 'a2': 0.19580205773593082, 'a3': 0.021619195204004137, 'a4': 4.706420144530727e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7654301066247347 0.18249789289730192 0.020133643749432484 1.5824291753161546e-05 0.031922532436777784\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1078, gpu_mem=7.81 GB]\n","Valid loss:0.1078\n","Val metric mean prob: 0.1955\n","Best metric at: 0.5087 0.4860  0.7169\n","Cf: [[4637   29]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 21:21:28,177]\u001b[0m Trial 117 finished with value: 0.508670520231214 and parameters: {'a1': 0.7654301066247347, 'a2': 0.18249789289730192, 'a3': 0.020133643749432484, 'a4': 1.5824291753161546e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6686808887049085 0.17245637400847977 0.008281495776418474 5.992482908774112e-05 0.15052131668110552\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1058, gpu_mem=7.81 GB]\n","Valid loss:0.1058\n","Val metric mean prob: 0.1926\n","Best metric at: 0.5198 0.4630  0.7267\n","Cf: [[4635   31]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 21:24:42,138]\u001b[0m Trial 118 finished with value: 0.5197740112994351 and parameters: {'a1': 0.6686808887049085, 'a2': 0.17245637400847977, 'a3': 0.008281495776418474, 'a4': 5.992482908774112e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.5941292698797509 0.24481732911646517 0.03299636242790239 2.884754182370457e-05 0.12802819103405785\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:07<00:00,  1.09s/it, eval_loss=0.1033, gpu_mem=7.81 GB]\n","Valid loss:0.1033\n","Val metric mean prob: 0.1978\n","Best metric at: 0.5114 0.4600  0.7217\n","Cf: [[4635   31]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 21:27:58,031]\u001b[0m Trial 119 finished with value: 0.5113636363636364 and parameters: {'a1': 0.5941292698797509, 'a2': 0.24481732911646517, 'a3': 0.03299636242790239, 'a4': 2.884754182370457e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6321295631589738 0.22488111842635522 0.013840093581888232 9.485408244018248e-06 0.12913973942453869\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.06s/it, eval_loss=0.1047, gpu_mem=7.81 GB]\n","Valid loss:0.1047\n","Val metric mean prob: 0.1950\n","Best metric at: 0.5198 0.4600  0.7267\n","Cf: [[4635   31]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 21:31:09,700]\u001b[0m Trial 120 finished with value: 0.5197740112994351 and parameters: {'a1': 0.6321295631589738, 'a2': 0.22488111842635522, 'a3': 0.013840093581888232, 'a4': 9.485408244018248e-06}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6860561226187992 0.21003706891449364 0.023825797821584643 1.566925056789384e-05 0.0800653413945546\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:07<00:00,  1.09s/it, eval_loss=0.1062, gpu_mem=7.81 GB]\n","Valid loss:0.1062\n","Val metric mean prob: 0.1947\n","Best metric at: 0.5257 0.4730  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 21:34:25,446]\u001b[0m Trial 121 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6860561226187992, 'a2': 0.21003706891449364, 'a3': 0.023825797821584643, 'a4': 1.566925056789384e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6915829532729301 0.2067022813597329 0.014837489124235456 1.6854485396502203e-05 0.08686042175770509\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.08s/it, eval_loss=0.1064, gpu_mem=7.81 GB]\n","Valid loss:0.1064\n","Val metric mean prob: 0.1943\n","Best metric at: 0.5257 0.4750  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 21:37:38,861]\u001b[0m Trial 122 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6915829532729301, 'a2': 0.2067022813597329, 'a3': 0.014837489124235456, 'a4': 1.6854485396502203e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7293510831385785 0.20184662577797205 0.01775058485060982 1.357085507751871e-05 0.05103813537776206\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.1071, gpu_mem=7.81 GB]\n","Valid loss:0.1071\n","Val metric mean prob: 0.1949\n","Best metric at: 0.5198 0.4760  0.7267\n","Cf: [[4635   31]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 21:40:51,345]\u001b[0m Trial 123 finished with value: 0.5197740112994351 and parameters: {'a1': 0.7293510831385785, 'a2': 0.20184662577797205, 'a3': 0.01775058485060982, 'a4': 1.357085507751871e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6573342394419188 0.21820051852045394 0.02438149229257612 1.8796705164313193e-05 0.1000649530398868\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.08s/it, eval_loss=0.1054, gpu_mem=7.81 GB]\n","Valid loss:0.1054\n","Val metric mean prob: 0.1950\n","Best metric at: 0.5227 0.4670  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 21:44:12,546]\u001b[0m Trial 124 finished with value: 0.5227272727272727 and parameters: {'a1': 0.6573342394419188, 'a2': 0.21820051852045394, 'a3': 0.02438149229257612, 'a4': 1.8796705164313193e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6802550260450707 0.19284017040877682 0.025635926973122353 2.666850813766769e-05 0.10124220806489245\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.1061, gpu_mem=7.81 GB]\n","Valid loss:0.1061\n","Val metric mean prob: 0.1940\n","Best metric at: 0.5257 0.4720  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 21:47:25,450]\u001b[0m Trial 125 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6802550260450707, 'a2': 0.19284017040877682, 'a3': 0.025635926973122353, 'a4': 2.666850813766769e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6204102561196836 0.22882439848076463 0.02872315127578349 1.1312835566628264e-05 0.12203088128820166\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.09s/it, eval_loss=0.1042, gpu_mem=7.81 GB]\n","Valid loss:0.1042\n","Val metric mean prob: 0.1962\n","Best metric at: 0.5143 0.4660  0.7218\n","Cf: [[4636   30]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 21:50:40,802]\u001b[0m Trial 126 finished with value: 0.5142857142857143 and parameters: {'a1': 0.6204102561196836, 'a2': 0.22882439848076463, 'a3': 0.02872315127578349, 'a4': 1.1312835566628264e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7068798347657909 0.20484405040480222 0.021440549778803865 2.435194037764032e-05 0.06681121311022542\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:02<00:00,  1.06s/it, eval_loss=0.1068, gpu_mem=7.81 GB]\n","Valid loss:0.1068\n","Val metric mean prob: 0.1945\n","Best metric at: 0.5257 0.4790  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 21:53:51,898]\u001b[0m Trial 127 finished with value: 0.5257142857142858 and parameters: {'a1': 0.7068798347657909, 'a2': 0.20484405040480222, 'a3': 0.021440549778803865, 'a4': 2.435194037764032e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.738046146943643 0.1983836555098617 0.018400094737531774 3.538729510630915e-05 0.0451347155138572\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:07<00:00,  1.09s/it, eval_loss=0.1073, gpu_mem=7.81 GB]\n","Valid loss:0.1073\n","Val metric mean prob: 0.1950\n","Best metric at: 0.5176 0.4910  0.7172\n","Cf: [[4640   26]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 21:57:07,345]\u001b[0m Trial 128 finished with value: 0.5176470588235295 and parameters: {'a1': 0.738046146943643, 'a2': 0.1983836555098617, 'a3': 0.018400094737531774, 'a4': 3.538729510630915e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6547554917504229 0.21374459964249165 0.010167565680965206 4.735398394997925e-05 0.12128498894217025\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.08s/it, eval_loss=0.1054, gpu_mem=7.81 GB]\n","Valid loss:0.1054\n","Val metric mean prob: 0.1943\n","Best metric at: 0.5227 0.4650  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 22:00:22,446]\u001b[0m Trial 129 finished with value: 0.5227272727272727 and parameters: {'a1': 0.6547554917504229, 'a2': 0.21374459964249165, 'a3': 0.010167565680965206, 'a4': 4.735398394997925e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7620204923664773 0.18865656063820566 0.020848227712670225 1.2842640531966744e-05 0.028461876642114865\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.1076, gpu_mem=7.81 GB]\n","Valid loss:0.1076\n","Val metric mean prob: 0.1958\n","Best metric at: 0.5087 0.4860  0.7169\n","Cf: [[4637   29]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 22:03:34,904]\u001b[0m Trial 130 finished with value: 0.508670520231214 and parameters: {'a1': 0.7620204923664773, 'a2': 0.18865656063820566, 'a3': 0.020848227712670225, 'a4': 1.2842640531966744e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6694872453333305 0.20660134106540456 0.027523037386792643 1.028752441914479e-05 0.09637808869005317\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.09s/it, eval_loss=0.1057, gpu_mem=7.81 GB]\n","Valid loss:0.1057\n","Val metric mean prob: 0.1948\n","Best metric at: 0.5227 0.4690  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 22:06:50,168]\u001b[0m Trial 131 finished with value: 0.5227272727272727 and parameters: {'a1': 0.6694872453333305, 'a2': 0.20660134106540456, 'a3': 0.027523037386792643, 'a4': 1.028752441914479e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.6850318729376357 0.17923290407733916 0.030061983466724715 2.1366106322026102e-05 0.10565187341197842\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.07s/it, eval_loss=0.1062, gpu_mem=7.81 GB]\n","Valid loss:0.1062\n","Val metric mean prob: 0.1938\n","Best metric at: 0.5257 0.4740  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 22:10:02,647]\u001b[0m Trial 132 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6850318729376357, 'a2': 0.17923290407733916, 'a3': 0.030061983466724715, 'a4': 2.1366106322026102e-05}. Best is trial 4 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7161379137268007 0.20623246622827462 0.02244891205992213 1.3143642271354952e-05 0.0551675643427312\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.08s/it, eval_loss=0.1069, gpu_mem=7.81 GB]\n","Valid loss:0.1069\n","Val metric mean prob: 0.1949\n","Best metric at: 0.5287 0.4820  0.7270\n","Cf: [[4638   28]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 22:13:19,108]\u001b[0m Trial 133 finished with value: 0.5287356321839081 and parameters: {'a1': 0.7161379137268007, 'a2': 0.20623246622827462, 'a3': 0.02244891205992213, 'a4': 1.3143642271354952e-05}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7160403968649134 0.21635568058341997 0.022540611176005438 1.5537357983096255e-05 0.04504777401767811\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.1069, gpu_mem=7.81 GB]\n","Valid loss:0.1069\n","Val metric mean prob: 0.1951\n","Best metric at: 0.5287 0.4820  0.7270\n","Cf: [[4638   28]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 22:16:35,144]\u001b[0m Trial 134 finished with value: 0.5287356321839081 and parameters: {'a1': 0.7160403968649134, 'a2': 0.21635568058341997, 'a3': 0.022540611176005438, 'a4': 1.5537357983096255e-05}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7321591376918125 0.19882606194485647 0.022490482732248254 1.3717738576323641e-05 0.04651059989250644\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.08s/it, eval_loss=0.1072, gpu_mem=7.81 GB]\n","Valid loss:0.1072\n","Val metric mean prob: 0.1949\n","Best metric at: 0.5176 0.4900  0.7172\n","Cf: [[4640   26]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 22:19:50,032]\u001b[0m Trial 135 finished with value: 0.5176470588235295 and parameters: {'a1': 0.7321591376918125, 'a2': 0.19882606194485647, 'a3': 0.022490482732248254, 'a4': 1.3717738576323641e-05}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7131532313890583 0.2185189284146561 0.01888650541592253 1.8075567122081087e-05 0.04942325921324102\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.09s/it, eval_loss=0.1068, gpu_mem=7.81 GB]\n","Valid loss:0.1068\n","Val metric mean prob: 0.1951\n","Best metric at: 0.5287 0.4810  0.7270\n","Cf: [[4638   28]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 22:23:08,628]\u001b[0m Trial 136 finished with value: 0.5287356321839081 and parameters: {'a1': 0.7131532313890583, 'a2': 0.2185189284146561, 'a3': 0.01888650541592253, 'a4': 1.8075567122081087e-05}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7056985462855198 0.21853658957032457 0.019142406322394095 0.00014728234847471305 0.056475175473286864\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.07s/it, eval_loss=0.1067, gpu_mem=7.81 GB]\n","Valid loss:0.1067\n","Val metric mean prob: 0.1948\n","Best metric at: 0.5287 0.4790  0.7270\n","Cf: [[4638   28]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 22:26:23,446]\u001b[0m Trial 137 finished with value: 0.5287356321839081 and parameters: {'a1': 0.7056985462855198, 'a2': 0.21853658957032457, 'a3': 0.019142406322394095, 'a4': 0.00014728234847471305}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7166407668602199 0.22067174655588245 0.018895633472748613 0.00015913165334938533 0.04363272145779961\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1069, gpu_mem=7.81 GB]\n","Valid loss:0.1069\n","Val metric mean prob: 0.1951\n","Best metric at: 0.5287 0.4820  0.7270\n","Cf: [[4638   28]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 22:29:40,628]\u001b[0m Trial 138 finished with value: 0.5287356321839081 and parameters: {'a1': 0.7166407668602199, 'a2': 0.22067174655588245, 'a3': 0.018895633472748613, 'a4': 0.00015913165334938533}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7164795867549775 0.2212755469686591 0.018896176301353526 0.0001406351883577562 0.04320805478665216\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:01<00:00,  1.06s/it, eval_loss=0.1069, gpu_mem=7.81 GB]\n","Valid loss:0.1069\n","Val metric mean prob: 0.1951\n","Best metric at: 0.5287 0.4810  0.7270\n","Cf: [[4638   28]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 22:32:54,074]\u001b[0m Trial 139 finished with value: 0.5287356321839081 and parameters: {'a1': 0.7164795867549775, 'a2': 0.2212755469686591, 'a3': 0.018896176301353526, 'a4': 0.0001406351883577562}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7740831840598024 0.19163699375542748 0.01919962312704925 0.00013429660224973186 0.014945902455471179\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1078, gpu_mem=7.81 GB]\n","Valid loss:0.1078\n","Val metric mean prob: 0.1962\n","Best metric at: 0.5116 0.4900  0.7170\n","Cf: [[4638   28]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 22:36:09,665]\u001b[0m Trial 140 finished with value: 0.5116279069767442 and parameters: {'a1': 0.7740831840598024, 'a2': 0.19163699375542748, 'a3': 0.01919962312704925, 'a4': 0.00013429660224973186}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7153634723581573 0.22092211376655754 0.016384775911186925 0.00016710393251221723 0.04716253403158598\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:08<00:00,  1.09s/it, eval_loss=0.1069, gpu_mem=7.81 GB]\n","Valid loss:0.1069\n","Val metric mean prob: 0.1951\n","Best metric at: 0.5287 0.4810  0.7270\n","Cf: [[4638   28]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 22:39:29,480]\u001b[0m Trial 141 finished with value: 0.5287356321839081 and parameters: {'a1': 0.7153634723581573, 'a2': 0.22092211376655754, 'a3': 0.016384775911186925, 'a4': 0.00016710393251221723}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7149622477004827 0.22082199778852835 0.018430321822334634 0.00010758842651919704 0.04567784426213516\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.1068, gpu_mem=7.81 GB]\n","Valid loss:0.1068\n","Val metric mean prob: 0.1951\n","Best metric at: 0.5287 0.4810  0.7270\n","Cf: [[4638   28]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 22:42:45,372]\u001b[0m Trial 142 finished with value: 0.5287356321839081 and parameters: {'a1': 0.7149622477004827, 'a2': 0.22082199778852835, 'a3': 0.018430321822334634, 'a4': 0.00010758842651919704}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7186365149012336 0.2201351667412052 0.018327865149540015 0.0001644455001532191 0.04273600770786797\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.1069, gpu_mem=7.81 GB]\n","Valid loss:0.1069\n","Val metric mean prob: 0.1951\n","Best metric at: 0.5287 0.4830  0.7270\n","Cf: [[4638   28]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 22:46:01,385]\u001b[0m Trial 143 finished with value: 0.5287356321839081 and parameters: {'a1': 0.7186365149012336, 'a2': 0.2201351667412052, 'a3': 0.018327865149540015, 'a4': 0.0001644455001532191}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7480869889562265 0.22126658686554007 0.018403882665065013 0.0001628915123889621 0.012079650000779457\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:01<00:00,  1.06s/it, eval_loss=0.1073, gpu_mem=7.81 GB]\n","Valid loss:0.1073\n","Val metric mean prob: 0.1961\n","Best metric at: 0.5172 0.4850  0.7219\n","Cf: [[4637   29]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 22:49:11,774]\u001b[0m Trial 144 finished with value: 0.5172413793103449 and parameters: {'a1': 0.7480869889562265, 'a2': 0.22126658686554007, 'a3': 0.018403882665065013, 'a4': 0.0001628915123889621}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7163912761735531 0.21848953250984363 0.01634136018896071 0.00018889117635056735 0.04858893995129196\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1069, gpu_mem=7.81 GB]\n","Valid loss:0.1069\n","Val metric mean prob: 0.1950\n","Best metric at: 0.5257 0.4800  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 22:52:26,050]\u001b[0m Trial 145 finished with value: 0.5257142857142858 and parameters: {'a1': 0.7163912761735531, 'a2': 0.21848953250984363, 'a3': 0.01634136018896071, 'a4': 0.00018889117635056735}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7987047425938117 0.1961098143939149 0.002670362950098558 0.00014808404063111573 0.002366996021543687\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.07s/it, eval_loss=0.1084, gpu_mem=7.81 GB]\n","Valid loss:0.1084\n","Val metric mean prob: 0.1967\n","Best metric at: 0.5116 0.4930  0.7170\n","Cf: [[4638   28]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 22:55:37,727]\u001b[0m Trial 146 finished with value: 0.5116279069767442 and parameters: {'a1': 0.7987047425938117, 'a2': 0.1961098143939149, 'a3': 0.002670362950098558, 'a4': 0.00014808404063111573}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7243067027509831 0.22978979279724787 0.019644885955445175 0.00011076135808637687 0.026147857138237498\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1070, gpu_mem=7.81 GB]\n","Valid loss:0.1070\n","Val metric mean prob: 0.1957\n","Best metric at: 0.5287 0.4840  0.7270\n","Cf: [[4638   28]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 22:58:54,693]\u001b[0m Trial 147 finished with value: 0.5287356321839081 and parameters: {'a1': 0.7243067027509831, 'a2': 0.22978979279724787, 'a3': 0.019644885955445175, 'a4': 0.00011076135808637687}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7509113975214364 0.21927591629865842 0.019580730416701296 0.00011066216977079534 0.01012129359343306\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.08s/it, eval_loss=0.1074, gpu_mem=7.81 GB]\n","Valid loss:0.1074\n","Val metric mean prob: 0.1963\n","Best metric at: 0.5202 0.4900  0.7220\n","Cf: [[4638   28]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 23:02:09,637]\u001b[0m Trial 148 finished with value: 0.5202312138728323 and parameters: {'a1': 0.7509113975214364, 'a2': 0.21927591629865842, 'a3': 0.019580730416701296, 'a4': 0.00011066216977079534}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.779390186487934 0.21477280423162706 0.0036624516547597626 0.00012839371816400342 0.00204616390751516\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:02<00:00,  1.06s/it, eval_loss=0.1080, gpu_mem=7.81 GB]\n","Valid loss:0.1080\n","Val metric mean prob: 0.1965\n","Best metric at: 0.5116 0.4930  0.7170\n","Cf: [[4638   28]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 23:05:20,427]\u001b[0m Trial 149 finished with value: 0.5116279069767442 and parameters: {'a1': 0.779390186487934, 'a2': 0.21477280423162706, 'a3': 0.0036624516547597626, 'a4': 0.00012839371816400342}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7245120765561341 0.2297196071296325 0.017923750669294625 0.00010336706208318053 0.02774119858285556\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:06<00:00,  1.08s/it, eval_loss=0.1070, gpu_mem=7.81 GB]\n","Valid loss:0.1070\n","Val metric mean prob: 0.1955\n","Best metric at: 0.5287 0.4840  0.7270\n","Cf: [[4638   28]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 23:08:38,457]\u001b[0m Trial 150 finished with value: 0.5287356321839081 and parameters: {'a1': 0.7245120765561341, 'a2': 0.2297196071296325, 'a3': 0.017923750669294625, 'a4': 0.00010336706208318053}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7159894410117215 0.2320485127480304 0.018182557503182654 0.00010197074760083816 0.03367751798946465\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1069, gpu_mem=7.81 GB]\n","Valid loss:0.1069\n","Val metric mean prob: 0.1954\n","Best metric at: 0.5287 0.4820  0.7270\n","Cf: [[4638   28]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 23:11:55,094]\u001b[0m Trial 151 finished with value: 0.5287356321839081 and parameters: {'a1': 0.7159894410117215, 'a2': 0.2320485127480304, 'a3': 0.018182557503182654, 'a4': 0.00010197074760083816}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7230992023895036 0.23029685372818487 0.01775952670605297 0.00010744141218625617 0.028736975764072255\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:03<00:00,  1.07s/it, eval_loss=0.1070, gpu_mem=7.81 GB]\n","Valid loss:0.1070\n","Val metric mean prob: 0.1955\n","Best metric at: 0.5287 0.4830  0.7270\n","Cf: [[4638   28]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 23:15:10,491]\u001b[0m Trial 152 finished with value: 0.5287356321839081 and parameters: {'a1': 0.7230992023895036, 'a2': 0.23029685372818487, 'a3': 0.01775952670605297, 'a4': 0.00010744141218625617}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7226884648037131 0.23109085320714545 0.018096542315336438 0.00010512628305868384 0.028019013390746354\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:04<00:00,  1.07s/it, eval_loss=0.1070, gpu_mem=7.81 GB]\n","Valid loss:0.1070\n","Val metric mean prob: 0.1956\n","Best metric at: 0.5287 0.4830  0.7270\n","Cf: [[4638   28]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 23:18:26,707]\u001b[0m Trial 153 finished with value: 0.5287356321839081 and parameters: {'a1': 0.7226884648037131, 'a2': 0.23109085320714545, 'a3': 0.018096542315336438, 'a4': 0.00010512628305868384}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7294321748574224 0.23019033458184734 0.017797072661263572 0.00010911695740684524 0.02247130094205984\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1071, gpu_mem=7.81 GB]\n","Valid loss:0.1071\n","Val metric mean prob: 0.1956\n","Best metric at: 0.5227 0.4810  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 23:21:40,184]\u001b[0m Trial 154 finished with value: 0.5227272727272727 and parameters: {'a1': 0.7294321748574224, 'a2': 0.23019033458184734, 'a3': 0.017797072661263572, 'a4': 0.00010911695740684524}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7216545268232657 0.23718054461871213 0.018435554538362417 0.00018115696154496095 0.022548217058114797\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:09<00:00,  1.10s/it, eval_loss=0.1070, gpu_mem=7.81 GB]\n","Valid loss:0.1070\n","Val metric mean prob: 0.1957\n","Best metric at: 0.5287 0.4830  0.7270\n","Cf: [[4638   28]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 23:25:00,968]\u001b[0m Trial 155 finished with value: 0.5287356321839081 and parameters: {'a1': 0.7216545268232657, 'a2': 0.23718054461871213, 'a3': 0.018435554538362417, 'a4': 0.00018115696154496095}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.756601740646172 0.22323819805627493 0.007053719243254243 0.00018265190986090887 0.012923690144437892\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:02<00:00,  1.06s/it, eval_loss=0.1074, gpu_mem=7.81 GB]\n","Valid loss:0.1074\n","Val metric mean prob: 0.1962\n","Best metric at: 0.5172 0.4850  0.7219\n","Cf: [[4637   29]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 23:28:11,849]\u001b[0m Trial 156 finished with value: 0.5172413793103449 and parameters: {'a1': 0.756601740646172, 'a2': 0.22323819805627493, 'a3': 0.007053719243254243, 'a4': 0.00018265190986090887}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth\n","0.7174932742526814 0.2377459576216479 0.01804071900649787 0.0002212485903798395 0.026498800528792995\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 172/172 [03:05<00:00,  1.08s/it, eval_loss=0.1068, gpu_mem=7.81 GB]\n","Valid loss:0.1068\n","Val metric mean prob: 0.1957\n","Best metric at: 0.5287 0.4820  0.7270\n","Cf: [[4638   28]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 23:31:29,343]\u001b[0m Trial 157 finished with value: 0.5287356321839081 and parameters: {'a1': 0.7174932742526814, 'a2': 0.2377459576216479, 'a3': 0.01804071900649787, 'a4': 0.0002212485903798395}. Best is trial 133 with value: 0.5287356321839081.\u001b[0m\n","\u001b[33m[W 2023-02-24 23:31:29,354]\u001b[0m Trial 158 failed with parameters: {'a1': 0.8111272587592091, 'a2': 0.1854941131543417, 'a3': 0.032858629785276094} because of the following error: ValueError('The `low` value must be smaller than or equal to the `high` value (low=9e-06, high=-0.030480001698826892).').\u001b[0m\n","Traceback (most recent call last):\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n","    value_or_values = func(trial)\n","  File \"/tmp/ipykernel_30113/2110198947.py\", line 33, in objective\n","    a4 = trial.suggest_loguniform('a4', 0.000009, 1-a1-a2-a3-0.001)\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/_deprecated.py\", line 113, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/trial/_trial.py\", line 203, in suggest_loguniform\n","    return self.suggest_float(name, low, high, log=True)\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/trial/_trial.py\", line 156, in suggest_float\n","    distribution = FloatDistribution(low, high, log=log, step=step)\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/distributions.py\", line 147, in __init__\n","    raise ValueError(\n","ValueError: The `low` value must be smaller than or equal to the `high` value (low=9e-06, high=-0.030480001698826892).\n","\u001b[33m[W 2023-02-24 23:31:29,372]\u001b[0m Trial 158 failed with value None.\u001b[0m\n"]},{"ename":"ValueError","evalue":"The `low` value must be smaller than or equal to the `high` value (low=9e-06, high=-0.030480001698826892).","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[37], line 132\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[39mreturn\u001b[39;00m best_metric\n\u001b[1;32m    131\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m, sampler \u001b[39m=\u001b[39m TPESampler(seed\u001b[39m=\u001b[39m\u001b[39m777\u001b[39m))\n\u001b[0;32m--> 132\u001b[0m study\u001b[39m.\u001b[39;49moptimize(func\u001b[39m=\u001b[39;49mobjective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n\u001b[1;32m    133\u001b[0m study\u001b[39m.\u001b[39mbest_params\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    332\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \n\u001b[1;32m    334\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     _optimize(\n\u001b[1;32m    426\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    427\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    428\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    429\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    430\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    431\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    432\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    433\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    434\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    435\u001b[0m     )\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n","Cell \u001b[0;32mIn[37], line 33\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     31\u001b[0m a3 \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39msuggest_uniform(\u001b[39m'\u001b[39m\u001b[39ma3\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0.00009\u001b[39m, \u001b[39m1\u001b[39m\u001b[39m-\u001b[39ma1\u001b[39m-\u001b[39ma2\u001b[39m-\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[39m# a4 = 1-a1-a2-a3\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m a4 \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39;49msuggest_loguniform(\u001b[39m'\u001b[39;49m\u001b[39ma4\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m0.000009\u001b[39;49m, \u001b[39m1\u001b[39;49m\u001b[39m-\u001b[39;49ma1\u001b[39m-\u001b[39;49ma2\u001b[39m-\u001b[39;49ma3\u001b[39m-\u001b[39;49m\u001b[39m0.001\u001b[39;49m)\n\u001b[1;32m     34\u001b[0m a5 \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\u001b[39m-\u001b[39ma1\u001b[39m-\u001b[39ma2\u001b[39m-\u001b[39ma3\u001b[39m-\u001b[39ma4\n\u001b[1;32m     35\u001b[0m \u001b[39m# a5 = trial.suggest_loguniform('a5', 0.0000009, 1-a1-a2-a3-a4-0.001)\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/_deprecated.py:113\u001b[0m, in \u001b[0;36mdeprecated_func.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m text\n\u001b[1;32m    111\u001b[0m warnings\u001b[39m.\u001b[39mwarn(message, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m--> 113\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/trial/_trial.py:203\u001b[0m, in \u001b[0;36mTrial.suggest_loguniform\u001b[0;34m(self, name, low, high)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39m@deprecated_func\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m3.0.0\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m6.0.0\u001b[39m\u001b[39m\"\u001b[39m, text\u001b[39m=\u001b[39m_suggest_deprecated_msg)\n\u001b[1;32m    184\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msuggest_loguniform\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m, low: \u001b[39mfloat\u001b[39m, high: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[1;32m    185\u001b[0m     \u001b[39m\"\"\"Suggest a value for the continuous parameter.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \n\u001b[1;32m    187\u001b[0m \u001b[39m    The value is sampled from the range :math:`[\\\\mathsf{low}, \\\\mathsf{high})`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39m        A suggested float value.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuggest_float(name, low, high, log\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/trial/_trial.py:156\u001b[0m, in \u001b[0;36mTrial.suggest_float\u001b[0;34m(self, name, low, high, step, log)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msuggest_float\u001b[39m(\n\u001b[1;32m     71\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     72\u001b[0m     name: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m     log: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     78\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[1;32m     79\u001b[0m     \u001b[39m\"\"\"Suggest a value for the floating point parameter.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \n\u001b[1;32m     81\u001b[0m \u001b[39m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39m        :ref:`configurations` tutorial describes more details and flexible usages.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     distribution \u001b[39m=\u001b[39m FloatDistribution(low, high, log\u001b[39m=\u001b[39;49mlog, step\u001b[39m=\u001b[39;49mstep)\n\u001b[1;32m    157\u001b[0m     suggested_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_suggest(name, distribution)\n\u001b[1;32m    158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_distribution(name, distribution)\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/distributions.py:147\u001b[0m, in \u001b[0;36mFloatDistribution.__init__\u001b[0;34m(self, low, high, log, step)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe parameter `step` is not supported when `log` is true.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    146\u001b[0m \u001b[39mif\u001b[39;00m low \u001b[39m>\u001b[39m high:\n\u001b[0;32m--> 147\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    148\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe `low` value must be smaller than or equal to the `high` value \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(low=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, high=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(low, high)\n\u001b[1;32m    150\u001b[0m     )\n\u001b[1;32m    152\u001b[0m \u001b[39mif\u001b[39;00m log \u001b[39mand\u001b[39;00m low \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m    153\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe `low` value must be larger than 0 for a log distribution \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(low=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, high=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(low, high)\n\u001b[1;32m    156\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: The `low` value must be smaller than or equal to the `high` value (low=9e-06, high=-0.030480001698826892)."]}],"source":["\n","# set_seed(1)\n","# out_file = 'swa_triple_ensemble_model_fold0_5.pth' \n","# iteration = [\n","#     # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth',\n","#     # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth',\n","#     'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth',\n","#     'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth',\n","    \n","#     'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth',\n","#     'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth',\n","#     'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth',\n","    \n","#     # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_8_0.4403_0.415.pth',\n","# #     'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_11_0.4387_0.436.pth'\n","# ]\n","\n","# criterion = nn.CrossEntropyLoss().to(CFG.device)\n","# best_metric = 0\n","# torch.cuda.empty_cache()\n","# def objective(trial):\n","# #     a1 = 0.036839841333967636 \n","# #     a2 = 0.6490629183820655\n","# #     a3 = 0.3140972402839668\n","# #     a2 = 0.47142151346976024 \n","# #     a3 = 0.3596277792186039\n","# #     a1 = trial.suggest_uniform('a1', 0.01, 0.99)\n","# #     a2 = 1-a1\n","#     a1 = trial.suggest_uniform('a1', 0.001, 0.99)\n","#     # a2 = 1-a1\n","#     a2 = trial.suggest_uniform('a2', 0.0009, 1-a1-0.001)\n","#     a3 = trial.suggest_uniform('a3', 0.00009, 1-a1-a2-0.001)\n","#     # a4 = 1-a1-a2-a3\n","#     a4 = trial.suggest_loguniform('a4', 0.000009, 1-a1-a2-a3-0.001)\n","#     a5 = 1-a1-a2-a3-a4\n","#     # a5 = trial.suggest_loguniform('a5', 0.0000009, 1-a1-a2-a3-a4-0.001)\n","#     a6 = 1-a1-a2-a3-a4-a5\n","# #     a5 = trial.suggest_loguniform('a5', 0.000009, 1-a1-a2-a3-a4-0.001)\n","# #     a6 = trial.suggest_loguniform('a6', 0.0000009, 1-a1-a2-a3-a4-a5-0.001)\n","# #     a7 = 1-a1-a2-a3-a4-a5-a6\n","#     state_dict = None\n","#     for i in iteration:\n","#         f = i\n","#         f = torch.load(f, map_location=lambda storage, loc: storage)\n","#         if state_dict is None:\n","#             print(\"none: \", i)\n","#             state_dict = f['state_dict']\n","#             key = list(f['state_dict'].keys())\n","#             for k in key:\n","#                 state_dict[k] = f['state_dict'][k]*a1\n","#         elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth':\n","#             print(\"noob\", i)\n","#             key = list(f['state_dict'].keys())\n","#             for k in key:\n","#                 state_dict[k] = state_dict[k] + a2*f['state_dict'][k]\n","#         elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth':\n","#             print(\"noob\", i)\n","#             key = list(f['state_dict'].keys())\n","#             for k in key:\n","#                 state_dict[k] = state_dict[k] + a3*f['state_dict'][k]\n","                \n","#         elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth':\n","#             print(\"noob\", i)\n","#             key = list(f['state_dict'].keys())\n","#             for k in key:\n","#                 state_dict[k] = state_dict[k] + a4*f['state_dict'][k]\n","#         elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth':\n","#             print(\"noob\", i)\n","#             key = list(f['state_dict'].keys())\n","#             for k in key:\n","#                 state_dict[k] = state_dict[k] + a5*f['state_dict'][k]\n","#         # elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth':\n","#         #     print(\"noob\", i)\n","#         #     key = list(f['state_dict'].keys())\n","#         #     for k in key:\n","#         #         state_dict[k] = state_dict[k] + a6*f['state_dict'][k]\n","#     print(a1, a2, a3, a4, a5)\n","#     # for k in key:\n","#     #     state_dict[k] = state_dict[k] / len(iteration)\n","#     print('')\n","\n","#     # print(out_file)\n","#     torch.save({'state_dict': state_dict}, out_file)\n","\n","#     model = ModelOld(model_name=CFG.model_name).to(CFG.device)\n","#     checkpoint = torch.load(\"swa_triple_ensemble_model_fold0_5.pth\")\n","#     model.load_state_dict(checkpoint['state_dict'])\n","# #     model = nn.DataParallel(model)\n","\n","#     loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","#     valid_preds = valid_preds[:, 1]\n","#     valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n","#     valid_preds = np.array(valid_preds).flatten()\n","    \n","#     valid_df['raw_pred'] = valid_preds\n","#     LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n","#     grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n","#     grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n","#     valid_labels_mean = grp_df['cancer'].values\n","#     valid_preds_mean = grp_df['raw_pred'].values\n","#     # print(valid_labels[:5], valid_preds_mean[:5])\n","#     val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n","#     LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n","#     best_metric_mean_at_epoch = 0\n","#     best_metric = 0\n","    \n","#     best_threshold_mean = 0\n","#     best_auc = 0\n","#     best_cf = None\n","#     for i in np.arange(0.001, 0.599, 0.001):\n","#         valid_argmax = (valid_preds_mean>i).astype(np.int32)\n","#         val_metric = pfbeta_np(valid_labels_mean, valid_argmax)\n","#         val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n","#         val_f1 = f1_score(valid_labels_mean, valid_argmax)\n","#         val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n","#         cf = confusion_matrix(valid_labels_mean, valid_argmax)\n","#         if val_metric> best_metric:\n","#             best_metric = val_metric\n","#             # best_metric_mean_at_epoch = val_metric\n","#             best_threshold_mean = i\n","#             best_auc = val_auc\n","#             best_cf = cf\n","#     if best_metric>0.5269:\n","#         state = {'state_dict': model.state_dict()}\n","#         path = f'swa_{CFG.model_name}_fold_{fold}_model_{best_metric:.4f}_{best_threshold_mean:.4f}.pth'\n","#         torch.save(state, path)\n","    \n","#     LOGGER.info(f\"Best metric at: {best_metric:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n","#     LOGGER.info(f\"Cf: {best_cf}\")\n","#     return best_metric\n","\n","# study = optuna.create_study(direction='maximize', sampler = TPESampler(seed=777))\n","# study.optimize(func=objective, n_trials=1000)\n","# study.best_params\n","# # # 0.5563409550491111 0.4436590449508889 fold 0\n","# # # 0.12634002523631388 0.8351954705276587 0.03846450423602743 0.5393 \n","# # # 0.583301614081906 0.3673525472043472 0.04934583871374687 fold 2 0.50\n","# # # 0.1689507073116359 0.47142151346976024 0.3596277792186039 fold 2 0.5055 0.5055 0.3670  0.7261"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Fold 1/10"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2023-02-24 23:41:25,945]\u001b[0m A new study created in memory with name: no-name-e21dbbda-5be0-464b-9149-8bf3d3e52735\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["> SEEDING DONE\n","none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_9_0.4681_0.319.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n"]}],"source":["def pfbeta_np(labels, preds, beta=1):\n","    preds = preds.clip(0, 1)\n","    y_true_count = labels.sum()\n","    ctp = preds[labels==1].sum()\n","    cfp = preds[labels==0].sum()\n","    beta_squared = beta * beta\n","    c_precision = ctp / (ctp + cfp)\n","    c_recall = ctp / y_true_count\n","    if (c_precision > 0 and c_recall > 0):\n","        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n","        return result\n","    else:\n","        return 0.0\n","# fold=3\n","# valid_df = df[df['fold']==fold].reset_index(drop=True)\n","# valid_dataset = BreastDataset(valid_df, transforms=data_transforms['valid'])\n","\n","valid_loader = DataLoader(valid_dataset, batch_size = CFG.valid_bs, \n","                                num_workers=1, shuffle=False, drop_last=False)\n","set_seed(1)\n","out_file = 'swa_model_fold2_5.pth' \n","iteration = [\n","    'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth',\n","    'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_9_0.4681_0.319.pth',\n","    'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth',\n","    'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4585_0.236.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4557_0.241.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_10_0.4550_0.245.pth',\n","]\n","\n","criterion = nn.CrossEntropyLoss().to(CFG.device)\n","best_metric = 0\n","torch.cuda.empty_cache()\n","def objective(trial):\n","#     a2 = 0.12003546043452194 \n","#     a3 = 0.8649578775769542\n","#     a1 = 0.020317850755860567 \n","#     a2 = 0.1293785181217534 \n","#     a3 = 0.850303631122386\n","    # a1 = 0.2\n","    # a2 = 0.2    \n","    # a3 = 0.2\n","    # a4 = 0.2\n","    # a5 = 0.2\n","    # a1 = 1\n","    a1 = trial.suggest_uniform('a1', 0.001, 0.99)\n","    a2 = trial.suggest_uniform('a2', 0.0009, 1-a1-0.001)\n","    a3 = trial.suggest_uniform('a3', 0.0009, 1-a1-a2-0.001)\n","    a4 = 1-a1-a2-a3\n","    # a4 = trial.suggest_loguniform('a4', 0.0009, 1-a1-a2-a3-0.001)\n","    # a5 = 1-a1-a2-a3-a4\n","    # a5 = trial.suggest_loguniform('a5', 0.00009, 1-a1-a2-a3-a4-0.001)\n","    # a6 = 1-a1-a2-a3-a4-a5\n","    # a4 = 1-a1-a2-a3\n","    # a1 = 0.4700450486328235 \n","    # a2 = 0.23862687145742947 \n","    # a3 = 0.2913280799097471\n","    state_dict = None\n","    for i in iteration:\n","        f = i\n","        # print(f)\n","        f = torch.load(f, map_location=lambda storage, loc: storage)\n","        if state_dict is None:\n","            print(\"none: \", i)\n","            state_dict = f['state_dict']\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = f['state_dict'][k]*a1\n","        elif i=='fold2/tf_efficientnetv2_b2_fold_2_model_epoch_9_0.4681_0.319.pth': \n","            print(\"hehe\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a2*f['state_dict'][k]\n","        elif i=='fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth': \n","            print(\"hehe\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a3*f['state_dict'][k]\n","        elif i=='fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4585_0.236.pth':\n","            print(\"noob\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a4*f['state_dict'][k]\n","        # elif i=='fold2/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4557_0.241.pth':\n","        #     print(\"noobie\", i)\n","        #     key = list(f['state_dict'].keys())\n","        #     for k in key:\n","        #         state_dict[k] = state_dict[k] + a5*f['state_dict'][k]\n","        # elif i=='fold2/tf_efficientnetv2_b2_fold_2_model_epoch_10_0.4550_0.245.pth':\n","        #     print(\"noobie\", i)\n","        #     key = list(f['state_dict'].keys())\n","        #     for k in key:\n","        #         state_dict[k] = state_dict[k] + a6*f['state_dict'][k]\n","    print(a1, a2, a3, a4)\n","    # for k in key:\n","    #     state_dict[k] = state_dict[k] / len(iteration)\n","    print('')\n","\n","    # print(out_file)\n","    torch.save({'state_dict': state_dict}, out_file)\n","\n","    model = ModelOld(model_name=CFG.model_name).to(CFG.device)\n","    checkpoint = torch.load(\"swa_model_fold2_5.pth\")\n","    model.load_state_dict(checkpoint['state_dict'])\n","#     model = nn.DataParallel(model)\n","\n","    loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","    valid_preds = valid_preds[:, 1]\n","    valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n","    valid_preds = np.array(valid_preds).flatten()\n","    \n","    valid_df['raw_pred'] = valid_preds\n","    LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n","    grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n","    grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n","    valid_labels_mean = grp_df['cancer'].values\n","    valid_preds_mean = grp_df['raw_pred'].values\n","    # print(valid_labels[:5], valid_preds_mean[:5])\n","    val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n","    LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n","    best_metric_mean_at_epoch = 0\n","    best_metric = 0\n","    \n","    best_threshold_mean = 0\n","    best_auc = 0\n","    best_cf = None\n","    for i in np.arange(0.001, 0.599, 0.001):\n","        valid_argmax = (valid_preds_mean>i).astype(np.int32)\n","        val_metric = pfbeta_np(valid_labels_mean, valid_argmax)\n","        val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n","        val_f1 = f1_score(valid_labels_mean, valid_argmax)\n","        val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n","        cf = confusion_matrix(valid_labels_mean, valid_argmax)\n","        if val_metric> best_metric:\n","            best_metric = val_metric\n","            # best_metric_mean_at_epoch = val_metric\n","            best_threshold_mean = i\n","            best_auc = val_auc\n","            best_cf = cf\n","    if best_metric>0.52:\n","        state = {'state_dict': model.state_dict()}\n","        path = f'swa_{CFG.model_name}_fold_{fold}_model_{best_metric:.4f}_{best_threshold_mean:.3f}.pth'\n","        torch.save(state, path)\n","    \n","    LOGGER.info(f\"Best metric at: {best_metric:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n","    LOGGER.info(f\"Cf: {best_cf}\")\n","    torch.cuda.empty_cache()\n","    return best_metric\n","\n","study = optuna.create_study(direction='maximize', sampler = TPESampler(seed=777))\n","study.optimize(func=objective, n_trials=200)\n","study.best_params"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Fold 0/10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2023-02-20 02:57:33,097]\u001b[0m A new study created in memory with name: no-name-3aa99082-12ec-4dbc-a712-bb22940d30a2\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["> SEEDING DONE\n","none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.5825_0.137.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5679_0.380.pth\n","0.15198443381740748 0.25672863401172846 0.591286932170864\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 86/86 [01:31<00:00,  1.06s/it, eval_loss=0.0752, gpu_mem=9.00 GB]\n","Valid loss:0.0752\n","Val metric mean prob: 0.3495\n","Best metric at: 0.5783 0.4180  0.7428\n","Cf: [[2324   10]\n"," [  25   24]]\n","\u001b[32m[I 2023-02-20 02:59:12,325]\u001b[0m Trial 0 finished with value: 0.5783132530120482 and parameters: {'a1': 0.15198443381740748, 'a2': 0.25672863401172846}. Best is trial 0 with value: 0.5783132530120482.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.5825_0.137.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5679_0.380.pth\n","0.06235401415270182 0.43121246871095986 0.5064335171363383\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 86/86 [01:24<00:00,  1.02it/s, eval_loss=0.0807, gpu_mem=9.00 GB]\n","Valid loss:0.0807\n","Val metric mean prob: 0.3465\n","Best metric at: 0.5500 0.4880  0.7226\n","Cf: [[2325    9]\n"," [  27   22]]\n","\u001b[32m[I 2023-02-20 03:00:44,629]\u001b[0m Trial 1 finished with value: 0.5499999999999999 and parameters: {'a1': 0.06235401415270182, 'a2': 0.43121246871095986}. Best is trial 0 with value: 0.5783132530120482.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.5825_0.137.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5679_0.380.pth\n","0.8270655972088143 0.15944838645109546 0.013486016340090196\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 86/86 [01:20<00:00,  1.06it/s, eval_loss=0.0676, gpu_mem=9.00 GB]\n","Valid loss:0.0676\n","Val metric mean prob: 0.3122\n","Best metric at: 0.6042 0.2300  0.7921\n","Cf: [[2316   18]\n"," [  20   29]]\n","\u001b[32m[I 2023-02-20 03:02:18,706]\u001b[0m Trial 2 finished with value: 0.6041666666666666 and parameters: {'a1': 0.8270655972088143, 'a2': 0.15944838645109546}. Best is trial 2 with value: 0.6041666666666666.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.5825_0.137.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5679_0.380.pth\n","0.7199921054915603 0.21462486621604113 0.06538302829239853\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 86/86 [01:23<00:00,  1.03it/s, eval_loss=0.0683, gpu_mem=9.00 GB]\n","Valid loss:0.0683\n","Val metric mean prob: 0.3252\n","Best metric at: 0.6265 0.3310  0.7636\n","Cf: [[2326    8]\n"," [  23   26]]\n","\u001b[32m[I 2023-02-20 03:03:53,523]\u001b[0m Trial 3 finished with value: 0.6265060240963856 and parameters: {'a1': 0.7199921054915603, 'a2': 0.21462486621604113}. Best is trial 3 with value: 0.6265060240963856.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.5825_0.137.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5679_0.380.pth\n","0.2672438107409991 0.4715927941741754 0.2611633950848255\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 86/86 [01:28<00:00,  1.03s/it, eval_loss=0.0777, gpu_mem=9.00 GB]\n","Valid loss:0.0777\n","Val metric mean prob: 0.3499\n","Best metric at: 0.5823 0.4800  0.7332\n","Cf: [[2327    7]\n"," [  26   23]]\n","\u001b[32m[I 2023-02-20 03:05:29,940]\u001b[0m Trial 4 finished with value: 0.5822784810126582 and parameters: {'a1': 0.2672438107409991, 'a2': 0.4715927941741754}. Best is trial 3 with value: 0.6265060240963856.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.5825_0.137.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5679_0.380.pth\n","0.09334615100410686 0.07299611171763565 0.8336577372782575\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 86/86 [01:23<00:00,  1.03it/s, eval_loss=0.0732, gpu_mem=9.00 GB]\n","Valid loss:0.0732\n","Val metric mean prob: 0.3482\n","Best metric at: 0.5854 0.3850  0.7430\n","Cf: [[2325    9]\n"," [  25   24]]\n","\u001b[32m[I 2023-02-20 03:07:00,922]\u001b[0m Trial 5 finished with value: 0.5853658536585367 and parameters: {'a1': 0.09334615100410686, 'a2': 0.07299611171763565}. Best is trial 3 with value: 0.6265060240963856.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.5825_0.137.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5679_0.380.pth\n","0.5841280021678498 0.1430333685445009 0.27283862928764935\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 86/86 [01:26<00:00,  1.01s/it, eval_loss=0.0681, gpu_mem=9.00 GB]\n","Valid loss:0.0681\n","Val metric mean prob: 0.3378\n","Best metric at: 0.6078 0.2200  0.8116\n","Cf: [[2312   22]\n"," [  18   31]]\n","\u001b[32m[I 2023-02-20 03:08:35,874]\u001b[0m Trial 6 finished with value: 0.6078431372549019 and parameters: {'a1': 0.5841280021678498, 'a2': 0.1430333685445009}. Best is trial 3 with value: 0.6265060240963856.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.5825_0.137.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5679_0.380.pth\n","0.9789985109384551 0.01286657109614868 0.008134917965396185\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 86/86 [01:24<00:00,  1.02it/s, eval_loss=0.0681, gpu_mem=9.00 GB]\n","Valid loss:0.0681\n","Val metric mean prob: 0.2791\n","Best metric at: 0.5895 0.1590  0.7819\n","Cf: [[2316   18]\n"," [  21   28]]\n","\u001b[32m[I 2023-02-20 03:10:08,346]\u001b[0m Trial 7 finished with value: 0.5894736842105263 and parameters: {'a1': 0.9789985109384551, 'a2': 0.01286657109614868}. Best is trial 3 with value: 0.6265060240963856.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.5825_0.137.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5679_0.380.pth\n","0.6752797077033628 0.1791797060334395 0.14554058626319774\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 86/86 [01:26<00:00,  1.01s/it, eval_loss=0.0680, gpu_mem=9.00 GB]\n","Valid loss:0.0680\n","Val metric mean prob: 0.3296\n","Best metric at: 0.6154 0.2230  0.8216\n","Cf: [[2311   23]\n"," [  17   32]]\n","\u001b[32m[I 2023-02-20 03:11:45,916]\u001b[0m Trial 8 finished with value: 0.6153846153846153 and parameters: {'a1': 0.6752797077033628, 'a2': 0.1791797060334395}. Best is trial 3 with value: 0.6265060240963856.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.5825_0.137.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5679_0.380.pth\n","0.2669025972514883 0.27382629391412533 0.45927110883438643\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 86/86 [01:23<00:00,  1.03it/s, eval_loss=0.0736, gpu_mem=9.00 GB]\n","Valid loss:0.0736\n","Val metric mean prob: 0.3501\n","Best metric at: 0.5745 0.3680  0.7717\n","Cf: [[2316   18]\n"," [  22   27]]\n","\u001b[32m[I 2023-02-20 03:13:17,551]\u001b[0m Trial 9 finished with value: 0.5744680851063829 and parameters: {'a1': 0.2669025972514883, 'a2': 0.27382629391412533}. Best is trial 3 with value: 0.6265060240963856.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.5825_0.137.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5679_0.380.pth\n","0.4561712336624775 0.35094144785237463 0.1928873184851479\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 86/86 [01:21<00:00,  1.05it/s, eval_loss=0.0723, gpu_mem=9.00 GB]\n","Valid loss:0.0723\n","Val metric mean prob: 0.3450\n","Best metric at: 0.5823 0.4330  0.7332\n","Cf: [[2327    7]\n"," [  26   23]]\n","\u001b[32m[I 2023-02-20 03:14:46,946]\u001b[0m Trial 10 finished with value: 0.5822784810126582 and parameters: {'a1': 0.4561712336624775, 'a2': 0.35094144785237463}. Best is trial 3 with value: 0.6265060240963856.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.5825_0.137.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5679_0.380.pth\n","0.6876988626090789 0.1763789844093658 0.13592215298155533\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 86/86 [01:23<00:00,  1.03it/s, eval_loss=0.0679, gpu_mem=9.00 GB]\n","Valid loss:0.0679\n","Val metric mean prob: 0.3283\n","Best metric at: 0.6154 0.2170  0.8216\n","Cf: [[2311   23]\n"," [  17   32]]\n","\u001b[32m[I 2023-02-20 03:16:21,583]\u001b[0m Trial 11 finished with value: 0.6153846153846153 and parameters: {'a1': 0.6876988626090789, 'a2': 0.1763789844093658}. Best is trial 3 with value: 0.6265060240963856.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.5825_0.137.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5679_0.380.pth\n","0.7196627263572118 0.11167256191777697 0.16866471172501118\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 86/86 [01:21<00:00,  1.06it/s, eval_loss=0.0673, gpu_mem=9.00 GB]\n","Valid loss:0.0673\n","Val metric mean prob: 0.3242\n","Best metric at: 0.6214 0.1990  0.8218\n","Cf: [[2312   22]\n"," [  17   32]]\n","\u001b[32m[I 2023-02-20 03:17:54,172]\u001b[0m Trial 12 finished with value: 0.6213592233009709 and parameters: {'a1': 0.7196627263572118, 'a2': 0.11167256191777697}. Best is trial 3 with value: 0.6265060240963856.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.5825_0.137.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5679_0.380.pth\n","0.8466542804410013 0.023707587717395208 0.12963813184160347\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 86/86 [01:24<00:00,  1.02it/s, eval_loss=0.0672, gpu_mem=9.00 GB]\n","Valid loss:0.0672\n","Val metric mean prob: 0.3030\n","Best metric at: 0.6078 0.1700  0.8116\n","Cf: [[2312   22]\n"," [  18   31]]\n","\u001b[32m[I 2023-02-20 03:19:26,181]\u001b[0m Trial 13 finished with value: 0.6078431372549019 and parameters: {'a1': 0.8466542804410013, 'a2': 0.023707587717395208}. Best is trial 3 with value: 0.6265060240963856.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.5825_0.137.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5679_0.380.pth\n","0.49226018958047907 0.09501277816556337 0.4127270322539576\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 86/86 [01:21<00:00,  1.05it/s, eval_loss=0.0682, gpu_mem=9.00 GB]\n","Valid loss:0.0682\n","Val metric mean prob: 0.3451\n","Best metric at: 0.6122 0.2260  0.8021\n","Cf: [[2315   19]\n"," [  19   30]]\n","\u001b[32m[I 2023-02-20 03:20:58,873]\u001b[0m Trial 14 finished with value: 0.6122448979591837 and parameters: {'a1': 0.49226018958047907, 'a2': 0.09501277816556337}. Best is trial 3 with value: 0.6265060240963856.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.5825_0.137.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5679_0.380.pth\n","0.7573547792478401 0.1147595840397917 0.1278856367123682\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 86/86 [01:24<00:00,  1.02it/s, eval_loss=0.0673, gpu_mem=9.00 GB]\n","Valid loss:0.0673\n","Val metric mean prob: 0.3197\n","Best metric at: 0.6214 0.1960  0.8218\n","Cf: [[2312   22]\n"," [  17   32]]\n","\u001b[32m[I 2023-02-20 03:22:34,079]\u001b[0m Trial 15 finished with value: 0.6213592233009709 and parameters: {'a1': 0.7573547792478401, 'a2': 0.1147595840397917}. Best is trial 3 with value: 0.6265060240963856.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.5825_0.137.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5679_0.380.pth\n","0.6014868231979391 0.2184741724966588 0.1800390043054021\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 86/86 [01:25<00:00,  1.01it/s, eval_loss=0.0689, gpu_mem=9.00 GB]\n","Valid loss:0.0689\n","Val metric mean prob: 0.3364\n","Best metric at: 0.6173 0.3680  0.7536\n","Cf: [[2327    7]\n"," [  24   25]]\n","\u001b[32m[I 2023-02-20 03:24:10,466]\u001b[0m Trial 16 finished with value: 0.617283950617284 and parameters: {'a1': 0.6014868231979391, 'a2': 0.2184741724966588}. Best is trial 3 with value: 0.6265060240963856.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.5825_0.137.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5679_0.380.pth\n","0.9643696763259075 0.0042684483938768 0.03136187528021567\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 86/86 [01:24<00:00,  1.01it/s, eval_loss=0.0680, gpu_mem=9.00 GB]\n","Valid loss:0.0680\n","Val metric mean prob: 0.2808\n","Best metric at: 0.5895 0.1590  0.7819\n","Cf: [[2316   18]\n"," [  21   28]]\n","\u001b[32m[I 2023-02-20 03:25:43,325]\u001b[0m Trial 17 finished with value: 0.5894736842105263 and parameters: {'a1': 0.9643696763259075, 'a2': 0.0042684483938768}. Best is trial 3 with value: 0.6265060240963856.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.5825_0.137.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5679_0.380.pth\n","0.8456044398642144 0.05556661187953133 0.09882894825625427\n","\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[33m[W 2023-02-20 03:25:46,784]\u001b[0m Trial 18 failed with parameters: {'a1': 0.8456044398642144, 'a2': 0.05556661187953133} because of the following error: KeyboardInterrupt().\u001b[0m\n","Traceback (most recent call last):\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n","    value_or_values = func(trial)\n","  File \"/tmp/ipykernel_12286/3795447351.py\", line 108, in objective\n","    checkpoint = torch.load(\"swa_model_fold0_10.pth\")\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/serialization.py\", line 772, in load\n","    if _is_zipfile(opened_file):\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/serialization.py\", line 78, in _is_zipfile\n","    byte = f.read(1)\n","KeyboardInterrupt\n","\u001b[33m[W 2023-02-20 03:25:46,800]\u001b[0m Trial 18 failed with value None.\u001b[0m\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 155\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39m# seed 777 fold 3\u001b[39;00m\n\u001b[1;32m    154\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m, sampler \u001b[39m=\u001b[39m TPESampler(seed\u001b[39m=\u001b[39m\u001b[39m777\u001b[39m))\n\u001b[0;32m--> 155\u001b[0m study\u001b[39m.\u001b[39;49moptimize(func\u001b[39m=\u001b[39;49mobjective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n\u001b[1;32m    156\u001b[0m study\u001b[39m.\u001b[39mbest_params\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    332\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \n\u001b[1;32m    334\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     _optimize(\n\u001b[1;32m    426\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    427\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    428\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    429\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    430\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    431\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    432\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    433\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    434\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    435\u001b[0m     )\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n","Cell \u001b[0;32mIn[25], line 108\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    105\u001b[0m     torch\u001b[39m.\u001b[39msave({\u001b[39m'\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m'\u001b[39m: state_dict}, out_file)\n\u001b[1;32m    107\u001b[0m     model \u001b[39m=\u001b[39m ModelOld(model_name\u001b[39m=\u001b[39mCFG\u001b[39m.\u001b[39mmodel_name)\u001b[39m.\u001b[39mto(CFG\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 108\u001b[0m     checkpoint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mswa_model_fold0_10.pth\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    109\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(checkpoint[\u001b[39m'\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    110\u001b[0m \u001b[39m#     model = nn.DataParallel(model)\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/serialization.py:772\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    769\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    771\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m--> 772\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    773\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    775\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n\u001b[1;32m    777\u001b[0m         \u001b[39mwith\u001b[39;00m _open_zipfile_reader(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/serialization.py:78\u001b[0m, in \u001b[0;36m_is_zipfile\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     75\u001b[0m read_bytes \u001b[39m=\u001b[39m []\n\u001b[1;32m     76\u001b[0m start \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mtell()\n\u001b[0;32m---> 78\u001b[0m byte \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49mread(\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     79\u001b[0m \u001b[39mwhile\u001b[39;00m byte \u001b[39m!=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     80\u001b[0m     read_bytes\u001b[39m.\u001b[39mappend(byte)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","set_seed(1)\n","out_file = 'swa_model_fold0_10.pth' \n","iteration = [\n","    'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.5825_0.137.pth',\n","    'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth',\n","    'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5679_0.380.pth', \n","]\n","\n","criterion = nn.CrossEntropyLoss().to(CFG.device)\n","best_metric = 0\n","torch.cuda.empty_cache()\n","def objective(trial):\n","    # a1 = 0.036839841333967636 \n","    # a2 = 0.6490629183820655\n","    # a3 = 0.3140972402839668\n","    # a2 = 0.47142151346976024 \n","    # a3 = 0.3596277792186039\n","    a1 = trial.suggest_uniform('a1', 0.001, 0.99)\n","    # a2 = 1-a1\n","    # a1 = trial.suggest_uniform('a1', 0.001, 0.99)\n","    a2 = trial.suggest_uniform('a2', 0.0009, 1-a1-0.001)\n","    a3 = 1-a1-a2\n","    # a3 = trial.suggest_uniform('a3', 0.0009, 1-a1-a2-0.001)\n","    # a4 = 1-a1-a2-a3\n","    # a4 = trial.suggest_uniform('a4', 0.0009, 1-a1-a2-a3-0.001)\n","    # a5 = 1-a1-a2-a3-a4\n","    # a5_lower = max(0.0009, 1-a1-a2-a3-a4-0.999)\n","    # a5 = trial.suggest_loguniform('a5', a5_lower, 1-a1-a2-a3-a4-0.001)\n","    # a6  =1-a1-a2-a3-a4-a5\n","    # a6 = trial.suggest_loguniform('a6', 0.00006, 1-a1-a2-a3-a4-a5)\n","    # a7 = 1-a1-a2-a3-a4-a5-a6\n","    # a1 = 0.24757534134332052 \n","    # a2 = 0.10196581218020337 \n","    # a3 = 0.08626526314257006 \n","    # a4 = 0.09079196656355407 \n","    # a5 = 0.473401616770352\n","    state_dict = None\n","    for i in iteration:\n","        f = i\n","        f = torch.load(f, map_location=lambda storage, loc: storage)\n","        if state_dict is None:\n","            print(\"none: \", i)\n","            state_dict = f['state_dict']\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = f['state_dict'][k]*a1\n","        elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth': \n","            print(\"hehe\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a2*f['state_dict'][k]\n","        elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5679_0.380.pth':\n","            print(\"noob\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a3*f['state_dict'][k]\n","        # elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_2_0.5510_0.151.pth':\n","        #     print(\"noob\", i)\n","        #     key = list(f['state_dict'].keys())\n","        #     for k in key:\n","        #         state_dict[k] = state_dict[k] + a4*f['state_dict'][k]\n","                \n","        # elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth':\n","        #     print(\"noob\", i)\n","        #     key = list(f['state_dict'].keys())\n","        #     for k in key:\n","        #         state_dict[k] = state_dict[k] + a5*f['state_dict'][k]\n","        # elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth':\n","        #     print(\"noob\", i)\n","        #     key = list(f['state_dict'].keys())\n","        #     for k in key:\n","        #         state_dict[k] = state_dict[k] + a6*f['state_dict'][k]\n","        # elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth':\n","        #     print(\"noob\", i)\n","        #     key = list(f['state_dict'].keys())\n","        #     for k in key:\n","        #         state_dict[k] = state_dict[k] + a7*f['state_dict'][k]\n","    print(a1, a2, a3)\n","    # for k in key:\n","    #     state_dict[k] = state_dict[k] / len(iteration)\n","    print('')\n","\n","    # print(out_file)\n","    torch.save({'state_dict': state_dict}, out_file)\n","\n","    model = ModelOld(model_name=CFG.model_name).to(CFG.device)\n","    checkpoint = torch.load(\"swa_model_fold0_10.pth\")\n","    model.load_state_dict(checkpoint['state_dict'])\n","#     model = nn.DataParallel(model)\n","\n","    loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","    valid_preds = valid_preds[:, 1]\n","    valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n","    valid_preds = np.array(valid_preds).flatten()\n","    \n","    valid_df['raw_pred'] = valid_preds\n","    LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n","    grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n","    grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n","    valid_labels_mean = grp_df['cancer'].values\n","    valid_preds_mean = grp_df['raw_pred'].values\n","    # print(valid_labels[:5], valid_preds_mean[:5])\n","    val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n","    LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n","    best_metric_mean_at_epoch = 0\n","    best_metric = 0\n","    \n","    best_threshold_mean = 0\n","    best_auc = 0\n","    best_cf = None\n","    for i in np.arange(0.001, 0.599, 0.001):\n","        valid_argmax = (valid_preds_mean>i).astype(np.int32)\n","        val_metric = pfbeta_np(valid_labels_mean, valid_argmax)\n","        val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n","        val_f1 = f1_score(valid_labels_mean, valid_argmax)\n","        val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n","        cf = confusion_matrix(valid_labels_mean, valid_argmax)\n","        if val_metric> best_metric:\n","            best_metric = val_metric\n","            # best_metric_mean_at_epoch = val_metric\n","            best_threshold_mean = i\n","            best_auc = val_auc\n","            best_cf = cf\n","    if best_metric > 0.61:\n","        state = {'state_dict': model.state_dict()}\n","        path = f'swa_diffaug_{CFG.model_name}_fold_{fold}_model_{best_metric:.4f}_{best_threshold_mean:.4f}.pth'\n","        torch.save(state, path)\n","    \n","    LOGGER.info(f\"Best metric at: {best_metric:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n","    LOGGER.info(f\"Cf: {best_cf}\")\n","    return best_metric\n","# seed 777 fold 3\n","study = optuna.create_study(direction='maximize', sampler = TPESampler(seed=777))\n","study.optimize(func=objective, n_trials=200)\n","study.best_params\n","# # 0.5563409550491111 0.4436590449508889 fold 0\n","# # 0.12634002523631388 0.8351954705276587 0.03846450423602743 0.5393 \n","# # 0.583301614081906 0.3673525472043472 0.04934583871374687 fold 2 0.50\n","# # 0.1689507073116359 0.47142151346976024 0.3596277792186039 fold 2 0.5055 0.5055 0.3670  0.7261"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Fold 2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2023-02-18 00:12:15,175]\u001b[0m A new study created in memory with name: no-name-1cf6bd6d-d453-4b38-99c1-19a712c38d45\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["> SEEDING DONE\n","none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.15198443381740748 0.25672863401172846 0.591286932170864\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.03s/it, eval_loss=0.1082, gpu_mem=8.82 GB]\n","Valid loss:0.1082\n","Val metric mean prob: 0.2358\n","Best metric at: 0.4390 0.4660  0.6737\n","Cf: [[2334   13]\n"," [  33   18]]\n","\u001b[32m[I 2023-02-18 00:14:04,971]\u001b[0m Trial 0 finished with value: 0.4390243902439025 and parameters: {'a1': 0.15198443381740748, 'a2': 0.25672863401172846}. Best is trial 0 with value: 0.4390243902439025.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.06235401415270182 0.43121246871095986 0.5064335171363383\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.01s/it, eval_loss=0.1057, gpu_mem=8.82 GB]\n","Valid loss:0.1057\n","Val metric mean prob: 0.2324\n","Best metric at: 0.4337 0.4290  0.6735\n","Cf: [[2333   14]\n"," [  33   18]]\n","\u001b[32m[I 2023-02-18 00:15:49,759]\u001b[0m Trial 1 finished with value: 0.43373493975903615 and parameters: {'a1': 0.06235401415270182, 'a2': 0.43121246871095986}. Best is trial 0 with value: 0.4390243902439025.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.8270655972088143 0.15944838645109546 0.013486016340090196\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:33<00:00,  1.02it/s, eval_loss=0.0998, gpu_mem=8.82 GB]\n","Valid loss:0.0998\n","Val metric mean prob: 0.2219\n","Best metric at: 0.4348 0.3980  0.6916\n","Cf: [[2326   21]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 00:17:31,449]\u001b[0m Trial 2 finished with value: 0.43478260869565216 and parameters: {'a1': 0.8270655972088143, 'a2': 0.15944838645109546}. Best is trial 0 with value: 0.4390243902439025.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.7199921054915603 0.21462486621604113 0.06538302829239853\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.01s/it, eval_loss=0.1000, gpu_mem=8.82 GB]\n","Valid loss:0.1000\n","Val metric mean prob: 0.2254\n","Best metric at: 0.4390 0.4520  0.6737\n","Cf: [[2334   13]\n"," [  33   18]]\n","\u001b[32m[I 2023-02-18 00:19:21,125]\u001b[0m Trial 3 finished with value: 0.4390243902439025 and parameters: {'a1': 0.7199921054915603, 'a2': 0.21462486621604113}. Best is trial 0 with value: 0.4390243902439025.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.2672438107409991 0.4715927941741754 0.2611633950848255\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.00s/it, eval_loss=0.1009, gpu_mem=8.82 GB]\n","Valid loss:0.1009\n","Val metric mean prob: 0.2309\n","Best metric at: 0.4598 0.3980  0.6927\n","Cf: [[2331   16]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 00:21:05,633]\u001b[0m Trial 4 finished with value: 0.4597701149425288 and parameters: {'a1': 0.2672438107409991, 'a2': 0.4715927941741754}. Best is trial 4 with value: 0.4597701149425288.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.09334615100410686 0.07299611171763565 0.8336577372782575\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1151, gpu_mem=8.82 GB]\n","Valid loss:0.1151\n","Val metric mean prob: 0.2308\n","Best metric at: 0.4000 0.3930  0.6989\n","Cf: [[2314   33]\n"," [  30   21]]\n","\u001b[32m[I 2023-02-18 00:22:56,967]\u001b[0m Trial 5 finished with value: 0.39999999999999997 and parameters: {'a1': 0.09334615100410686, 'a2': 0.07299611171763565}. Best is trial 4 with value: 0.4597701149425288.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5841280021678498 0.1430333685445009 0.27283862928764935\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.03s/it, eval_loss=0.1028, gpu_mem=8.82 GB]\n","Valid loss:0.1028\n","Val metric mean prob: 0.2341\n","Best metric at: 0.4468 0.4410  0.7012\n","Cf: [[2325   22]\n"," [  30   21]]\n","\u001b[32m[I 2023-02-18 00:24:43,906]\u001b[0m Trial 6 finished with value: 0.44680851063829785 and parameters: {'a1': 0.5841280021678498, 'a2': 0.1430333685445009}. Best is trial 4 with value: 0.4597701149425288.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.9789985109384551 0.01286657109614868 0.008134917965396185\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1007, gpu_mem=8.82 GB]\n","Valid loss:0.1007\n","Val metric mean prob: 0.2184\n","Best metric at: 0.4146 0.4700  0.6637\n","Cf: [[2333   14]\n"," [  34   17]]\n","\u001b[32m[I 2023-02-18 00:26:33,573]\u001b[0m Trial 7 finished with value: 0.4146341463414634 and parameters: {'a1': 0.9789985109384551, 'a2': 0.01286657109614868}. Best is trial 4 with value: 0.4597701149425288.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.6752797077033628 0.1791797060334395 0.14554058626319774\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1011, gpu_mem=8.82 GB]\n","Valid loss:0.1011\n","Val metric mean prob: 0.2286\n","Best metric at: 0.4368 0.4430  0.6827\n","Cf: [[2330   17]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 00:28:24,386]\u001b[0m Trial 8 finished with value: 0.4367816091954023 and parameters: {'a1': 0.6752797077033628, 'a2': 0.1791797060334395}. Best is trial 4 with value: 0.4597701149425288.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.2669025972514883 0.27382629391412533 0.45927110883438643\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.1053, gpu_mem=8.82 GB]\n","Valid loss:0.1053\n","Val metric mean prob: 0.2366\n","Best metric at: 0.4419 0.4370  0.6829\n","Cf: [[2331   16]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 00:30:13,964]\u001b[0m Trial 9 finished with value: 0.4418604651162791 and parameters: {'a1': 0.2669025972514883, 'a2': 0.27382629391412533}. Best is trial 4 with value: 0.4597701149425288.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.387757743001335 0.6109498989347721 0.001292358063892829\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.0966, gpu_mem=8.82 GB]\n","Valid loss:0.0966\n","Val metric mean prob: 0.2200\n","Best metric at: 0.4545 0.3690  0.6925\n","Cf: [[2330   17]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 00:32:00,040]\u001b[0m Trial 10 finished with value: 0.4545454545454546 and parameters: {'a1': 0.387757743001335, 'a2': 0.6109498989347721}. Best is trial 4 with value: 0.4597701149425288.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.320518711276845 0.6282325223401696 0.05124876638298537\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.0972, gpu_mem=8.82 GB]\n","Valid loss:0.0972\n","Val metric mean prob: 0.2213\n","Best metric at: 0.4545 0.3680  0.6925\n","Cf: [[2330   17]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 00:33:45,658]\u001b[0m Trial 11 finished with value: 0.4545454545454546 and parameters: {'a1': 0.320518711276845, 'a2': 0.6282325223401696}. Best is trial 4 with value: 0.4597701149425288.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4046346334821459 0.5870217229711038 0.008343643546750323\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.0969, gpu_mem=8.82 GB]\n","Valid loss:0.0969\n","Val metric mean prob: 0.2207\n","Best metric at: 0.4545 0.3720  0.6925\n","Cf: [[2330   17]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 00:35:31,989]\u001b[0m Trial 12 finished with value: 0.4545454545454546 and parameters: {'a1': 0.4046346334821459, 'a2': 0.5870217229711038}. Best is trial 4 with value: 0.4597701149425288.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.43107148439101994 0.4889954670518225 0.07993304855715755\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.0983, gpu_mem=8.82 GB]\n","Valid loss:0.0983\n","Val metric mean prob: 0.2252\n","Best metric at: 0.4651 0.4050  0.6929\n","Cf: [[2332   15]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 00:37:18,570]\u001b[0m Trial 13 finished with value: 0.46511627906976744 and parameters: {'a1': 0.43107148439101994, 'a2': 0.4889954670518225}. Best is trial 13 with value: 0.46511627906976744.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5183309358075145 0.40787643382464156 0.07379263036784389\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.0987, gpu_mem=8.82 GB]\n","Valid loss:0.0987\n","Val metric mean prob: 0.2260\n","Best metric at: 0.4444 0.4150  0.6739\n","Cf: [[2335   12]\n"," [  33   18]]\n","\u001b[32m[I 2023-02-18 00:39:04,498]\u001b[0m Trial 14 finished with value: 0.4444444444444445 and parameters: {'a1': 0.5183309358075145, 'a2': 0.40787643382464156}. Best is trial 13 with value: 0.46511627906976744.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.27296437628256587 0.4964255502224143 0.23061007349501983\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1004, gpu_mem=8.82 GB]\n","Valid loss:0.1004\n","Val metric mean prob: 0.2296\n","Best metric at: 0.4651 0.4040  0.6929\n","Cf: [[2332   15]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 00:40:50,873]\u001b[0m Trial 15 finished with value: 0.46511627906976744 and parameters: {'a1': 0.27296437628256587, 'a2': 0.4964255502224143}. Best is trial 13 with value: 0.46511627906976744.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.46967533564383324 0.3450342119882751 0.18529045236789166\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.1006, gpu_mem=8.82 GB]\n","Valid loss:0.1006\n","Val metric mean prob: 0.2306\n","Best metric at: 0.4706 0.4310  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 00:42:44,124]\u001b[0m Trial 16 finished with value: 0.47058823529411764 and parameters: {'a1': 0.46967533564383324, 'a2': 0.3450342119882751}. Best is trial 16 with value: 0.47058823529411764.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4774369437245228 0.33903119249856983 0.18353186377690744\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:39<00:00,  1.03s/it, eval_loss=0.1006, gpu_mem=8.82 GB]\n","Valid loss:0.1006\n","Val metric mean prob: 0.2305\n","Best metric at: 0.4706 0.4330  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 00:44:39,341]\u001b[0m Trial 17 finished with value: 0.47058823529411764 and parameters: {'a1': 0.4774369437245228, 'a2': 0.33903119249856983}. Best is trial 16 with value: 0.47058823529411764.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5264225719211554 0.3091857239682668 0.1643917041105778\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:34<00:00,  1.02it/s, eval_loss=0.1006, gpu_mem=8.82 GB]\n","Valid loss:0.1006\n","Val metric mean prob: 0.2298\n","Best metric at: 0.4524 0.4360  0.6833\n","Cf: [[2333   14]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 00:46:21,880]\u001b[0m Trial 18 finished with value: 0.45238095238095244 and parameters: {'a1': 0.5264225719211554, 'a2': 0.3091857239682668}. Best is trial 16 with value: 0.47058823529411764.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.598201902756248 0.30460286712520707 0.09719523011854497\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.01s/it, eval_loss=0.0997, gpu_mem=8.82 GB]\n","Valid loss:0.0997\n","Val metric mean prob: 0.2271\n","Best metric at: 0.4390 0.4480  0.6737\n","Cf: [[2334   13]\n"," [  33   18]]\n","\u001b[32m[I 2023-02-18 00:48:06,895]\u001b[0m Trial 19 finished with value: 0.4390243902439025 and parameters: {'a1': 0.598201902756248, 'a2': 0.30460286712520707}. Best is trial 16 with value: 0.47058823529411764.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4581511551937867 0.35162908700804124 0.19021975779817207\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:39<00:00,  1.03s/it, eval_loss=0.1006, gpu_mem=8.82 GB]\n","Valid loss:0.1006\n","Val metric mean prob: 0.2306\n","Best metric at: 0.4706 0.4310  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 00:50:02,011]\u001b[0m Trial 20 finished with value: 0.47058823529411764 and parameters: {'a1': 0.4581511551937867, 'a2': 0.35162908700804124}. Best is trial 16 with value: 0.47058823529411764.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4637063502669432 0.349897676770888 0.1863959729621688\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.03s/it, eval_loss=0.1006, gpu_mem=8.82 GB]\n","Valid loss:0.1006\n","Val metric mean prob: 0.2305\n","Best metric at: 0.4706 0.4290  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 00:51:52,679]\u001b[0m Trial 21 finished with value: 0.47058823529411764 and parameters: {'a1': 0.4637063502669432, 'a2': 0.349897676770888}. Best is trial 16 with value: 0.47058823529411764.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.3718566368162158 0.36073416437700845 0.2674091988067758\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.1015, gpu_mem=8.82 GB]\n","Valid loss:0.1015\n","Val metric mean prob: 0.2332\n","Best metric at: 0.4706 0.4330  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 00:53:41,770]\u001b[0m Trial 22 finished with value: 0.47058823529411764 and parameters: {'a1': 0.3718566368162158, 'a2': 0.36073416437700845}. Best is trial 16 with value: 0.47058823529411764.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5262097046619402 0.32841288150894715 0.14537741382911268\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.03s/it, eval_loss=0.1002, gpu_mem=8.82 GB]\n","Valid loss:0.1002\n","Val metric mean prob: 0.2291\n","Best metric at: 0.4545 0.4180  0.6925\n","Cf: [[2330   17]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 00:55:28,514]\u001b[0m Trial 23 finished with value: 0.4545454545454546 and parameters: {'a1': 0.5262097046619402, 'a2': 0.32841288150894715}. Best is trial 16 with value: 0.47058823529411764.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.46114223269519555 0.3785300317992645 0.16032773550554003\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.03s/it, eval_loss=0.1000, gpu_mem=8.82 GB]\n","Valid loss:0.1000\n","Val metric mean prob: 0.2294\n","Best metric at: 0.4706 0.4230  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 00:57:23,655]\u001b[0m Trial 24 finished with value: 0.47058823529411764 and parameters: {'a1': 0.46114223269519555, 'a2': 0.3785300317992645}. Best is trial 16 with value: 0.47058823529411764.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.34510791308625577 0.24288227857893535 0.4120098083348089\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1045, gpu_mem=8.82 GB]\n","Valid loss:0.1045\n","Val metric mean prob: 0.2369\n","Best metric at: 0.4471 0.4490  0.6831\n","Cf: [[2332   15]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 00:59:10,595]\u001b[0m Trial 25 finished with value: 0.4470588235294118 and parameters: {'a1': 0.34510791308625577, 'a2': 0.24288227857893535}. Best is trial 16 with value: 0.47058823529411764.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4570075949976057 0.2875676969996524 0.2554247080027419\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.1018, gpu_mem=8.82 GB]\n","Valid loss:0.1018\n","Val metric mean prob: 0.2334\n","Best metric at: 0.4762 0.4430  0.6933\n","Cf: [[2334   13]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 01:00:58,887]\u001b[0m Trial 26 finished with value: 0.47619047619047616 and parameters: {'a1': 0.4570075949976057, 'a2': 0.2875676969996524}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.602880321650694 0.2852361957653361 0.11188348258396985\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.1000, gpu_mem=8.82 GB]\n","Valid loss:0.1000\n","Val metric mean prob: 0.2277\n","Best metric at: 0.4390 0.4530  0.6737\n","Cf: [[2334   13]\n"," [  33   18]]\n","\u001b[32m[I 2023-02-18 01:02:44,909]\u001b[0m Trial 27 finished with value: 0.4390243902439025 and parameters: {'a1': 0.602880321650694, 'a2': 0.2852361957653361}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.20191753434596343 0.41563103081105024 0.3824514348429864\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:35<00:00,  1.00it/s, eval_loss=0.1033, gpu_mem=8.82 GB]\n","Valid loss:0.1033\n","Val metric mean prob: 0.2335\n","Best metric at: 0.4471 0.4190  0.6831\n","Cf: [[2332   15]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 01:04:31,105]\u001b[0m Trial 28 finished with value: 0.4470588235294118 and parameters: {'a1': 0.20191753434596343, 'a2': 0.41563103081105024}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.16741790072702906 0.2311689369952002 0.6014131622777708\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.01s/it, eval_loss=0.1086, gpu_mem=8.82 GB]\n","Valid loss:0.1086\n","Val metric mean prob: 0.2359\n","Best metric at: 0.4337 0.4650  0.6735\n","Cf: [[2333   14]\n"," [  33   18]]\n","\u001b[32m[I 2023-02-18 01:06:21,048]\u001b[0m Trial 29 finished with value: 0.43373493975903615 and parameters: {'a1': 0.16741790072702906, 'a2': 0.2311689369952002}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.38598809491186625 0.2726831520954552 0.34132875299267856\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.01s/it, eval_loss=0.1032, gpu_mem=8.82 GB]\n","Valid loss:0.1032\n","Val metric mean prob: 0.2356\n","Best metric at: 0.4500 0.4640  0.6741\n","Cf: [[2336   11]\n"," [  33   18]]\n","\u001b[32m[I 2023-02-18 01:08:06,246]\u001b[0m Trial 30 finished with value: 0.45000000000000007 and parameters: {'a1': 0.38598809491186625, 'a2': 0.2726831520954552}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4790544166403739 0.31039756399962143 0.21054801936000472\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:35<00:00,  1.01it/s, eval_loss=0.1011, gpu_mem=8.82 GB]\n","Valid loss:0.1011\n","Val metric mean prob: 0.2317\n","Best metric at: 0.4706 0.4400  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 01:09:55,002]\u001b[0m Trial 31 finished with value: 0.47058823529411764 and parameters: {'a1': 0.4790544166403739, 'a2': 0.31039756399962143}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4445022401523302 0.34379411583329345 0.21170364401437636\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:35<00:00,  1.00it/s, eval_loss=0.1009, gpu_mem=8.82 GB]\n","Valid loss:0.1009\n","Val metric mean prob: 0.2315\n","Best metric at: 0.4762 0.4360  0.6933\n","Cf: [[2334   13]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 01:11:46,460]\u001b[0m Trial 32 finished with value: 0.47619047619047616 and parameters: {'a1': 0.4445022401523302, 'a2': 0.34379411583329345}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.32586871672473505 0.39062969257870944 0.2835015906965555\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.03s/it, eval_loss=0.1018, gpu_mem=8.82 GB]\n","Valid loss:0.1018\n","Val metric mean prob: 0.2327\n","Best metric at: 0.4651 0.4190  0.6929\n","Cf: [[2332   15]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 01:13:33,684]\u001b[0m Trial 33 finished with value: 0.46511627906976744 and parameters: {'a1': 0.32586871672473505, 'a2': 0.39062969257870944}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4292887475339534 0.324866051637404 0.24584520082864258\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.1015, gpu_mem=8.82 GB]\n","Valid loss:0.1015\n","Val metric mean prob: 0.2327\n","Best metric at: 0.4762 0.4420  0.6933\n","Cf: [[2334   13]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 01:15:22,788]\u001b[0m Trial 34 finished with value: 0.47619047619047616 and parameters: {'a1': 0.4292887475339534, 'a2': 0.324866051637404}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.0014064481955573527 0.5577616552150897 0.44083189658935296\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.1037, gpu_mem=8.82 GB]\n","Valid loss:0.1037\n","Val metric mean prob: 0.2285\n","Best metric at: 0.4359 0.4200  0.6645\n","Cf: [[2337   10]\n"," [  34   17]]\n","\u001b[32m[I 2023-02-18 01:17:08,735]\u001b[0m Trial 35 finished with value: 0.43589743589743585 and parameters: {'a1': 0.0014064481955573527, 'a2': 0.5577616552150897}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.41520985081859335 0.38065202582600505 0.20413812335540166\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1005, gpu_mem=8.82 GB]\n","Valid loss:0.1005\n","Val metric mean prob: 0.2311\n","Best metric at: 0.4706 0.4280  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 01:18:58,185]\u001b[0m Trial 36 finished with value: 0.47058823529411764 and parameters: {'a1': 0.41520985081859335, 'a2': 0.38065202582600505}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5520929345772928 0.32951966970759694 0.11838739571511026\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.0998, gpu_mem=8.82 GB]\n","Valid loss:0.0998\n","Val metric mean prob: 0.2279\n","Best metric at: 0.4396 0.4040  0.6918\n","Cf: [[2327   20]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 01:20:44,787]\u001b[0m Trial 37 finished with value: 0.4395604395604396 and parameters: {'a1': 0.5520929345772928, 'a2': 0.32951966970759694}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.6806004595931592 0.2507334295379068 0.06866611086893404\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.01s/it, eval_loss=0.0997, gpu_mem=8.82 GB]\n","Valid loss:0.0997\n","Val metric mean prob: 0.2260\n","Best metric at: 0.4419 0.4250  0.6829\n","Cf: [[2331   16]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 01:22:29,745]\u001b[0m Trial 38 finished with value: 0.4418604651162791 and parameters: {'a1': 0.6806004595931592, 'a2': 0.2507334295379068}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.565157492909161 0.2900169690543007 0.14482553803653836\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:39<00:00,  1.04s/it, eval_loss=0.1003, gpu_mem=8.82 GB]\n","Valid loss:0.1003\n","Val metric mean prob: 0.2293\n","Best metric at: 0.4396 0.4110  0.6918\n","Cf: [[2327   20]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 01:24:22,438]\u001b[0m Trial 39 finished with value: 0.4395604395604396 and parameters: {'a1': 0.565157492909161, 'a2': 0.2900169690543007}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5043928742517101 0.21485998486523228 0.28074714088305763\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:33<00:00,  1.03it/s, eval_loss=0.1025, gpu_mem=8.82 GB]\n","Valid loss:0.1025\n","Val metric mean prob: 0.2345\n","Best metric at: 0.4634 0.4610  0.6837\n","Cf: [[2335   12]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 01:26:03,756]\u001b[0m Trial 40 finished with value: 0.46341463414634143 and parameters: {'a1': 0.5043928742517101, 'a2': 0.21485998486523228}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4316518323098257 0.32874972960409354 0.23959843808608072\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:34<00:00,  1.01it/s, eval_loss=0.1013, gpu_mem=8.82 GB]\n","Valid loss:0.1013\n","Val metric mean prob: 0.2327\n","Best metric at: 0.4706 0.4370  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 01:27:50,343]\u001b[0m Trial 41 finished with value: 0.47058823529411764 and parameters: {'a1': 0.4316518323098257, 'a2': 0.32874972960409354}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.49695752858798325 0.2606927799961223 0.24234969141589446\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.1017, gpu_mem=8.82 GB]\n","Valid loss:0.1017\n","Val metric mean prob: 0.2333\n","Best metric at: 0.4651 0.4460  0.6929\n","Cf: [[2332   15]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 01:29:41,532]\u001b[0m Trial 42 finished with value: 0.46511627906976744 and parameters: {'a1': 0.49695752858798325, 'a2': 0.2606927799961223}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.6286784316623291 0.29497449614402116 0.07634707219364978\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.0996, gpu_mem=8.82 GB]\n","Valid loss:0.0996\n","Val metric mean prob: 0.2259\n","Best metric at: 0.4337 0.4380  0.6735\n","Cf: [[2333   14]\n"," [  33   18]]\n","\u001b[32m[I 2023-02-18 01:31:26,637]\u001b[0m Trial 43 finished with value: 0.43373493975903615 and parameters: {'a1': 0.6286784316623291, 'a2': 0.29497449614402116}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4524303145941285 0.3662977568976119 0.18127192850825957\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.03s/it, eval_loss=0.1004, gpu_mem=8.82 GB]\n","Valid loss:0.1004\n","Val metric mean prob: 0.2302\n","Best metric at: 0.4706 0.4290  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 01:33:20,779]\u001b[0m Trial 44 finished with value: 0.47058823529411764 and parameters: {'a1': 0.4524303145941285, 'a2': 0.3662977568976119}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.3657960861108353 0.45173790598774394 0.1824660079014207\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:39<00:00,  1.03s/it, eval_loss=0.0998, gpu_mem=8.82 GB]\n","Valid loss:0.0998\n","Val metric mean prob: 0.2295\n","Best metric at: 0.4691 0.4360  0.6839\n","Cf: [[2336   11]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 01:35:11,178]\u001b[0m Trial 45 finished with value: 0.4691358024691358 and parameters: {'a1': 0.3657960861108353, 'a2': 0.45173790598774394}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.41382581822395836 0.3990158825560158 0.18715829922002586\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:35<00:00,  1.00it/s, eval_loss=0.1002, gpu_mem=8.82 GB]\n","Valid loss:0.1002\n","Val metric mean prob: 0.2304\n","Best metric at: 0.4706 0.4240  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 01:37:03,459]\u001b[0m Trial 46 finished with value: 0.47058823529411764 and parameters: {'a1': 0.41382581822395836, 'a2': 0.3990158825560158}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5486546046183697 0.3433909200978621 0.10795447528376823\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.0995, gpu_mem=8.82 GB]\n","Valid loss:0.0995\n","Val metric mean prob: 0.2276\n","Best metric at: 0.4444 0.4350  0.6739\n","Cf: [[2335   12]\n"," [  33   18]]\n","\u001b[32m[I 2023-02-18 01:38:51,675]\u001b[0m Trial 47 finished with value: 0.4444444444444445 and parameters: {'a1': 0.5486546046183697, 'a2': 0.3433909200978621}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4847604640570742 0.32164474740648386 0.19359478853644196\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.1008, gpu_mem=8.82 GB]\n","Valid loss:0.1008\n","Val metric mean prob: 0.2311\n","Best metric at: 0.4651 0.4330  0.6929\n","Cf: [[2332   15]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 01:40:37,674]\u001b[0m Trial 48 finished with value: 0.46511627906976744 and parameters: {'a1': 0.4847604640570742, 'a2': 0.32164474740648386}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.2941453798117436 0.18921678392001687 0.5166378362682396\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.01s/it, eval_loss=0.1067, gpu_mem=8.82 GB]\n","Valid loss:0.1067\n","Val metric mean prob: 0.2379\n","Best metric at: 0.4337 0.4720  0.6735\n","Cf: [[2333   14]\n"," [  33   18]]\n","\u001b[32m[I 2023-02-18 01:42:22,360]\u001b[0m Trial 49 finished with value: 0.43373493975903615 and parameters: {'a1': 0.2941453798117436, 'a2': 0.18921678392001687}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.3270465669537322 0.4135352394712635 0.25941819357500434\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.03s/it, eval_loss=0.1012, gpu_mem=8.82 GB]\n","Valid loss:0.1012\n","Val metric mean prob: 0.2320\n","Best metric at: 0.4706 0.4240  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 01:44:17,727]\u001b[0m Trial 50 finished with value: 0.47058823529411764 and parameters: {'a1': 0.3270465669537322, 'a2': 0.4135352394712635}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.43659879021566883 0.36034098853919516 0.203060221245136\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.01s/it, eval_loss=0.1006, gpu_mem=8.82 GB]\n","Valid loss:0.1006\n","Val metric mean prob: 0.2313\n","Best metric at: 0.4762 0.4340  0.6933\n","Cf: [[2334   13]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 01:46:05,580]\u001b[0m Trial 51 finished with value: 0.47619047619047616 and parameters: {'a1': 0.43659879021566883, 'a2': 0.36034098853919516}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.43901164339316695 0.3674500915168863 0.1935382650899467\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.1005, gpu_mem=8.82 GB]\n","Valid loss:0.1005\n","Val metric mean prob: 0.2307\n","Best metric at: 0.4762 0.4330  0.6933\n","Cf: [[2334   13]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 01:47:58,699]\u001b[0m Trial 52 finished with value: 0.47619047619047616 and parameters: {'a1': 0.43901164339316695, 'a2': 0.3674500915168863}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.3909788591719552 0.3706501178139242 0.2383710230141206\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1011, gpu_mem=8.82 GB]\n","Valid loss:0.1011\n","Val metric mean prob: 0.2319\n","Best metric at: 0.4706 0.4270  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 01:49:52,389]\u001b[0m Trial 53 finished with value: 0.47058823529411764 and parameters: {'a1': 0.3909788591719552, 'a2': 0.3706501178139242}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4281172401086564 0.35785533074825315 0.21402742914309048\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:39<00:00,  1.04s/it, eval_loss=0.1008, gpu_mem=8.82 GB]\n","Valid loss:0.1008\n","Val metric mean prob: 0.2315\n","Best metric at: 0.4706 0.4300  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 01:51:44,379]\u001b[0m Trial 54 finished with value: 0.47058823529411764 and parameters: {'a1': 0.4281172401086564, 'a2': 0.35785533074825315}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.351660927828094 0.43810370969670986 0.21023536247519614\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:35<00:00,  1.00it/s, eval_loss=0.1003, gpu_mem=8.82 GB]\n","Valid loss:0.1003\n","Val metric mean prob: 0.2302\n","Best metric at: 0.4706 0.4190  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 01:53:32,042]\u001b[0m Trial 55 finished with value: 0.47058823529411764 and parameters: {'a1': 0.351660927828094, 'a2': 0.43810370969670986}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5059353150601267 0.3439011267399843 0.15016355819988902\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.1001, gpu_mem=8.82 GB]\n","Valid loss:0.1001\n","Val metric mean prob: 0.2294\n","Best metric at: 0.4598 0.4190  0.6927\n","Cf: [[2331   16]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 01:55:18,172]\u001b[0m Trial 56 finished with value: 0.4597701149425288 and parameters: {'a1': 0.5059353150601267, 'a2': 0.3439011267399843}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4326619512528676 0.3090915967336696 0.25824645201346286\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.1018, gpu_mem=8.82 GB]\n","Valid loss:0.1018\n","Val metric mean prob: 0.2331\n","Best metric at: 0.4762 0.4420  0.6933\n","Cf: [[2334   13]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 01:57:12,560]\u001b[0m Trial 57 finished with value: 0.47619047619047616 and parameters: {'a1': 0.4326619512528676, 'a2': 0.3090915967336696}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.39610454900990777 0.27429982455131163 0.3295956264387806\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1029, gpu_mem=8.82 GB]\n","Valid loss:0.1029\n","Val metric mean prob: 0.2356\n","Best metric at: 0.4500 0.4640  0.6741\n","Cf: [[2336   11]\n"," [  33   18]]\n","\u001b[32m[I 2023-02-18 01:58:59,078]\u001b[0m Trial 58 finished with value: 0.45000000000000007 and parameters: {'a1': 0.39610454900990777, 'a2': 0.27429982455131163}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4366416519244162 0.3150915978374965 0.2482667502380873\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.1016, gpu_mem=8.82 GB]\n","Valid loss:0.1016\n","Val metric mean prob: 0.2328\n","Best metric at: 0.4762 0.4430  0.6933\n","Cf: [[2334   13]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:00:48,169]\u001b[0m Trial 59 finished with value: 0.47619047619047616 and parameters: {'a1': 0.4366416519244162, 'a2': 0.3150915978374965}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.29447406114173225 0.39287020082475843 0.3126557380335093\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.01s/it, eval_loss=0.1022, gpu_mem=8.82 GB]\n","Valid loss:0.1022\n","Val metric mean prob: 0.2333\n","Best metric at: 0.4598 0.4120  0.6927\n","Cf: [[2331   16]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:02:32,869]\u001b[0m Trial 60 finished with value: 0.4597701149425288 and parameters: {'a1': 0.29447406114173225, 'a2': 0.39287020082475843}. Best is trial 26 with value: 0.47619047619047616.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.43345892433227945 0.31153683597278437 0.25500423969493613\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.1017, gpu_mem=8.82 GB]\n","Valid loss:0.1017\n","Val metric mean prob: 0.2329\n","Best metric at: 0.4819 0.4440  0.6935\n","Cf: [[2335   12]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:04:20,975]\u001b[0m Trial 61 finished with value: 0.4819277108433735 and parameters: {'a1': 0.43345892433227945, 'a2': 0.31153683597278437}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.37559015602403717 0.2982519885845339 0.326157855391429\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.01s/it, eval_loss=0.1027, gpu_mem=8.82 GB]\n","Valid loss:0.1027\n","Val metric mean prob: 0.2353\n","Best metric at: 0.4651 0.4320  0.6929\n","Cf: [[2332   15]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:06:05,381]\u001b[0m Trial 62 finished with value: 0.46511627906976744 and parameters: {'a1': 0.37559015602403717, 'a2': 0.2982519885845339}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4400405875652116 0.3141988621336771 0.24576055030111132\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:34<00:00,  1.02it/s, eval_loss=0.1015, gpu_mem=8.82 GB]\n","Valid loss:0.1015\n","Val metric mean prob: 0.2328\n","Best metric at: 0.4762 0.4420  0.6933\n","Cf: [[2334   13]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:07:54,330]\u001b[0m Trial 63 finished with value: 0.47619047619047616 and parameters: {'a1': 0.4400405875652116, 'a2': 0.3141988621336771}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5352019042188864 0.35720565290690687 0.10759244287420677\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.01s/it, eval_loss=0.0995, gpu_mem=8.82 GB]\n","Valid loss:0.0995\n","Val metric mean prob: 0.2275\n","Best metric at: 0.4444 0.4060  0.6920\n","Cf: [[2328   19]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:09:39,124]\u001b[0m Trial 64 finished with value: 0.4444444444444445 and parameters: {'a1': 0.5352019042188864, 'a2': 0.35720565290690687}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.47850816976865984 0.3316042391699804 0.18988759106135977\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.1007, gpu_mem=8.82 GB]\n","Valid loss:0.1007\n","Val metric mean prob: 0.2308\n","Best metric at: 0.4706 0.4350  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:11:32,453]\u001b[0m Trial 65 finished with value: 0.47058823529411764 and parameters: {'a1': 0.47850816976865984, 'a2': 0.3316042391699804}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.35769597236720746 0.2690815082657396 0.37322251936705286\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1037, gpu_mem=8.82 GB]\n","Valid loss:0.1037\n","Val metric mean prob: 0.2363\n","Best metric at: 0.4500 0.4660  0.6741\n","Cf: [[2336   11]\n"," [  33   18]]\n","\u001b[32m[I 2023-02-18 02:13:18,469]\u001b[0m Trial 66 finished with value: 0.45000000000000007 and parameters: {'a1': 0.35769597236720746, 'a2': 0.2690815082657396}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4059852393534909 0.29615204668907685 0.2978627139574323\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.1023, gpu_mem=8.82 GB]\n","Valid loss:0.1023\n","Val metric mean prob: 0.2348\n","Best metric at: 0.4651 0.4350  0.6929\n","Cf: [[2332   15]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:15:04,012]\u001b[0m Trial 67 finished with value: 0.46511627906976744 and parameters: {'a1': 0.4059852393534909, 'a2': 0.29615204668907685}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5240925481159936 0.33942898133166155 0.13647847055234485\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:39<00:00,  1.03s/it, eval_loss=0.1000, gpu_mem=8.82 GB]\n","Valid loss:0.1000\n","Val metric mean prob: 0.2287\n","Best metric at: 0.4545 0.4150  0.6925\n","Cf: [[2330   17]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:16:55,811]\u001b[0m Trial 68 finished with value: 0.4545454545454546 and parameters: {'a1': 0.5240925481159936, 'a2': 0.33942898133166155}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.46316132860331455 0.3795631447756342 0.15727552662105132\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.1000, gpu_mem=8.82 GB]\n","Valid loss:0.1000\n","Val metric mean prob: 0.2293\n","Best metric at: 0.4706 0.4220  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:18:47,634]\u001b[0m Trial 69 finished with value: 0.47058823529411764 and parameters: {'a1': 0.46316132860331455, 'a2': 0.3795631447756342}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4083099993375439 0.2860801104764263 0.30560989018602985\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.03s/it, eval_loss=0.1025, gpu_mem=8.82 GB]\n","Valid loss:0.1025\n","Val metric mean prob: 0.2349\n","Best metric at: 0.4651 0.4380  0.6929\n","Cf: [[2332   15]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:20:34,437]\u001b[0m Trial 70 finished with value: 0.46511627906976744 and parameters: {'a1': 0.4083099993375439, 'a2': 0.2860801104764263}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.49461581769764423 0.3095092174227393 0.19587496487961642\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:34<00:00,  1.02it/s, eval_loss=0.1009, gpu_mem=8.82 GB]\n","Valid loss:0.1009\n","Val metric mean prob: 0.2311\n","Best metric at: 0.4651 0.4360  0.6929\n","Cf: [[2332   15]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:22:16,667]\u001b[0m Trial 71 finished with value: 0.46511627906976744 and parameters: {'a1': 0.49461581769764423, 'a2': 0.3095092174227393}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4364055302314287 0.3165196892240491 0.2470747805445222\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.1015, gpu_mem=8.82 GB]\n","Valid loss:0.1015\n","Val metric mean prob: 0.2329\n","Best metric at: 0.4762 0.4430  0.6933\n","Cf: [[2334   13]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:24:13,264]\u001b[0m Trial 72 finished with value: 0.47619047619047616 and parameters: {'a1': 0.4364055302314287, 'a2': 0.3165196892240491}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4627734204679181 0.3254653955139888 0.21176118401809307\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1010, gpu_mem=8.82 GB]\n","Valid loss:0.1010\n","Val metric mean prob: 0.2318\n","Best metric at: 0.4762 0.4380  0.6933\n","Cf: [[2334   13]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:26:07,597]\u001b[0m Trial 73 finished with value: 0.47619047619047616 and parameters: {'a1': 0.4627734204679181, 'a2': 0.3254653955139888}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4445702183831793 0.36559623526315277 0.189833546353668\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1005, gpu_mem=8.82 GB]\n","Valid loss:0.1005\n","Val metric mean prob: 0.2306\n","Best metric at: 0.4762 0.4340  0.6933\n","Cf: [[2334   13]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:27:56,688]\u001b[0m Trial 74 finished with value: 0.47619047619047616 and parameters: {'a1': 0.4445702183831793, 'a2': 0.36559623526315277}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.3849097724097558 0.23842754465387106 0.37666268293637306\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1039, gpu_mem=8.82 GB]\n","Valid loss:0.1039\n","Val metric mean prob: 0.2367\n","Best metric at: 0.4500 0.4690  0.6741\n","Cf: [[2336   11]\n"," [  33   18]]\n","\u001b[32m[I 2023-02-18 02:29:42,899]\u001b[0m Trial 75 finished with value: 0.45000000000000007 and parameters: {'a1': 0.3849097724097558, 'a2': 0.23842754465387106}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5125872096906731 0.308811177672811 0.17860161263651592\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.1007, gpu_mem=8.82 GB]\n","Valid loss:0.1007\n","Val metric mean prob: 0.2306\n","Best metric at: 0.4598 0.4260  0.6927\n","Cf: [[2331   16]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:31:28,057]\u001b[0m Trial 76 finished with value: 0.4597701149425288 and parameters: {'a1': 0.5125872096906731, 'a2': 0.308811177672811}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.567872927136611 0.33621006876806925 0.09591700409531978\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:39<00:00,  1.04s/it, eval_loss=0.0994, gpu_mem=8.82 GB]\n","Valid loss:0.0994\n","Val metric mean prob: 0.2271\n","Best metric at: 0.4390 0.4380  0.6737\n","Cf: [[2334   13]\n"," [  33   18]]\n","\u001b[32m[I 2023-02-18 02:33:19,575]\u001b[0m Trial 77 finished with value: 0.4390243902439025 and parameters: {'a1': 0.567872927136611, 'a2': 0.33621006876806925}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4316804583539266 0.2779771952324022 0.2903423464136711\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:35<00:00,  1.00it/s, eval_loss=0.1023, gpu_mem=8.82 GB]\n","Valid loss:0.1023\n","Val metric mean prob: 0.2346\n","Best metric at: 0.4819 0.4500  0.6935\n","Cf: [[2335   12]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:35:12,270]\u001b[0m Trial 78 finished with value: 0.4819277108433735 and parameters: {'a1': 0.4316804583539266, 'a2': 0.2779771952324022}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.34601516649943187 0.2685399956013017 0.3854448378992664\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:39<00:00,  1.04s/it, eval_loss=0.1039, gpu_mem=8.82 GB]\n","Valid loss:0.1039\n","Val metric mean prob: 0.2363\n","Best metric at: 0.4471 0.4420  0.6831\n","Cf: [[2332   15]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 02:37:00,381]\u001b[0m Trial 79 finished with value: 0.4470588235294118 and parameters: {'a1': 0.34601516649943187, 'a2': 0.2685399956013017}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.41452266856614367 0.2826283665428145 0.3028489648910419\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:34<00:00,  1.01it/s, eval_loss=0.1025, gpu_mem=8.82 GB]\n","Valid loss:0.1025\n","Val metric mean prob: 0.2348\n","Best metric at: 0.4651 0.4390  0.6929\n","Cf: [[2332   15]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:38:43,409]\u001b[0m Trial 80 finished with value: 0.46511627906976744 and parameters: {'a1': 0.41452266856614367, 'a2': 0.2826283665428145}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4407986958464875 0.2540147047665192 0.3051865993869932\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.1027, gpu_mem=8.82 GB]\n","Valid loss:0.1027\n","Val metric mean prob: 0.2350\n","Best metric at: 0.4706 0.4510  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:40:31,929]\u001b[0m Trial 81 finished with value: 0.47058823529411764 and parameters: {'a1': 0.4407986958464875, 'a2': 0.2540147047665192}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4818011822798647 0.3027079976045852 0.2154908201155501\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.1012, gpu_mem=8.82 GB]\n","Valid loss:0.1012\n","Val metric mean prob: 0.2319\n","Best metric at: 0.4706 0.4410  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:42:23,432]\u001b[0m Trial 82 finished with value: 0.47058823529411764 and parameters: {'a1': 0.4818011822798647, 'a2': 0.3027079976045852}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.37806457524351983 0.3826338869623704 0.23930153779410973\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.1011, gpu_mem=8.82 GB]\n","Valid loss:0.1011\n","Val metric mean prob: 0.2318\n","Best metric at: 0.4706 0.4250  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:44:12,727]\u001b[0m Trial 83 finished with value: 0.47058823529411764 and parameters: {'a1': 0.37806457524351983, 'a2': 0.3826338869623704}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4224338943561778 0.3445898932539787 0.23297621238984345\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.03s/it, eval_loss=0.1012, gpu_mem=8.82 GB]\n","Valid loss:0.1012\n","Val metric mean prob: 0.2320\n","Best metric at: 0.4706 0.4340  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:46:02,366]\u001b[0m Trial 84 finished with value: 0.47058823529411764 and parameters: {'a1': 0.4224338943561778, 'a2': 0.3445898932539787}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.45458980955058775 0.31893467959166083 0.22647551085775136\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.1011, gpu_mem=8.82 GB]\n","Valid loss:0.1011\n","Val metric mean prob: 0.2325\n","Best metric at: 0.4762 0.4370  0.6933\n","Cf: [[2334   13]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:47:50,535]\u001b[0m Trial 85 finished with value: 0.47619047619047616 and parameters: {'a1': 0.45458980955058775, 'a2': 0.31893467959166083}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5344785223506078 0.3512957229562996 0.1142257546930926\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.0996, gpu_mem=8.82 GB]\n","Valid loss:0.0996\n","Val metric mean prob: 0.2278\n","Best metric at: 0.4444 0.4090  0.6920\n","Cf: [[2328   19]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:49:36,374]\u001b[0m Trial 86 finished with value: 0.4444444444444445 and parameters: {'a1': 0.5344785223506078, 'a2': 0.3512957229562996}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.3987191298659013 0.28891055449691194 0.31237031563718676\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.1025, gpu_mem=8.82 GB]\n","Valid loss:0.1025\n","Val metric mean prob: 0.2352\n","Best metric at: 0.4651 0.4370  0.6929\n","Cf: [[2332   15]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:51:23,788]\u001b[0m Trial 87 finished with value: 0.46511627906976744 and parameters: {'a1': 0.3987191298659013, 'a2': 0.28891055449691194}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.49574490066214083 0.3258819922960694 0.17837310704178977\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:35<00:00,  1.00it/s, eval_loss=0.1006, gpu_mem=8.82 GB]\n","Valid loss:0.1006\n","Val metric mean prob: 0.2304\n","Best metric at: 0.4651 0.4310  0.6929\n","Cf: [[2332   15]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:53:11,949]\u001b[0m Trial 88 finished with value: 0.46511627906976744 and parameters: {'a1': 0.49574490066214083, 'a2': 0.3258819922960694}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4714052628086737 0.2776958716909207 0.25089886550040563\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:34<00:00,  1.01it/s, eval_loss=0.1018, gpu_mem=8.82 GB]\n","Valid loss:0.1018\n","Val metric mean prob: 0.2333\n","Best metric at: 0.4762 0.4450  0.6933\n","Cf: [[2334   13]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:54:58,027]\u001b[0m Trial 89 finished with value: 0.47619047619047616 and parameters: {'a1': 0.4714052628086737, 'a2': 0.2776958716909207}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.364932450861107 0.26052864879045085 0.3745389003484422\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.1038, gpu_mem=8.82 GB]\n","Valid loss:0.1038\n","Val metric mean prob: 0.2364\n","Best metric at: 0.4500 0.4680  0.6741\n","Cf: [[2336   11]\n"," [  33   18]]\n","\u001b[32m[I 2023-02-18 02:56:43,311]\u001b[0m Trial 90 finished with value: 0.45000000000000007 and parameters: {'a1': 0.364932450861107, 'a2': 0.26052864879045085}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4373437513361725 0.3112812525015965 0.2513749961622311\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1016, gpu_mem=8.82 GB]\n","Valid loss:0.1016\n","Val metric mean prob: 0.2330\n","Best metric at: 0.4819 0.4440  0.6935\n","Cf: [[2335   12]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 02:58:41,465]\u001b[0m Trial 91 finished with value: 0.4819277108433735 and parameters: {'a1': 0.4373437513361725, 'a2': 0.3112812525015965}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.44221802031096624 0.29480961005005435 0.2629723696389794\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.03s/it, eval_loss=0.1018, gpu_mem=8.82 GB]\n","Valid loss:0.1018\n","Val metric mean prob: 0.2336\n","Best metric at: 0.4819 0.4440  0.6935\n","Cf: [[2335   12]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:00:31,647]\u001b[0m Trial 92 finished with value: 0.4819277108433735 and parameters: {'a1': 0.44221802031096624, 'a2': 0.29480961005005435}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.41243901519099274 0.2983854727684451 0.2891755120405622\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.1022, gpu_mem=8.82 GB]\n","Valid loss:0.1022\n","Val metric mean prob: 0.2344\n","Best metric at: 0.4706 0.4440  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:02:20,744]\u001b[0m Trial 93 finished with value: 0.47058823529411764 and parameters: {'a1': 0.41243901519099274, 'a2': 0.2983854727684451}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4582786240911259 0.35200973609419084 0.1897116398146833\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:39<00:00,  1.04s/it, eval_loss=0.1006, gpu_mem=8.82 GB]\n","Valid loss:0.1006\n","Val metric mean prob: 0.2306\n","Best metric at: 0.4706 0.4310  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:04:11,440]\u001b[0m Trial 94 finished with value: 0.47058823529411764 and parameters: {'a1': 0.4582786240911259, 'a2': 0.35200973609419084}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5088890837709635 0.30028226648939965 0.1908286497396368\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:35<00:00,  1.01it/s, eval_loss=0.1008, gpu_mem=8.82 GB]\n","Valid loss:0.1008\n","Val metric mean prob: 0.2311\n","Best metric at: 0.4598 0.4280  0.6927\n","Cf: [[2331   16]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:05:54,514]\u001b[0m Trial 95 finished with value: 0.4597701149425288 and parameters: {'a1': 0.5088890837709635, 'a2': 0.30028226648939965}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.3846007040571156 0.24057408997099045 0.374825205971894\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.01s/it, eval_loss=0.1039, gpu_mem=8.82 GB]\n","Valid loss:0.1039\n","Val metric mean prob: 0.2367\n","Best metric at: 0.4500 0.4690  0.6741\n","Cf: [[2336   11]\n"," [  33   18]]\n","\u001b[32m[I 2023-02-18 03:07:44,553]\u001b[0m Trial 96 finished with value: 0.45000000000000007 and parameters: {'a1': 0.3846007040571156, 'a2': 0.24057408997099045}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.426109452824432 0.36903583811299623 0.20485470906257175\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:34<00:00,  1.02it/s, eval_loss=0.1006, gpu_mem=8.82 GB]\n","Valid loss:0.1006\n","Val metric mean prob: 0.2312\n","Best metric at: 0.4706 0.4280  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:09:30,167]\u001b[0m Trial 97 finished with value: 0.47058823529411764 and parameters: {'a1': 0.426109452824432, 'a2': 0.36903583811299623}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.48574828960363436 0.33629463471383964 0.177957075682526\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.00s/it, eval_loss=0.1005, gpu_mem=8.82 GB]\n","Valid loss:0.1005\n","Val metric mean prob: 0.2304\n","Best metric at: 0.4651 0.4280  0.6929\n","Cf: [[2332   15]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:11:14,308]\u001b[0m Trial 98 finished with value: 0.46511627906976744 and parameters: {'a1': 0.48574828960363436, 'a2': 0.33629463471383964}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.44821116701510605 0.27989587614730943 0.27189295683758447\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.1020, gpu_mem=8.82 GB]\n","Valid loss:0.1020\n","Val metric mean prob: 0.2339\n","Best metric at: 0.4819 0.4460  0.6935\n","Cf: [[2335   12]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:13:07,774]\u001b[0m Trial 99 finished with value: 0.4819277108433735 and parameters: {'a1': 0.44821116701510605, 'a2': 0.27989587614730943}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.3304795974610633 0.2546771607432599 0.41484324179567683\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.03s/it, eval_loss=0.1046, gpu_mem=8.82 GB]\n","Valid loss:0.1046\n","Val metric mean prob: 0.2367\n","Best metric at: 0.4471 0.4470  0.6831\n","Cf: [[2332   15]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 03:14:59,841]\u001b[0m Trial 100 finished with value: 0.4470588235294118 and parameters: {'a1': 0.3304795974610633, 'a2': 0.2546771607432599}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4551342697409812 0.28761214420009645 0.2572535860589223\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:35<00:00,  1.00it/s, eval_loss=0.1018, gpu_mem=8.82 GB]\n","Valid loss:0.1018\n","Val metric mean prob: 0.2334\n","Best metric at: 0.4762 0.4430  0.6933\n","Cf: [[2334   13]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:16:46,911]\u001b[0m Trial 101 finished with value: 0.47619047619047616 and parameters: {'a1': 0.4551342697409812, 'a2': 0.28761214420009645}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4260736760910523 0.2709205171730437 0.303005806735904\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:35<00:00,  1.01it/s, eval_loss=0.1026, gpu_mem=8.82 GB]\n","Valid loss:0.1026\n","Val metric mean prob: 0.2349\n","Best metric at: 0.4651 0.4430  0.6929\n","Cf: [[2332   15]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:18:30,173]\u001b[0m Trial 102 finished with value: 0.46511627906976744 and parameters: {'a1': 0.4260736760910523, 'a2': 0.2709205171730437}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.3936001449210158 0.3207325206659859 0.2856673344129983\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.00s/it, eval_loss=0.1020, gpu_mem=8.82 GB]\n","Valid loss:0.1020\n","Val metric mean prob: 0.2342\n","Best metric at: 0.4706 0.4410  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:20:22,592]\u001b[0m Trial 103 finished with value: 0.47058823529411764 and parameters: {'a1': 0.3936001449210158, 'a2': 0.3207325206659859}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.3688316668371513 0.2820515151730208 0.3491168179898279\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.1033, gpu_mem=8.82 GB]\n","Valid loss:0.1033\n","Val metric mean prob: 0.2357\n","Best metric at: 0.4500 0.4640  0.6741\n","Cf: [[2336   11]\n"," [  33   18]]\n","\u001b[32m[I 2023-02-18 03:22:13,124]\u001b[0m Trial 104 finished with value: 0.45000000000000007 and parameters: {'a1': 0.3688316668371513, 'a2': 0.2820515151730208}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4817003057301974 0.3089225521396174 0.2093771421301852\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.00s/it, eval_loss=0.1011, gpu_mem=8.82 GB]\n","Valid loss:0.1011\n","Val metric mean prob: 0.2317\n","Best metric at: 0.4706 0.4400  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:24:00,782]\u001b[0m Trial 105 finished with value: 0.47058823529411764 and parameters: {'a1': 0.4817003057301974, 'a2': 0.3089225521396174}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5187561188672278 0.2943123594709449 0.18693152166182725\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.01s/it, eval_loss=0.1009, gpu_mem=8.82 GB]\n","Valid loss:0.1009\n","Val metric mean prob: 0.2310\n","Best metric at: 0.4598 0.4310  0.6927\n","Cf: [[2331   16]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:25:45,795]\u001b[0m Trial 106 finished with value: 0.4597701149425288 and parameters: {'a1': 0.5187561188672278, 'a2': 0.2943123594709449}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.43966479099279515 0.32793872047266376 0.23239648853454115\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:34<00:00,  1.01it/s, eval_loss=0.1012, gpu_mem=8.82 GB]\n","Valid loss:0.1012\n","Val metric mean prob: 0.2324\n","Best metric at: 0.4762 0.4400  0.6933\n","Cf: [[2334   13]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:27:36,722]\u001b[0m Trial 107 finished with value: 0.47619047619047616 and parameters: {'a1': 0.43966479099279515, 'a2': 0.32793872047266376}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.40022779276332 0.3516257728553067 0.2481464343813733\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.01s/it, eval_loss=0.1014, gpu_mem=8.82 GB]\n","Valid loss:0.1014\n","Val metric mean prob: 0.2322\n","Best metric at: 0.4706 0.4310  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:29:24,667]\u001b[0m Trial 108 finished with value: 0.47058823529411764 and parameters: {'a1': 0.40022779276332, 'a2': 0.3516257728553067}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.44641266988808703 0.30626541977779614 0.24732191033411682\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.1016, gpu_mem=8.82 GB]\n","Valid loss:0.1016\n","Val metric mean prob: 0.2328\n","Best metric at: 0.4762 0.4420  0.6933\n","Cf: [[2334   13]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:31:14,062]\u001b[0m Trial 109 finished with value: 0.47619047619047616 and parameters: {'a1': 0.44641266988808703, 'a2': 0.30626541977779614}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4634825490462014 0.26339841025780564 0.273119040695993\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1022, gpu_mem=8.82 GB]\n","Valid loss:0.1022\n","Val metric mean prob: 0.2339\n","Best metric at: 0.4819 0.4500  0.6935\n","Cf: [[2335   12]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:33:07,890]\u001b[0m Trial 110 finished with value: 0.4819277108433735 and parameters: {'a1': 0.4634825490462014, 'a2': 0.26339841025780564}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.46593613040434234 0.27789493031213436 0.2561689392835233\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1019, gpu_mem=8.82 GB]\n","Valid loss:0.1019\n","Val metric mean prob: 0.2334\n","Best metric at: 0.4762 0.4440  0.6933\n","Cf: [[2334   13]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:35:03,254]\u001b[0m Trial 111 finished with value: 0.47619047619047616 and parameters: {'a1': 0.46593613040434234, 'a2': 0.27789493031213436}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.42439878005852943 0.26600852058517815 0.30959269935629247\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.03s/it, eval_loss=0.1027, gpu_mem=8.82 GB]\n","Valid loss:0.1027\n","Val metric mean prob: 0.2351\n","Best metric at: 0.4651 0.4440  0.6929\n","Cf: [[2332   15]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:36:53,836]\u001b[0m Trial 112 finished with value: 0.46511627906976744 and parameters: {'a1': 0.42439878005852943, 'a2': 0.26600852058517815}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5059571126380659 0.29230566831408367 0.20173721904785047\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.01s/it, eval_loss=0.1010, gpu_mem=8.82 GB]\n","Valid loss:0.1010\n","Val metric mean prob: 0.2314\n","Best metric at: 0.4598 0.4320  0.6927\n","Cf: [[2331   16]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:38:42,646]\u001b[0m Trial 113 finished with value: 0.4597701149425288 and parameters: {'a1': 0.5059571126380659, 'a2': 0.29230566831408367}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.47134766403098977 0.33683805109654746 0.19181428487246283\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.1008, gpu_mem=8.82 GB]\n","Valid loss:0.1008\n","Val metric mean prob: 0.2307\n","Best metric at: 0.4706 0.4330  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:40:31,361]\u001b[0m Trial 114 finished with value: 0.47058823529411764 and parameters: {'a1': 0.47134766403098977, 'a2': 0.33683805109654746}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.40956485818265675 0.2469707901037383 0.34346435171360495\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.03s/it, eval_loss=0.1033, gpu_mem=8.82 GB]\n","Valid loss:0.1033\n","Val metric mean prob: 0.2360\n","Best metric at: 0.4500 0.4670  0.6741\n","Cf: [[2336   11]\n"," [  33   18]]\n","\u001b[32m[I 2023-02-18 03:42:18,174]\u001b[0m Trial 115 finished with value: 0.45000000000000007 and parameters: {'a1': 0.40956485818265675, 'a2': 0.2469707901037383}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4894578621737032 0.3133768835608575 0.19716525426543935\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:34<00:00,  1.02it/s, eval_loss=0.1009, gpu_mem=8.82 GB]\n","Valid loss:0.1009\n","Val metric mean prob: 0.2312\n","Best metric at: 0.4651 0.4340  0.6929\n","Cf: [[2332   15]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:44:01,512]\u001b[0m Trial 116 finished with value: 0.46511627906976744 and parameters: {'a1': 0.4894578621737032, 'a2': 0.3133768835608575}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4523807017438158 0.2663263691527491 0.2812929291034352\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.1023, gpu_mem=8.82 GB]\n","Valid loss:0.1023\n","Val metric mean prob: 0.2341\n","Best metric at: 0.4819 0.4470  0.6935\n","Cf: [[2335   12]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:45:51,936]\u001b[0m Trial 117 finished with value: 0.4819277108433735 and parameters: {'a1': 0.4523807017438158, 'a2': 0.2663263691527491}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5451969507782453 0.26502243175379225 0.1897806174679625\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.03s/it, eval_loss=0.1011, gpu_mem=8.82 GB]\n","Valid loss:0.1011\n","Val metric mean prob: 0.2311\n","Best metric at: 0.4524 0.4450  0.6833\n","Cf: [[2333   14]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 03:47:39,359]\u001b[0m Trial 118 finished with value: 0.45238095238095244 and parameters: {'a1': 0.5451969507782453, 'a2': 0.26502243175379225}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4585235984245462 0.23259580436798372 0.30888059720747013\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.00s/it, eval_loss=0.1028, gpu_mem=8.82 GB]\n","Valid loss:0.1028\n","Val metric mean prob: 0.2354\n","Best metric at: 0.4819 0.4530  0.6935\n","Cf: [[2335   12]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:49:26,864]\u001b[0m Trial 119 finished with value: 0.4819277108433735 and parameters: {'a1': 0.4585235984245462, 'a2': 0.23259580436798372}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.45494305629596765 0.21681762474907984 0.3282393189549525\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1032, gpu_mem=8.82 GB]\n","Valid loss:0.1032\n","Val metric mean prob: 0.2359\n","Best metric at: 0.4634 0.4580  0.6837\n","Cf: [[2335   12]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 03:51:12,916]\u001b[0m Trial 120 finished with value: 0.46341463414634143 and parameters: {'a1': 0.45494305629596765, 'a2': 0.21681762474907984}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.44547437283093366 0.254265725499831 0.3002599016692354\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:35<00:00,  1.00it/s, eval_loss=0.1026, gpu_mem=8.82 GB]\n","Valid loss:0.1026\n","Val metric mean prob: 0.2348\n","Best metric at: 0.4819 0.4500  0.6935\n","Cf: [[2335   12]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:53:05,027]\u001b[0m Trial 121 finished with value: 0.4819277108433735 and parameters: {'a1': 0.44547437283093366, 'a2': 0.254265725499831}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.49752467872035444 0.26015544614917574 0.24231987513046982\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.01s/it, eval_loss=0.1017, gpu_mem=8.82 GB]\n","Valid loss:0.1017\n","Val metric mean prob: 0.2332\n","Best metric at: 0.4651 0.4460  0.6929\n","Cf: [[2332   15]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:54:50,143]\u001b[0m Trial 122 finished with value: 0.46511627906976744 and parameters: {'a1': 0.49752467872035444, 'a2': 0.26015544614917574}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.46795956371861336 0.24901682411188103 0.2830236121695056\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:39<00:00,  1.04s/it, eval_loss=0.1024, gpu_mem=8.82 GB]\n","Valid loss:0.1024\n","Val metric mean prob: 0.2343\n","Best metric at: 0.4819 0.4510  0.6935\n","Cf: [[2335   12]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:56:43,460]\u001b[0m Trial 123 finished with value: 0.4819277108433735 and parameters: {'a1': 0.46795956371861336, 'a2': 0.24901682411188103}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.47256900140143787 0.252346321781372 0.2750846768171901\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.1023, gpu_mem=8.82 GB]\n","Valid loss:0.1023\n","Val metric mean prob: 0.2341\n","Best metric at: 0.4819 0.4540  0.6935\n","Cf: [[2335   12]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 03:58:35,888]\u001b[0m Trial 124 finished with value: 0.4819277108433735 and parameters: {'a1': 0.47256900140143787, 'a2': 0.252346321781372}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.522284639475142 0.2515309173262286 0.22618444319862935\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.03s/it, eval_loss=0.1017, gpu_mem=8.82 GB]\n","Valid loss:0.1017\n","Val metric mean prob: 0.2323\n","Best metric at: 0.4578 0.4560  0.6835\n","Cf: [[2334   13]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 04:00:23,406]\u001b[0m Trial 125 finished with value: 0.4578313253012048 and parameters: {'a1': 0.522284639475142, 'a2': 0.2515309173262286}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.47198247589642867 0.23868856711567332 0.28932895698789807\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:34<00:00,  1.01it/s, eval_loss=0.1025, gpu_mem=8.82 GB]\n","Valid loss:0.1025\n","Val metric mean prob: 0.2347\n","Best metric at: 0.4819 0.4530  0.6935\n","Cf: [[2335   12]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 04:02:18,067]\u001b[0m Trial 126 finished with value: 0.4819277108433735 and parameters: {'a1': 0.47198247589642867, 'a2': 0.23868856711567332}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4676604371686852 0.2270494191382425 0.3052901436930723\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.03s/it, eval_loss=0.1028, gpu_mem=8.82 GB]\n","Valid loss:0.1028\n","Val metric mean prob: 0.2354\n","Best metric at: 0.4819 0.4540  0.6935\n","Cf: [[2335   12]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 04:04:14,448]\u001b[0m Trial 127 finished with value: 0.4819277108433735 and parameters: {'a1': 0.4676604371686852, 'a2': 0.2270494191382425}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.47547564103426876 0.22932715472277262 0.2951972042429586\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.1026, gpu_mem=8.82 GB]\n","Valid loss:0.1026\n","Val metric mean prob: 0.2350\n","Best metric at: 0.4819 0.4550  0.6935\n","Cf: [[2335   12]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 04:06:08,452]\u001b[0m Trial 128 finished with value: 0.4819277108433735 and parameters: {'a1': 0.47547564103426876, 'a2': 0.22932715472277262}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5397697679851625 0.2333885466665522 0.22684168534828528\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.1018, gpu_mem=8.82 GB]\n","Valid loss:0.1018\n","Val metric mean prob: 0.2324\n","Best metric at: 0.4524 0.4540  0.6833\n","Cf: [[2333   14]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 04:07:53,968]\u001b[0m Trial 129 finished with value: 0.45238095238095244 and parameters: {'a1': 0.5397697679851625, 'a2': 0.2333885466665522}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5060936188941763 0.243041700834844 0.25086468027097975\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:34<00:00,  1.01it/s, eval_loss=0.1019, gpu_mem=8.82 GB]\n","Valid loss:0.1019\n","Val metric mean prob: 0.2336\n","Best metric at: 0.4634 0.4550  0.6837\n","Cf: [[2335   12]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 04:09:36,736]\u001b[0m Trial 130 finished with value: 0.46341463414634143 and parameters: {'a1': 0.5060936188941763, 'a2': 0.243041700834844}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.473936610702058 0.224808881432784 0.30125450786515806\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.1028, gpu_mem=8.82 GB]\n","Valid loss:0.1028\n","Val metric mean prob: 0.2352\n","Best metric at: 0.4819 0.4560  0.6935\n","Cf: [[2335   12]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 04:11:31,797]\u001b[0m Trial 131 finished with value: 0.4819277108433735 and parameters: {'a1': 0.473936610702058, 'a2': 0.224808881432784}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4752739315235198 0.2273970985684538 0.2973289699080264\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1027, gpu_mem=8.82 GB]\n","Valid loss:0.1027\n","Val metric mean prob: 0.2350\n","Best metric at: 0.4819 0.4560  0.6935\n","Cf: [[2335   12]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 04:13:26,383]\u001b[0m Trial 132 finished with value: 0.4819277108433735 and parameters: {'a1': 0.4752739315235198, 'a2': 0.2273970985684538}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4533442388248936 0.20697637606653974 0.33967938510856666\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.03s/it, eval_loss=0.1034, gpu_mem=8.82 GB]\n","Valid loss:0.1034\n","Val metric mean prob: 0.2362\n","Best metric at: 0.4634 0.4610  0.6837\n","Cf: [[2335   12]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 04:15:14,969]\u001b[0m Trial 133 finished with value: 0.46341463414634143 and parameters: {'a1': 0.4533442388248936, 'a2': 0.20697637606653974}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.49031315921214785 0.24991292310979726 0.2597739176780548\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.01s/it, eval_loss=0.1020, gpu_mem=8.82 GB]\n","Valid loss:0.1020\n","Val metric mean prob: 0.2338\n","Best metric at: 0.4706 0.4500  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 04:17:03,325]\u001b[0m Trial 134 finished with value: 0.47058823529411764 and parameters: {'a1': 0.49031315921214785, 'a2': 0.24991292310979726}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.41834834332450066 0.23345065163982165 0.3482010050356777\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1035, gpu_mem=8.82 GB]\n","Valid loss:0.1035\n","Val metric mean prob: 0.2360\n","Best metric at: 0.4500 0.4690  0.6741\n","Cf: [[2336   11]\n"," [  33   18]]\n","\u001b[32m[I 2023-02-18 04:18:49,550]\u001b[0m Trial 135 finished with value: 0.45000000000000007 and parameters: {'a1': 0.41834834332450066, 'a2': 0.23345065163982165}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.523306995727542 0.24545804110719674 0.23123496316526124\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:35<00:00,  1.00it/s, eval_loss=0.1018, gpu_mem=8.82 GB]\n","Valid loss:0.1018\n","Val metric mean prob: 0.2325\n","Best metric at: 0.4578 0.4580  0.6835\n","Cf: [[2334   13]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 04:20:36,071]\u001b[0m Trial 136 finished with value: 0.4578313253012048 and parameters: {'a1': 0.523306995727542, 'a2': 0.24545804110719674}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.569985042425249 0.25788230843032234 0.1721326491444286\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.1009, gpu_mem=8.82 GB]\n","Valid loss:0.1009\n","Val metric mean prob: 0.2302\n","Best metric at: 0.4348 0.4170  0.6916\n","Cf: [[2326   21]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 04:22:23,198]\u001b[0m Trial 137 finished with value: 0.43478260869565216 and parameters: {'a1': 0.569985042425249, 'a2': 0.25788230843032234}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4650306441808484 0.20712270039038347 0.3278466554287681\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.1033, gpu_mem=8.82 GB]\n","Valid loss:0.1033\n","Val metric mean prob: 0.2359\n","Best metric at: 0.4634 0.4610  0.6837\n","Cf: [[2335   12]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 04:24:08,629]\u001b[0m Trial 138 finished with value: 0.46341463414634143 and parameters: {'a1': 0.4650306441808484, 'a2': 0.20712270039038347}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.38886333143632895 0.2247251811488875 0.3864114874147835\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.01s/it, eval_loss=0.1041, gpu_mem=8.82 GB]\n","Valid loss:0.1041\n","Val metric mean prob: 0.2371\n","Best metric at: 0.4500 0.4710  0.6741\n","Cf: [[2336   11]\n"," [  33   18]]\n","\u001b[32m[I 2023-02-18 04:25:54,628]\u001b[0m Trial 139 finished with value: 0.45000000000000007 and parameters: {'a1': 0.38886333143632895, 'a2': 0.2247251811488875}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.44213303699718876 0.27466286266309425 0.283204100339717\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.1023, gpu_mem=8.82 GB]\n","Valid loss:0.1023\n","Val metric mean prob: 0.2342\n","Best metric at: 0.4819 0.4480  0.6935\n","Cf: [[2335   12]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 04:27:48,243]\u001b[0m Trial 140 finished with value: 0.4819277108433735 and parameters: {'a1': 0.44213303699718876, 'a2': 0.27466286266309425}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.47659364891345407 0.23559789020942343 0.2878084608771224\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.1025, gpu_mem=8.82 GB]\n","Valid loss:0.1025\n","Val metric mean prob: 0.2346\n","Best metric at: 0.4819 0.4540  0.6935\n","Cf: [[2335   12]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 04:29:36,837]\u001b[0m Trial 141 finished with value: 0.4819277108433735 and parameters: {'a1': 0.47659364891345407, 'a2': 0.23559789020942343}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4941880731661857 0.24537557626436302 0.26043635056945136\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:35<00:00,  1.00it/s, eval_loss=0.1021, gpu_mem=8.82 GB]\n","Valid loss:0.1021\n","Val metric mean prob: 0.2337\n","Best metric at: 0.4651 0.4480  0.6929\n","Cf: [[2332   15]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 04:31:20,896]\u001b[0m Trial 142 finished with value: 0.46511627906976744 and parameters: {'a1': 0.4941880731661857, 'a2': 0.24537557626436302}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.46926779275568387 0.21954763422765738 0.31118457301665875\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:35<00:00,  1.01it/s, eval_loss=0.1029, gpu_mem=8.82 GB]\n","Valid loss:0.1029\n","Val metric mean prob: 0.2354\n","Best metric at: 0.4819 0.4570  0.6935\n","Cf: [[2335   12]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 04:33:15,994]\u001b[0m Trial 143 finished with value: 0.4819277108433735 and parameters: {'a1': 0.46926779275568387, 'a2': 0.21954763422765738}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.41756607601057233 0.20117433259538126 0.38125959139404636\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.03s/it, eval_loss=0.1041, gpu_mem=8.82 GB]\n","Valid loss:0.1041\n","Val metric mean prob: 0.2371\n","Best metric at: 0.4524 0.4630  0.6833\n","Cf: [[2333   14]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 04:35:07,475]\u001b[0m Trial 144 finished with value: 0.45238095238095244 and parameters: {'a1': 0.41756607601057233, 'a2': 0.20117433259538126}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4513420902033669 0.2357660574172637 0.3128918523793694\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.02s/it, eval_loss=0.1029, gpu_mem=8.82 GB]\n","Valid loss:0.1029\n","Val metric mean prob: 0.2353\n","Best metric at: 0.4706 0.4530  0.6931\n","Cf: [[2333   14]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 04:37:03,673]\u001b[0m Trial 145 finished with value: 0.47058823529411764 and parameters: {'a1': 0.4513420902033669, 'a2': 0.2357660574172637}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5163250046145182 0.22671840760287662 0.2569565877826051\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1021, gpu_mem=8.82 GB]\n","Valid loss:0.1021\n","Val metric mean prob: 0.2338\n","Best metric at: 0.4634 0.4590  0.6837\n","Cf: [[2335   12]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 04:38:55,389]\u001b[0m Trial 146 finished with value: 0.46341463414634143 and parameters: {'a1': 0.5163250046145182, 'a2': 0.22671840760287662}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.40080653794025406 0.1916416758444754 0.4075517862152705\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.01s/it, eval_loss=0.1046, gpu_mem=8.82 GB]\n","Valid loss:0.1046\n","Val metric mean prob: 0.2375\n","Best metric at: 0.4524 0.4660  0.6833\n","Cf: [[2333   14]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 04:40:40,284]\u001b[0m Trial 147 finished with value: 0.45238095238095244 and parameters: {'a1': 0.40080653794025406, 'a2': 0.1916416758444754}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4825489385206215 0.26162977598914217 0.2558212854902364\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.01s/it, eval_loss=0.1019, gpu_mem=8.82 GB]\n","Valid loss:0.1019\n","Val metric mean prob: 0.2336\n","Best metric at: 0.4762 0.4490  0.6933\n","Cf: [[2334   13]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 04:42:32,319]\u001b[0m Trial 148 finished with value: 0.47619047619047616 and parameters: {'a1': 0.4825489385206215, 'a2': 0.26162977598914217}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.43197583255995137 0.22234688308572545 0.3456772843543231\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1035, gpu_mem=8.82 GB]\n","Valid loss:0.1035\n","Val metric mean prob: 0.2362\n","Best metric at: 0.4578 0.4600  0.6835\n","Cf: [[2334   13]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 04:44:20,352]\u001b[0m Trial 149 finished with value: 0.4578313253012048 and parameters: {'a1': 0.43197583255995137, 'a2': 0.22234688308572545}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5019840706219104 0.2735518281850308 0.22446410119305876\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1015, gpu_mem=8.82 GB]\n","Valid loss:0.1015\n","Val metric mean prob: 0.2323\n","Best metric at: 0.4634 0.4510  0.6837\n","Cf: [[2335   12]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 04:46:11,745]\u001b[0m Trial 150 finished with value: 0.46341463414634143 and parameters: {'a1': 0.5019840706219104, 'a2': 0.2735518281850308}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4693742544660359 0.2269556105418708 0.3036701349920932\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.02s/it, eval_loss=0.1028, gpu_mem=8.82 GB]\n","Valid loss:0.1028\n","Val metric mean prob: 0.2353\n","Best metric at: 0.4819 0.4550  0.6935\n","Cf: [[2335   12]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 04:48:06,147]\u001b[0m Trial 151 finished with value: 0.4819277108433735 and parameters: {'a1': 0.4693742544660359, 'a2': 0.2269556105418708}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.47384150459021346 0.25099233023385525 0.2751661651759313\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:37<00:00,  1.01s/it, eval_loss=0.1022, gpu_mem=8.82 GB]\n","Valid loss:0.1022\n","Val metric mean prob: 0.2343\n","Best metric at: 0.4819 0.4540  0.6935\n","Cf: [[2335   12]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 04:49:55,246]\u001b[0m Trial 152 finished with value: 0.4819277108433735 and parameters: {'a1': 0.47384150459021346, 'a2': 0.25099233023385525}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.43875212239879413 0.2110967007212197 0.3501511768799862\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:33<00:00,  1.02it/s, eval_loss=0.1036, gpu_mem=8.82 GB]\n","Valid loss:0.1036\n","Val metric mean prob: 0.2364\n","Best metric at: 0.4524 0.4590  0.6833\n","Cf: [[2333   14]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 04:51:36,959]\u001b[0m Trial 153 finished with value: 0.45238095238095244 and parameters: {'a1': 0.43875212239879413, 'a2': 0.2110967007212197}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.44922062418965475 0.2293940115443849 0.3213853642659603\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:33<00:00,  1.03it/s, eval_loss=0.1031, gpu_mem=8.82 GB]\n","Valid loss:0.1031\n","Val metric mean prob: 0.2354\n","Best metric at: 0.4634 0.4570  0.6837\n","Cf: [[2335   12]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 04:53:18,668]\u001b[0m Trial 154 finished with value: 0.46341463414634143 and parameters: {'a1': 0.44922062418965475, 'a2': 0.2293940115443849}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.41486207942361153 0.26605091700567407 0.3190870035707144\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.01s/it, eval_loss=0.1028, gpu_mem=8.82 GB]\n","Valid loss:0.1028\n","Val metric mean prob: 0.2353\n","Best metric at: 0.4651 0.4430  0.6929\n","Cf: [[2332   15]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 04:55:07,512]\u001b[0m Trial 155 finished with value: 0.46511627906976744 and parameters: {'a1': 0.41486207942361153, 'a2': 0.26605091700567407}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.48543430688146116 0.23975324304042472 0.2748124500781141\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:35<00:00,  1.00it/s, eval_loss=0.1023, gpu_mem=8.82 GB]\n","Valid loss:0.1023\n","Val metric mean prob: 0.2342\n","Best metric at: 0.4762 0.4540  0.6933\n","Cf: [[2334   13]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 04:56:55,276]\u001b[0m Trial 156 finished with value: 0.47619047619047616 and parameters: {'a1': 0.48543430688146116, 'a2': 0.23975324304042472}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.45962159659470697 0.2821890026736629 0.25818940073163005\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:35<00:00,  1.01it/s, eval_loss=0.1019, gpu_mem=8.82 GB]\n","Valid loss:0.1019\n","Val metric mean prob: 0.2334\n","Best metric at: 0.4762 0.4430  0.6933\n","Cf: [[2334   13]\n"," [  31   20]]\n","\u001b[32m[I 2023-02-18 04:58:46,036]\u001b[0m Trial 157 finished with value: 0.47619047619047616 and parameters: {'a1': 0.45962159659470697, 'a2': 0.2821890026736629}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5087793857875254 0.25663239938717647 0.23458821482529818\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:38<00:00,  1.03s/it, eval_loss=0.1017, gpu_mem=8.82 GB]\n","Valid loss:0.1017\n","Val metric mean prob: 0.2327\n","Best metric at: 0.4634 0.4540  0.6837\n","Cf: [[2335   12]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 05:00:37,295]\u001b[0m Trial 158 finished with value: 0.46341463414634143 and parameters: {'a1': 0.5087793857875254, 'a2': 0.25663239938717647}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.5426633616420505 0.21679443361663897 0.2405422047413105\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 96/96 [01:36<00:00,  1.00s/it, eval_loss=0.1020, gpu_mem=8.82 GB]\n","Valid loss:0.1020\n","Val metric mean prob: 0.2328\n","Best metric at: 0.4524 0.4590  0.6833\n","Cf: [[2333   14]\n"," [  32   19]]\n","\u001b[32m[I 2023-02-18 05:02:27,149]\u001b[0m Trial 159 finished with value: 0.45238095238095244 and parameters: {'a1': 0.5426633616420505, 'a2': 0.21679443361663897}. Best is trial 61 with value: 0.4819277108433735.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.4324526077797173 0.189150277238796 0.37839711498148676\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val:  53%|    | 51/96 [00:51<00:45,  1.01s/it, eval_loss=0.1176, gpu_mem=8.82 GB]\n","\u001b[33m[W 2023-02-18 05:03:25,677]\u001b[0m Trial 160 failed with parameters: {'a1': 0.4324526077797173, 'a2': 0.189150277238796} because of the following error: KeyboardInterrupt().\u001b[0m\n","Traceback (most recent call last):\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n","    value_or_values = func(trial)\n","  File \"/tmp/ipykernel_28415/1818135845.py\", line 78, in objective\n","    loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","  File \"/tmp/ipykernel_28415/1289089649.py\", line 65, in valid_fn_two\n","    for step, (images, labels) in pbar:\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/tqdm/std.py\", line 1195, in __iter__\n","    for obj in iterable:\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 628, in __next__\n","    data = self._next_data()\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1316, in _next_data\n","    idx, data = self._get_data()\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1282, in _get_data\n","    success, data = self._try_get_data()\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1120, in _try_get_data\n","    data = self._data_queue.get(timeout=timeout)\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/queues.py\", line 113, in get\n","    if not self._poll(timeout):\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/connection.py\", line 262, in poll\n","    return self._poll(timeout)\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/connection.py\", line 429, in _poll\n","    r = wait([self], timeout)\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/connection.py\", line 936, in wait\n","    ready = selector.select(timeout)\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/selectors.py\", line 416, in select\n","    fd_event_list = self._selector.poll(timeout)\n","KeyboardInterrupt\n","\u001b[33m[W 2023-02-18 05:03:25,678]\u001b[0m Trial 160 failed with value None.\u001b[0m\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[42], line 121\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[39mreturn\u001b[39;00m best_metric\n\u001b[1;32m    120\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m, sampler \u001b[39m=\u001b[39m TPESampler(seed\u001b[39m=\u001b[39m\u001b[39m777\u001b[39m))\n\u001b[0;32m--> 121\u001b[0m study\u001b[39m.\u001b[39;49moptimize(func\u001b[39m=\u001b[39;49mobjective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m study\u001b[39m.\u001b[39mbest_params\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    332\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \n\u001b[1;32m    334\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     _optimize(\n\u001b[1;32m    426\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    427\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    428\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    429\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    430\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    431\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    432\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    433\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    434\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    435\u001b[0m     )\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n","Cell \u001b[0;32mIn[42], line 78\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     75\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(checkpoint[\u001b[39m'\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     76\u001b[0m \u001b[39m#     model = nn.DataParallel(model)\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     loss_valid, valid_preds \u001b[39m=\u001b[39m valid_fn_two(valid_loader, model, criterion, CFG\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m     79\u001b[0m     valid_preds \u001b[39m=\u001b[39m valid_preds[:, \u001b[39m1\u001b[39m]\n\u001b[1;32m     80\u001b[0m     valid_df[\u001b[39m'\u001b[39m\u001b[39mprediction_id\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m valid_df[\u001b[39m'\u001b[39m\u001b[39mpatient_id\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m valid_df[\u001b[39m'\u001b[39m\u001b[39mlaterality\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\n","Cell \u001b[0;32mIn[34], line 65\u001b[0m, in \u001b[0;36mvalid_fn_two\u001b[0;34m(val_dataloader, model, criterion, device)\u001b[0m\n\u001b[1;32m     63\u001b[0m preds \u001b[39m=\u001b[39m []\n\u001b[1;32m     64\u001b[0m pbar \u001b[39m=\u001b[39m tqdm(\u001b[39menumerate\u001b[39m(val_dataloader), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(val_dataloader), desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mVal\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[39mfor\u001b[39;00m step, (images, labels) \u001b[39min\u001b[39;00m pbar:\n\u001b[1;32m     66\u001b[0m     images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     67\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1283\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1284\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1121\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    430\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    933\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    935\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    938\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["fold=2\n","valid_df = df[df['fold']==fold].reset_index(drop=True)\n","valid_dataset = BreastDataset(valid_df, transforms=data_transforms['valid'])\n","\n","valid_loader = DataLoader(valid_dataset, batch_size = CFG.valid_bs, \n","                                num_workers=1, shuffle=False, drop_last=False)\n","set_seed(1)\n","out_file = 'swa_model_fold2_5.pth' \n","iteration = [\n","    'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth',\n","    'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth',\n","    'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth',\n","]\n","\n","criterion = nn.CrossEntropyLoss().to(CFG.device)\n","best_metric = 0\n","torch.cuda.empty_cache()\n","def objective(trial):\n","#     a1 = 0.4360187712961733\n","#     a2 = 0.31005592868022136\n","#     a3 = 0.25392530002360536\n","#     a1 = 0.015006661988523864 \n","#     a2 = 0.12003546043452194 \n","#     a3 = 0.8649578775769542\n","#     a1 = 0.020317850755860567 \n","#     a2 = 0.1293785181217534 \n","#     a3 = 0.850303631122386\n","#     a1 = 0.12634002523631388\n","#     a2 = 0.8351954705276587\n","#     a3 = 0.03846450423602743\n","    a1 = trial.suggest_uniform('a1', 0.001, 0.99)\n","    a2 = trial.suggest_uniform('a2', 0.0009, 1-a1-0.001)\n","    a3 = 1-a1-a2\n","    # a3 = trial.suggest_uniform('a3', 0.003, 1-a1-a2)\n","    # a1 = 0.4700450486328235 \n","    # a2 = 0.23862687145742947 \n","    # a3 = 0.2913280799097471\n","    state_dict = None\n","    for i in iteration:\n","        f = i\n","        # print(f)\n","        f = torch.load(f, map_location=lambda storage, loc: storage)\n","        if state_dict is None:\n","            print(\"none: \", i)\n","            state_dict = f['state_dict']\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = f['state_dict'][k]*a1\n","        elif i=='fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth': \n","            print(\"hehe\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a2*f['state_dict'][k]\n","        elif i=='fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth':\n","            print(\"noob\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a3*f['state_dict'][k]\n","#         elif i=='fold1/tf_efficientnetv2_b2_fold_2_model_epoch_9_0.4681_0.319.pth':\n","#             print(\"noobie\", i)\n","#             key = list(f['state_dict'].keys())\n","#             for k in key:\n","#                 state_dict[k] = state_dict[k] + a4*f['state_dict'][k]\n","    print(a1, a2, a3)\n","    # for k in key:\n","    #     state_dict[k] = state_dict[k] / len(iteration)\n","    print('')\n","\n","    # print(out_file)\n","    torch.save({'state_dict': state_dict}, out_file)\n","\n","    model = ModelOld(model_name=CFG.model_name).to(CFG.device)\n","    checkpoint = torch.load(\"swa_model_fold2_5.pth\")\n","    model.load_state_dict(checkpoint['state_dict'])\n","#     model = nn.DataParallel(model)\n","\n","    loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","    valid_preds = valid_preds[:, 1]\n","    valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n","    valid_preds = np.array(valid_preds).flatten()\n","    \n","    valid_df['raw_pred'] = valid_preds\n","    LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n","    grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n","    grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n","    valid_labels_mean = grp_df['cancer'].values\n","    valid_preds_mean = grp_df['raw_pred'].values\n","    # print(valid_labels[:5], valid_preds_mean[:5])\n","    val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n","    LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n","    best_metric_mean_at_epoch = 0\n","    best_metric = 0\n","    \n","    best_threshold_mean = 0\n","    best_auc = 0\n","    best_cf = None\n","    for i in np.arange(0.001, 0.599, 0.001):\n","        valid_argmax = (valid_preds_mean>i).astype(np.int32)\n","        val_metric = pfbeta_np(valid_labels_mean, valid_argmax)\n","        val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n","        val_f1 = f1_score(valid_labels_mean, valid_argmax)\n","        val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n","        cf = confusion_matrix(valid_labels_mean, valid_argmax)\n","        if val_metric> best_metric:\n","            best_metric = val_metric\n","            # best_metric_mean_at_epoch = val_metric\n","            best_threshold_mean = i\n","            best_auc = val_auc\n","            best_cf = cf\n","    if best_metric>0.47:\n","        state = {'state_dict': model.state_dict()}\n","        path = f'site1_swa_{CFG.model_name}_fold_{fold}_model_{best_metric:.4f}_{best_threshold_mean:.3f}.pth'\n","        torch.save(state, path)\n","    \n","    LOGGER.info(f\"Best metric at: {best_metric:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n","    LOGGER.info(f\"Cf: {best_cf}\")\n","    return best_metric\n","\n","study = optuna.create_study(direction='maximize', sampler = TPESampler(seed=777))\n","study.optimize(func=objective, n_trials=200)\n","study.best_params"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2023-02-17 23:37:34,893]\u001b[0m A new study created in memory with name: no-name-7294d8e0-af54-4852-bd01-b810915cd988\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["> SEEDING DONE\n","none:  fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth\n","hehe fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth\n","noob fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth\n","0.15198443381740748 0.25672863401172846 0.591286932170864\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val:   0%|          | 0/77 [00:00<?, ?it/s]\n","\u001b[33m[W 2023-02-17 23:37:42,143]\u001b[0m Trial 0 failed with parameters: {'a1': 0.15198443381740748, 'a2': 0.25672863401172846} because of the following error: KeyboardInterrupt().\u001b[0m\n","Traceback (most recent call last):\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n","    value_or_values = func(trial)\n","  File \"/tmp/ipykernel_28415/1352320558.py\", line 78, in objective\n","    loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","  File \"/tmp/ipykernel_28415/1289089649.py\", line 65, in valid_fn_two\n","    for step, (images, labels) in pbar:\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/tqdm/std.py\", line 1195, in __iter__\n","    for obj in iterable:\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 628, in __next__\n","    data = self._next_data()\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1316, in _next_data\n","    idx, data = self._get_data()\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1282, in _get_data\n","    success, data = self._try_get_data()\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1120, in _try_get_data\n","    data = self._data_queue.get(timeout=timeout)\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/queues.py\", line 113, in get\n","    if not self._poll(timeout):\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/connection.py\", line 262, in poll\n","    return self._poll(timeout)\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/connection.py\", line 429, in _poll\n","    r = wait([self], timeout)\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/connection.py\", line 936, in wait\n","    ready = selector.select(timeout)\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/selectors.py\", line 416, in select\n","    fd_event_list = self._selector.poll(timeout)\n","KeyboardInterrupt\n","\u001b[33m[W 2023-02-17 23:37:42,145]\u001b[0m Trial 0 failed with value None.\u001b[0m\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[40], line 121\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[39mreturn\u001b[39;00m best_metric\n\u001b[1;32m    120\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m, sampler \u001b[39m=\u001b[39m TPESampler(seed\u001b[39m=\u001b[39m\u001b[39m777\u001b[39m))\n\u001b[0;32m--> 121\u001b[0m study\u001b[39m.\u001b[39;49moptimize(func\u001b[39m=\u001b[39;49mobjective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m study\u001b[39m.\u001b[39mbest_params\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    332\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \n\u001b[1;32m    334\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     _optimize(\n\u001b[1;32m    426\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    427\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    428\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    429\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    430\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    431\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    432\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    433\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    434\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    435\u001b[0m     )\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n","Cell \u001b[0;32mIn[40], line 78\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     75\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(checkpoint[\u001b[39m'\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     76\u001b[0m \u001b[39m#     model = nn.DataParallel(model)\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     loss_valid, valid_preds \u001b[39m=\u001b[39m valid_fn_two(valid_loader, model, criterion, CFG\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m     79\u001b[0m     valid_preds \u001b[39m=\u001b[39m valid_preds[:, \u001b[39m1\u001b[39m]\n\u001b[1;32m     80\u001b[0m     valid_df[\u001b[39m'\u001b[39m\u001b[39mprediction_id\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m valid_df[\u001b[39m'\u001b[39m\u001b[39mpatient_id\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m valid_df[\u001b[39m'\u001b[39m\u001b[39mlaterality\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\n","Cell \u001b[0;32mIn[34], line 65\u001b[0m, in \u001b[0;36mvalid_fn_two\u001b[0;34m(val_dataloader, model, criterion, device)\u001b[0m\n\u001b[1;32m     63\u001b[0m preds \u001b[39m=\u001b[39m []\n\u001b[1;32m     64\u001b[0m pbar \u001b[39m=\u001b[39m tqdm(\u001b[39menumerate\u001b[39m(val_dataloader), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(val_dataloader), desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mVal\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[39mfor\u001b[39;00m step, (images, labels) \u001b[39min\u001b[39;00m pbar:\n\u001b[1;32m     66\u001b[0m     images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     67\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1283\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1284\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1121\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    430\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    933\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    935\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    938\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["fold=2\n","valid_df = df[df['fold']==fold].reset_index(drop=True)\n","valid_df = valid_df[valid_df['site_id']==2].reset_index(drop=True)\n","valid_dataset = BreastDataset(valid_df, transforms=data_transforms['valid'])\n","\n","valid_loader = DataLoader(valid_dataset, batch_size = CFG.valid_bs, \n","                                num_workers=1, shuffle=False, drop_last=False)\n","set_seed(1)\n","out_file = 'swa_model_fold2_5.pth' \n","iteration = [\n","    'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth',\n","    'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth',\n","    'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth',\n","]\n","\n","criterion = nn.CrossEntropyLoss().to(CFG.device)\n","best_metric = 0\n","torch.cuda.empty_cache()\n","def objective(trial):\n","#     a1 = 0.4360187712961733\n","#     a2 = 0.31005592868022136\n","#     a3 = 0.25392530002360536\n","#     a1 = 0.015006661988523864 \n","#     a2 = 0.12003546043452194 \n","#     a3 = 0.8649578775769542\n","#     a1 = 0.020317850755860567 \n","#     a2 = 0.1293785181217534 \n","#     a3 = 0.850303631122386\n","#     a1 = 0.12634002523631388\n","#     a2 = 0.8351954705276587\n","#     a3 = 0.03846450423602743\n","    a1 = trial.suggest_uniform('a1', 0.001, 0.99)\n","    a2 = trial.suggest_uniform('a2', 0.0009, 1-a1-0.001)\n","    a3 = 1-a1-a2\n","    # a3 = trial.suggest_uniform('a3', 0.003, 1-a1-a2)\n","    # a1 = 0.4700450486328235 \n","    # a2 = 0.23862687145742947 \n","    # a3 = 0.2913280799097471\n","    state_dict = None\n","    for i in iteration:\n","        f = i\n","        # print(f)\n","        f = torch.load(f, map_location=lambda storage, loc: storage)\n","        if state_dict is None:\n","            print(\"none: \", i)\n","            state_dict = f['state_dict']\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = f['state_dict'][k]*a1\n","        elif i=='fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth': \n","            print(\"hehe\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a2*f['state_dict'][k]\n","        elif i=='fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth':\n","            print(\"noob\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a3*f['state_dict'][k]\n","#         elif i=='fold1/tf_efficientnetv2_b2_fold_2_model_epoch_9_0.4681_0.319.pth':\n","#             print(\"noobie\", i)\n","#             key = list(f['state_dict'].keys())\n","#             for k in key:\n","#                 state_dict[k] = state_dict[k] + a4*f['state_dict'][k]\n","    print(a1, a2, a3)\n","    # for k in key:\n","    #     state_dict[k] = state_dict[k] / len(iteration)\n","    print('')\n","\n","    # print(out_file)\n","    torch.save({'state_dict': state_dict}, out_file)\n","\n","    model = ModelOld(model_name=CFG.model_name).to(CFG.device)\n","    checkpoint = torch.load(\"swa_model_fold2_5.pth\")\n","    model.load_state_dict(checkpoint['state_dict'])\n","#     model = nn.DataParallel(model)\n","\n","    loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","    valid_preds = valid_preds[:, 1]\n","    valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n","    valid_preds = np.array(valid_preds).flatten()\n","    \n","    valid_df['raw_pred'] = valid_preds\n","    LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n","    grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n","    grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n","    valid_labels_mean = grp_df['cancer'].values\n","    valid_preds_mean = grp_df['raw_pred'].values\n","    # print(valid_labels[:5], valid_preds_mean[:5])\n","    val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n","    LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n","    best_metric_mean_at_epoch = 0\n","    best_metric = 0\n","    \n","    best_threshold_mean = 0\n","    best_auc = 0\n","    best_cf = None\n","    for i in np.arange(0.001, 0.599, 0.001):\n","        valid_argmax = (valid_preds_mean>i).astype(np.int32)\n","        val_metric = pfbeta_np(valid_labels_mean, valid_argmax)\n","        val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n","        val_f1 = f1_score(valid_labels_mean, valid_argmax)\n","        val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n","        cf = confusion_matrix(valid_labels_mean, valid_argmax)\n","        if val_metric> best_metric:\n","            best_metric = val_metric\n","            # best_metric_mean_at_epoch = val_metric\n","            best_threshold_mean = i\n","            best_auc = val_auc\n","            best_cf = cf\n","    if best_metric>0.55:\n","        state = {'state_dict': model.state_dict()}\n","        path = f'site2_swa_{CFG.model_name}_fold_{fold}_model_{best_metric:.4f}_{best_threshold_mean:.3f}.pth'\n","        torch.save(state, path)\n","    \n","    LOGGER.info(f\"Best metric at: {best_metric:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n","    LOGGER.info(f\"Cf: {best_cf}\")\n","    return best_metric\n","\n","study = optuna.create_study(direction='maximize', sampler = TPESampler(seed=777))\n","study.optimize(func=objective, n_trials=200)\n","study.best_params"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Fold 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2023-02-17 22:57:17,185]\u001b[0m A new study created in memory with name: no-name-ee7c3426-82ad-490b-8656-a26f5656adda\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["> SEEDING DONE\n","Find fold 1\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","none:  fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","hehe fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","0.41343476265084567 0.42182495052152247 0.00011871632791617526 0.0009368038859990152 0.16368476661371667\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 170/170 [03:01<00:00,  1.07s/it, eval_loss=0.0882, gpu_mem=7.92 GB]\n","Valid loss:0.0882\n","Val metric mean prob: 0.2898\n","Best metric at: 0.4725 0.3580  0.7068\n","Cf: [[4625   37]\n"," [  59   43]]\n","\u001b[32m[I 2023-02-17 23:00:27,018]\u001b[0m Trial 0 finished with value: 0.47252747252747257 and parameters: {'a1': 0.41343476265084567, 'a2': 0.42182495052152247, 'a3': 0.00011871632791617526, 'a4': 0.0009368038859990152}. Best is trial 0 with value: 0.47252747252747257.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","none:  fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","hehe fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","0.1461415760181248 0.07884251454774104 0.14424974087974424 0.0020551672478268017 0.6287110013065631\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 170/170 [03:06<00:00,  1.10s/it, eval_loss=0.0871, gpu_mem=7.92 GB]\n","Valid loss:0.0871\n","Val metric mean prob: 0.2753\n","Best metric at: 0.4767 0.3410  0.7207\n","Cf: [[4617   45]\n"," [  56   46]]\n","\u001b[32m[I 2023-02-17 23:03:42,574]\u001b[0m Trial 1 finished with value: 0.4766839378238342 and parameters: {'a1': 0.1461415760181248, 'a2': 0.07884251454774104, 'a3': 0.14424974087974424, 'a4': 0.0020551672478268017}. Best is trial 1 with value: 0.4766839378238342.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","none:  fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","hehe fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","0.39340303201413257 0.3263518987390802 0.11711608175098105 0.015829205780972477 0.14729978171483366\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 170/170 [02:56<00:00,  1.04s/it, eval_loss=0.0873, gpu_mem=7.92 GB]\n","Valid loss:0.0873\n","Val metric mean prob: 0.2907\n","Best metric at: 0.4663 0.3220  0.7157\n","Cf: [[4616   46]\n"," [  57   45]]\n","\u001b[32m[I 2023-02-17 23:06:48,715]\u001b[0m Trial 2 finished with value: 0.46632124352331605 and parameters: {'a1': 0.39340303201413257, 'a2': 0.3263518987390802, 'a3': 0.11711608175098105, 'a4': 0.015829205780972477}. Best is trial 1 with value: 0.4766839378238342.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","none:  fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","hehe fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","0.20320327498447074 0.6988151683153075 0.002753352663287489 0.009864876940377607 0.08536332709655658\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 170/170 [02:56<00:00,  1.04s/it, eval_loss=0.0832, gpu_mem=7.92 GB]\n","Valid loss:0.0832\n","Val metric mean prob: 0.2500\n","Best metric at: 0.4747 0.2490  0.7251\n","Cf: [[4613   49]\n"," [  55   47]]\n","\u001b[32m[I 2023-02-17 23:09:53,764]\u001b[0m Trial 3 finished with value: 0.4747474747474747 and parameters: {'a1': 0.20320327498447074, 'a2': 0.6988151683153075, 'a3': 0.002753352663287489, 'a4': 0.009864876940377607}. Best is trial 1 with value: 0.4766839378238342.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","none:  fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","hehe fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","0.41371444954108855 0.327037214794822 0.036340654547336336 0.000460131242350345 0.22244754987440282\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 170/170 [02:55<00:00,  1.03s/it, eval_loss=0.0886, gpu_mem=7.92 GB]\n","Valid loss:0.0886\n","Val metric mean prob: 0.2945\n","Best metric at: 0.4751 0.3670  0.7069\n","Cf: [[4626   36]\n"," [  59   43]]\n","\u001b[32m[I 2023-02-17 23:12:58,273]\u001b[0m Trial 4 finished with value: 0.4751381215469613 and parameters: {'a1': 0.41371444954108855, 'a2': 0.327037214794822, 'a3': 0.036340654547336336, 'a4': 0.000460131242350345}. Best is trial 1 with value: 0.4766839378238342.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","none:  fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","hehe fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","0.7929363784201058 0.19952666077182207 0.002117499151113268 0.0013776104427212648 0.004041851214237614\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 170/170 [02:54<00:00,  1.03s/it, eval_loss=0.0991, gpu_mem=7.92 GB]\n","Valid loss:0.0991\n","Val metric mean prob: 0.3114\n","Best metric at: 0.4516 0.3150  0.7014\n","Cf: [[4620   42]\n"," [  60   42]]\n","\u001b[32m[I 2023-02-17 23:16:06,241]\u001b[0m Trial 5 finished with value: 0.45161290322580644 and parameters: {'a1': 0.7929363784201058, 'a2': 0.19952666077182207, 'a3': 0.002117499151113268, 'a4': 0.0013776104427212648}. Best is trial 1 with value: 0.4766839378238342.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","none:  fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","hehe fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","0.8677488716207818 0.11742867337409711 0.0012670153639677806 0.00012077288085278285 0.013434666760300477\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 170/170 [03:02<00:00,  1.07s/it, eval_loss=0.1028, gpu_mem=7.92 GB]\n","Valid loss:0.1028\n","Val metric mean prob: 0.3112\n","Best metric at: 0.4541 0.2980  0.7015\n","Cf: [[4621   41]\n"," [  60   42]]\n","\u001b[32m[I 2023-02-17 23:19:21,589]\u001b[0m Trial 6 finished with value: 0.454054054054054 and parameters: {'a1': 0.8677488716207818, 'a2': 0.11742867337409711, 'a3': 0.0012670153639677806, 'a4': 0.00012077288085278285}. Best is trial 1 with value: 0.4766839378238342.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","none:  fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","hehe fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","0.16896228494935864 0.7289035827850572 0.010036387017389814 0.001763076790695471 0.09033466845749892\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 170/170 [03:07<00:00,  1.10s/it, eval_loss=0.0827, gpu_mem=7.92 GB]\n","Valid loss:0.0827\n","Val metric mean prob: 0.2433\n","Best metric at: 0.4751 0.2900  0.7069\n","Cf: [[4626   36]\n"," [  59   43]]\n","\u001b[32m[I 2023-02-17 23:22:38,359]\u001b[0m Trial 7 finished with value: 0.4751381215469613 and parameters: {'a1': 0.16896228494935864, 'a2': 0.7289035827850572, 'a3': 0.010036387017389814, 'a4': 0.001763076790695471}. Best is trial 1 with value: 0.4766839378238342.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","none:  fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","hehe fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","0.9483527453188464 0.027050041446680932 0.016357184078545823 0.00038616876125302616 0.007853860394673827\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 170/170 [02:51<00:00,  1.01s/it, eval_loss=0.1069, gpu_mem=7.92 GB]\n","Valid loss:0.1069\n","Val metric mean prob: 0.3065\n","Best metric at: 0.4432 0.2820  0.6965\n","Cf: [[4620   42]\n"," [  61   41]]\n","\u001b[32m[I 2023-02-17 23:25:39,635]\u001b[0m Trial 8 finished with value: 0.4432432432432432 and parameters: {'a1': 0.9483527453188464, 'a2': 0.027050041446680932, 'a3': 0.016357184078545823, 'a4': 0.00038616876125302616}. Best is trial 1 with value: 0.4766839378238342.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","none:  fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","hehe fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","0.6799494174770863 0.26630434424024535 0.0010628090068418475 0.01084938369831163 0.04183404557751492\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 170/170 [03:00<00:00,  1.06s/it, eval_loss=0.0951, gpu_mem=7.92 GB]\n","Valid loss:0.0951\n","Val metric mean prob: 0.3092\n","Best metric at: 0.4649 0.3250  0.7065\n","Cf: [[4622   40]\n"," [  59   43]]\n","\u001b[32m[I 2023-02-17 23:28:48,713]\u001b[0m Trial 9 finished with value: 0.4648648648648649 and parameters: {'a1': 0.6799494174770863, 'a2': 0.26630434424024535, 'a3': 0.0010628090068418475, 'a4': 0.01084938369831163}. Best is trial 1 with value: 0.4766839378238342.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","none:  fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","hehe fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","0.012330039789369474 0.5611299321580077 0.2983089691126598 0.11648516211586564 0.011745896824097365\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 170/170 [03:06<00:00,  1.10s/it, eval_loss=0.0796, gpu_mem=7.92 GB]\n","Valid loss:0.0796\n","Val metric mean prob: 0.2277\n","Best metric at: 0.4787 0.2530  0.7162\n","Cf: [[4621   41]\n"," [  57   45]]\n","\u001b[32m[I 2023-02-17 23:32:03,942]\u001b[0m Trial 10 finished with value: 0.4787234042553191 and parameters: {'a1': 0.012330039789369474, 'a2': 0.5611299321580077, 'a3': 0.2983089691126598, 'a4': 0.11648516211586564}. Best is trial 10 with value: 0.4787234042553191.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","none:  fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","hehe fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n","fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","noob fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n","0.010632516058786012 0.5205266514514182 0.32135025901555847 0.13959981515199907 0.007890758322238262\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val:  33%|      | 56/170 [01:00<02:02,  1.08s/it, eval_loss=0.0771, gpu_mem=7.92 GB]\n","\u001b[33m[W 2023-02-17 23:33:11,495]\u001b[0m Trial 11 failed with parameters: {'a1': 0.010632516058786012, 'a2': 0.5205266514514182, 'a3': 0.32135025901555847, 'a4': 0.13959981515199907} because of the following error: KeyboardInterrupt().\u001b[0m\n","Traceback (most recent call last):\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n","    value_or_values = func(trial)\n","  File \"/tmp/ipykernel_28415/1275780627.py\", line 83, in objective\n","    loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","  File \"/tmp/ipykernel_28415/1289089649.py\", line 65, in valid_fn_two\n","    for step, (images, labels) in pbar:\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/tqdm/std.py\", line 1195, in __iter__\n","    for obj in iterable:\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 628, in __next__\n","    data = self._next_data()\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1316, in _next_data\n","    idx, data = self._get_data()\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1282, in _get_data\n","    success, data = self._try_get_data()\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1120, in _try_get_data\n","    data = self._data_queue.get(timeout=timeout)\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/queues.py\", line 113, in get\n","    if not self._poll(timeout):\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/connection.py\", line 262, in poll\n","    return self._poll(timeout)\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/connection.py\", line 429, in _poll\n","    r = wait([self], timeout)\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/connection.py\", line 936, in wait\n","    ready = selector.select(timeout)\n","  File \"/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/selectors.py\", line 416, in select\n","    fd_event_list = self._selector.poll(timeout)\n","KeyboardInterrupt\n","\u001b[33m[W 2023-02-17 23:33:11,512]\u001b[0m Trial 11 failed with value None.\u001b[0m\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[35], line 126\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFind fold 1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m, sampler \u001b[39m=\u001b[39m TPESampler(seed\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m--> 126\u001b[0m study\u001b[39m.\u001b[39;49moptimize(func\u001b[39m=\u001b[39;49mobjective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n\u001b[1;32m    127\u001b[0m study\u001b[39m.\u001b[39mbest_params\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    332\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \n\u001b[1;32m    334\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     _optimize(\n\u001b[1;32m    426\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    427\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    428\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    429\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    430\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    431\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    432\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    433\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    434\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    435\u001b[0m     )\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n","Cell \u001b[0;32mIn[35], line 83\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     80\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(checkpoint[\u001b[39m'\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     81\u001b[0m \u001b[39m#     model = nn.DataParallel(model)\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m     loss_valid, valid_preds \u001b[39m=\u001b[39m valid_fn_two(valid_loader, model, criterion, CFG\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m     84\u001b[0m     valid_preds \u001b[39m=\u001b[39m valid_preds[:, \u001b[39m1\u001b[39m]\n\u001b[1;32m     85\u001b[0m     valid_df[\u001b[39m'\u001b[39m\u001b[39mprediction_id\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m valid_df[\u001b[39m'\u001b[39m\u001b[39mpatient_id\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m valid_df[\u001b[39m'\u001b[39m\u001b[39mlaterality\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\n","Cell \u001b[0;32mIn[34], line 65\u001b[0m, in \u001b[0;36mvalid_fn_two\u001b[0;34m(val_dataloader, model, criterion, device)\u001b[0m\n\u001b[1;32m     63\u001b[0m preds \u001b[39m=\u001b[39m []\n\u001b[1;32m     64\u001b[0m pbar \u001b[39m=\u001b[39m tqdm(\u001b[39menumerate\u001b[39m(val_dataloader), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(val_dataloader), desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mVal\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[39mfor\u001b[39;00m step, (images, labels) \u001b[39min\u001b[39;00m pbar:\n\u001b[1;32m     66\u001b[0m     images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     67\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1283\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1284\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1121\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    430\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    933\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    935\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    938\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n","File \u001b[0;32m~/miniconda3/envs/zaloenv/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# set_seed(1)\n","# out_file = 'swa_model_fold1_5.pth' \n","# iteration = [\n","#     'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth',\n","    \n","#     'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth',\n","#     'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth',\n","#     'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth',\n","#     'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth',\n","#     # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_11_0.4211_0.242.pth',\n","#     # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4231_0.320.pth'\n","# ]\n","\n","# criterion = nn.CrossEntropyLoss().to(CFG.device)\n","# best_metric = 0\n","# torch.cuda.empty_cache()\n","# def objective(trial):\n","#     a1 = trial.suggest_uniform('a1', 0.001, 0.99)\n","#     a2 = trial.suggest_uniform('a2', 0.0001, 1-a1-0.001)\n","#     a3 = trial.suggest_uniform('a3', 0.0001, 1-a1-a2-0.001)\n","#     a4 = trial.suggest_loguniform('a4', 0.0001, 1-a1-a2-a3-0.001)\n","#     a5 = 1-a1-a2-a3-a4\n","#     # a5 = trial.suggest_loguniform('a5', 0.0001, 1-a1-a2-a3-a4-0.001)\n","#     # a6 = trial.suggest_loguniform('a6', 0.0001, 1-a1-a2-a3-a4-a5-0.001)\n","#     # a7 = 1-a1-a2-a3-a4-a5-a6\n","#     state_dict = None\n","#     for i in iteration:\n","#         f = i\n","#         print(f)\n","#         f = torch.load(f, map_location=lambda storage, loc: storage)\n","#         if state_dict is None:\n","#             print(\"none: \", i)\n","#             state_dict = f['state_dict']\n","#             key = list(f['state_dict'].keys())\n","#             for k in key:\n","#                 state_dict[k] = f['state_dict'][k]*a1\n","#         elif i=='fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth': \n","#             print(\"hehe\", i)\n","#             key = list(f['state_dict'].keys())\n","#             for k in key:\n","#                 state_dict[k] = state_dict[k] + a2*f['state_dict'][k]\n","#         elif i=='fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth':\n","#             print(\"noob\", i)\n","#             key = list(f['state_dict'].keys())\n","#             for k in key:\n","#                 state_dict[k] = state_dict[k] + a3*f['state_dict'][k]\n","#         elif i=='fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth':\n","#             print(\"noob\", i)\n","#             key = list(f['state_dict'].keys())\n","#             for k in key:\n","#                 state_dict[k] = state_dict[k] + a4*f['state_dict'][k]\n","                \n","#         elif i=='fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth':\n","#             print(\"noob\", i)\n","#             key = list(f['state_dict'].keys())\n","#             for k in key:\n","#                 state_dict[k] = state_dict[k] + a5*f['state_dict'][k]\n","                \n","#         # elif i=='fold1/tf_efficientnetv2_b2_fold_1_model_epoch_11_0.4211_0.242.pth': \n","#         #     print(\"hehe\", i)\n","#         #     key = list(f['state_dict'].keys())\n","#         #     for k in key:\n","#         #         state_dict[k] = state_dict[k] + a6*f['state_dict'][k]\n","                \n","#         # elif i=='fold1/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4231_0.320.pth': \n","#         #     print(\"hehe\", i)\n","#         #     key = list(f['state_dict'].keys())\n","#         #     for k in key:\n","#         #         state_dict[k] = state_dict[k] + a7*f['state_dict'][k]\n","#     print(a1, a2, a3, a4, a5)\n","#     # for k in key:\n","#     #     state_dict[k] = state_dict[k] / len(iteration)\n","#     print('')\n","\n","#     # print(out_file)\n","#     torch.save({'state_dict': state_dict}, out_file)\n","\n","#     model = ModelOld(model_name=CFG.model_name).to(CFG.device)\n","#     checkpoint = torch.load(\"swa_model_fold1_5.pth\")\n","#     model.load_state_dict(checkpoint['state_dict'])\n","# #     model = nn.DataParallel(model)\n","\n","#     loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","#     valid_preds = valid_preds[:, 1]\n","#     valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n","#     valid_preds = np.array(valid_preds).flatten()\n","    \n","#     valid_df['raw_pred'] = valid_preds\n","#     LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n","#     grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n","#     grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n","#     valid_labels_mean = grp_df['cancer'].values\n","#     valid_preds_mean = grp_df['raw_pred'].values\n","#     # print(valid_labels[:5], valid_preds_mean[:5])\n","#     val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n","#     LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n","#     best_metric_mean_at_epoch = 0\n","#     best_metric = 0\n","    \n","#     best_threshold_mean = 0\n","#     best_auc = 0\n","#     best_cf = None\n","#     for i in np.arange(0.001, 0.599, 0.001):\n","#         valid_argmax = (valid_preds_mean>i).astype(np.int32)\n","#         val_metric = pfbeta_np(valid_labels_mean, valid_argmax)\n","#         val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n","#         val_f1 = f1_score(valid_labels_mean, valid_argmax)\n","#         val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n","#         cf = confusion_matrix(valid_labels_mean, valid_argmax)\n","#         if val_metric> best_metric:\n","#             best_metric = val_metric\n","#             # best_metric_mean_at_epoch = val_metric\n","#             best_threshold_mean = i\n","#             best_auc = val_auc\n","#             best_cf = cf\n","#     if best_metric>0.49:\n","#         state = {'state_dict': model.state_dict()}\n","#         path = f'swa_{CFG.model_name}_fold_{fold}_model_{best_metric:.4f}_{best_threshold_mean:.4f}.pth'\n","#         torch.save(state, path)\n","    \n","#     LOGGER.info(f\"Best metric at: {best_metric:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n","#     LOGGER.info(f\"Cf: {best_cf}\")\n","#     return best_metric\n","# print(\"Find fold 1\")\n","# study = optuna.create_study(direction='maximize', sampler = TPESampler(seed=1))\n","# study.optimize(func=objective, n_trials=200)\n","# study.best_params"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# train_loader = DataLoader(train_dataset, batch_size = CFG.train_bs,\n","#                                   num_workers=1, shuffle=True, pin_memory=True, drop_last=True)\n","# for step, (images, labels) in tqdm(enumerate(train_loader)):\n","#     image0 = images[0, :, :, :]\n","#     image0 = torch.permute(image0, (1, 2, 0))\n","#     image0 = image0.cpu().numpy().astype(np.uint8)\n","#     plt.imshow(image0)\n","#     plt.show()\n","#     break"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 10folds b2v2 x1 summary:\n","### epoch 13 fold 0/10 epoch 2 vs 13 (0.673170477524555 0.3268295224754445) 0.5979 cv\n","### epoch 3,4,5,6,7,8 fold 1/10 needs retrain? because stop at epoch 4\n","### 2/3/2023 epoch 3, 5, 6, 8, fold 1/10 better CV\n","### epoch 7 fold 2/10\n","### no epoch fold 3/10\n","### epoch 7,8 fold 4/10 needs retrain because starts after fold 3\n","### epoch 6 fold 4 better CV\n","### epoch 5,8,11,13 fold 5/10\n","### epoch 6,7,9 fold 6/10\n","### epoch 7 fold 7/10 \n","### epoch ~ fold 8/10\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 10folds b2ns x1 summary\n","### epoch 5,7 fold 0/10 0.6304, 4, 7 fold 0/10 6263 \n","### epoch 2,7 fold 1/10\n","### epoch 4,7 fold 2/10"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 5 fold summaries:\n","### all good"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["foldtest/tf_efficientnetv2_b2_fold_1_model_epoch_3_0.5055_0.360.pth\n","foldtest/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4865_0.324.pth\n","\n","swa_model_fold1_10.pth\n"]}],"source":["out_file = 'swa_model_fold1_10.pth' \n","iteration = [\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4231_0.320.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_11_0.4211_0.242.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4568_0.290.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4762_0.152.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_4_0.4151_0.352.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_8_0.4403_0.415.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_11_0.4387_0.436.pth'\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4000_0.122.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4585_0.236.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4149_0.131.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_6_0.4516_0.188.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4557_0.241.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_8_0.4455_0.208.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_9_0.4681_0.319.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_10_0.4550_0.245.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_11_0.4500_0.373.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_12_0.4457_0.298.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_3_0.3867_0.302.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_4_0.3924_0.275.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_6_0.4030_0.339.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_5_0.3850_0.161.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_7_0.4192_0.270.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_8_0.3913_0.362.pth'\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_4_0.4103_0.343.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_5_0.4041_0.141.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_6_0.4648_0.444.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_7_0.4103_0.310.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_8_0.4471_0.371.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_10_0.4062_0.202.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_7_0.4192_0.270.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_11_0.4309_0.199.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_12_0.4074_0.278.pth'\n","    # 'fold4/tf_efficientnetv2_b2_fold_4_model_epoch_5_0.3889_0.407.pth',\n","    # 'fold4/tf_efficientnetv2_b2_fold_4_model_epoch_4_0.4276_0.403.pth',\n","    # 'fold4/tf_efficientnetv2_b2_fold_4_model_epoch_6_0.4000_0.586.pth',\n","    # 'fold4/tf_efficientnetv2_b2_fold_4_model_epoch_7_0.3913_0.444.pth',\n","    # 'fold4/tf_efficientnetv2_b2_fold_4_model_epoch_8_0.3916_0.483.pth'\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_3_0.4444_0.273.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4533_0.439.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4416_0.357.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4400_0.230.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4118_0.398.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4000_0.442.pth'\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4272_0.261.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_6_0.4118_0.425.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_10_0.4314_0.241.pth',\n","    # 'fold4/tf_efficientnetv2_b2_fold_4_model_epoch_6_0.4675_0.377.pth',\n","    # 'fold4/tf_efficientnetv2_b2_fold_4_model_epoch_8_0.4722_0.472.pth',\n","    # 'fold4/tf_efficientnetv2_b2_fold_4_model_epoch_7_0.4810_0.474.pth',\n","    # 'fold6/tf_efficientnetv2_b2_fold_6_model_epoch_6_0.5128_0.307.pth',\n","    # 'fold6/tf_efficientnetv2_b2_fold_6_model_epoch_7_0.5385_0.423.pth',\n","    # 'fold6/tf_efficientnetv2_b2_fold_6_model_epoch_9_0.5135_0.338.pth'\n","    # 'fold14/tf_efficientnetv2_b2_fold_1_model_epoch_3_0.4524_0.331.pth',\n","    # 'fold14/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4510_0.228.pth',\n","    # 'fold14/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4337_0.284.pth',\n","    # 'fold14/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4211_0.231.pth'\n","    # 'fold14/tf_efficientnetv2_b2_fold_4_model_epoch_6_0.5349_0.350.pth',\n","    # 'fold14/tf_efficientnetv2_b2_fold_4_model_epoch_10_0.5349_0.352.pth'\n","    # 'fold14/tf_efficientnetv2_b2_fold_4_model_epoch_8_0.5316_0.367.pth',\n","    # 'fold14/tf_efficientnetv2_b2_fold_4_model_epoch_9_0.5195_0.395.pth',\n","    # 'fold14/tf_efficientnetv2_b2_fold_4_model_epoch_11_0.5287_0.326.pth',\n","    # 'fold14/tf_efficientnetv2_b2_fold_4_model_epoch_12_0.5055_0.308.pth',\n","    # 'fold14/tf_efficientnetv2_b2_fold_4_model_epoch_13_0.5176_0.328.pth'\n","    # 'fold8/tf_efficientnetv2_b2_fold_8_model_epoch_5_0.4675_0.175.pth',\n","    # 'fold8/tf_efficientnetv2_b2_fold_8_model_epoch_13_0.4742_0.337.pth',\n","    # 'fold8/tf_efficientnetv2_b2_fold_8_model_epoch_8_0.4658_0.412.pth'\n","    # 'foldtest/tf_efficientnet_b2_ns_fold_0_model_epoch_4_0.5778_0.326.pth',\n","    # 'foldtest/tf_efficientnet_b2_ns_fold_0_model_epoch_5_0.5783_0.535.pth',\n","    # 'foldtest/tf_efficientnet_b2_ns_fold_0_model_epoch_7_0.5895_0.270.pth',\n","    # 'foldtest/tf_efficientnet_b2_ns_fold_1_model_epoch_2_0.4706_0.370.pth',\n","    # 'foldtest/tf_efficientnet_b2_ns_fold_1_model_epoch_7_0.4557_0.426.pth',\n","    # 'foldtest/tf_efficientnet_b2_ns_fold_2_model_epoch_4_0.5234_0.334.pth',\n","    # 'foldtest/tf_efficientnet_b2_ns_fold_2_model_epoch_7_0.5000_0.234.pth',\n","    # 'foldonechannel/tf_efficientnetv2_b2_fold_0_model_epoch_4_0.5679_0.383.pth',\n","    # 'foldonechannel/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5636_0.153.pth',\n","    # 'foldonechannel/tf_efficientnetv2_b2_fold_0_model_epoch_8_0.5581_0.387.pth',\n","    # 'foldonechannel/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4837_0.455.pth',\n","    # 'foldonechannel/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4636_0.454.pth'\n","    'foldtest/tf_efficientnetv2_b2_fold_1_model_epoch_3_0.5055_0.360.pth',\n","    'foldtest/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4865_0.324.pth'\n","]\n","#46789101112 4824\n","state_dict = None\n","for i in iteration:\n","    f = i\n","    print(f)\n","    f = torch.load(f, map_location=lambda storage, loc: storage)\n","    if state_dict is None:\n","        state_dict = f['state_dict']\n","    else:\n","        key = list(f['state_dict'].keys())\n","        for k in key:\n","            state_dict[k] = state_dict[k] + f['state_dict'][k]\n","\n","for k in key:\n","    state_dict[k] = state_dict[k] / len(iteration)\n","print('')\n","\n","print(out_file)\n","torch.save({'state_dict': state_dict}, out_file)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["set_seed(1)\n","out_file = 'swa_model_fold1_5.pth' \n","iteration = [\n","    'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth',\n","    'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4569_0.264.pth',\n","    'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4444_0.409.pth',\n","    'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth',\n","    'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4430_0.474.pth',\n","    'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4403_0.422.pth',\n","    'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth',\n","]\n","\n","criterion = nn.CrossEntropyLoss().to(CFG.device)\n","best_metric = 0\n","torch.cuda.empty_cache()\n","def objective(trial):\n","#     a1 = 0.036839841333967636 \n","#     a2 = 0.6490629183820655\n","#     a3 = 0.3140972402839668\n","#     a2 = 0.47142151346976024 \n","#     a3 = 0.3596277792186039\n","#     a1 = trial.suggest_uniform('a1', 0.01, 0.99)\n","#     a2 = 1-a1\n","    a1 = trial.suggest_uniform('a1', 0.001, 0.99)\n","    a2 = trial.suggest_uniform('a2', 0.0009, 1-a1-0.001)\n","    a3 = trial.suggest_uniform('a3', 0.0009, 1-a1-a2-0.001)\n","    a4 = trial.suggest_loguniform('a4', 0.0009, 1-a1-a2-a3-0.001)\n","    a5 = trial.suggest_loguniform('a5', 0.0009, 1-a1-a2-a3-0.001)\n","    a6 = trial.suggest_loguniform('a6', 0.0009, 1-a1-a2-a3-0.001)\n","    a7 = 1-a1-a2-a3-a4-a5-a6\n","    # a1 = trial.suggest_uniform('a1', 0.001, 0.99)\n","    # a2 = trial.suggest_uniform('a2', 0.0009, 1-a1)\n","    # a3 = trial.suggest_uniform('a3', 0.0007, 1-a1-a2)\n","    # a4 = trial.suggest_loguniform('a4', 0.0005, 1-a1-a2-a3)\n","    # a5 = trial.suggest_loguniform('a5', 0.00003, 1-a1-a2-a3-a4)\n","    # a6 = trial.suggest_loguniform('a6', 0.00009, 1-a1-a2-a3-a4-a5)\n","    # a7 = 1-a1-a2-a3-a4-a5-a6\n","    state_dict = None\n","    for i in iteration:\n","        f = i\n","        f = torch.load(f, map_location=lambda storage, loc: storage)\n","        if state_dict is None:\n","            print(\"none: \", i)\n","            state_dict = f['state_dict']\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = f['state_dict'][k]*a1\n","        elif i== 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4569_0.264.pth': \n","            print(\"hehe\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a2*f['state_dict'][k]\n","        elif i=='fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4444_0.409.pth':\n","            print(\"noob\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a3*f['state_dict'][k]\n","        elif i=='fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth':\n","            print(\"noob\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a4*f['state_dict'][k]\n","                \n","        elif i=='fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4430_0.474.pth':\n","            print(\"noob\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a5*f['state_dict'][k]\n","                \n","        elif i=='fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4403_0.422.pth': \n","            print(\"hehe\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a6*f['state_dict'][k]\n","                \n","        elif i=='fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth': \n","            print(\"hehe\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a7*f['state_dict'][k]\n","    print(a1, a2, a3, a4, a5, a6, a7)\n","    # for k in key:\n","    #     state_dict[k] = state_dict[k] / len(iteration)\n","    print('')\n","\n","    # print(out_file)\n","    torch.save({'state_dict': state_dict}, out_file)\n","\n","    model = Model(model_name=CFG.model_name).to(CFG.device)\n","    checkpoint = torch.load(\"swa_model_fold1_5.pth\")\n","    model.load_state_dict(checkpoint['state_dict'])\n","#     model = nn.DataParallel(model)\n","\n","    loss_valid, valid_preds, _ = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","    valid_preds = valid_preds[:, 1]\n","    valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n","    valid_preds = np.array(valid_preds).flatten()\n","    \n","    valid_df['raw_pred'] = valid_preds\n","    LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n","    grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n","    grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n","    valid_labels_mean = grp_df['cancer'].values\n","    valid_preds_mean = grp_df['raw_pred'].values\n","    # print(valid_labels[:5], valid_preds_mean[:5])\n","    val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n","    LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n","    best_metric_mean_at_epoch = 0\n","    best_metric = 0\n","    \n","    best_threshold_mean = 0\n","    best_auc = 0\n","    best_cf = None\n","    for i in np.arange(0.001, 0.599, 0.001):\n","        valid_argmax = (valid_preds_mean>i).astype(np.int32)\n","        val_metric = pfbeta_np(valid_labels_mean, valid_argmax)\n","        val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n","        val_f1 = f1_score(valid_labels_mean, valid_argmax)\n","        val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n","        cf = confusion_matrix(valid_labels_mean, valid_argmax)\n","        if val_metric> best_metric:\n","            best_metric = val_metric\n","            # best_metric_mean_at_epoch = val_metric\n","            best_threshold_mean = i\n","            best_auc = val_auc\n","            best_cf = cf\n","    state = {'state_dict': model.state_dict()}\n","    path = f'swa_{CFG.model_name}_fold_{fold}_model_{best_metric:.4f}_{best_threshold_mean:.4f}.pth'\n","    torch.save(state, path)\n","    \n","    LOGGER.info(f\"Best metric at: {best_metric:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n","    LOGGER.info(f\"Cf: {best_cf}\")\n","    return best_metric\n","\n","study = optuna.create_study(direction='maximize', sampler = TPESampler(seed=1))\n","study.optimize(func=objective, n_trials=30)\n","study.best_params"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def pfbeta_np(labels, preds, beta=1):\n","    preds = preds.clip(0, 1)\n","    y_true_count = labels.sum()\n","    ctp = preds[labels==1].sum()\n","    cfp = preds[labels==0].sum()\n","    beta_squared = beta * beta\n","    c_precision = ctp / (ctp + cfp)\n","    c_recall = ctp / y_true_count\n","    if (c_precision > 0 and c_recall > 0):\n","        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n","        return result\n","    else:\n","        return 0.0\n","# fold=3\n","# valid_df = df[df['fold']==fold].reset_index(drop=True)\n","# valid_dataset = BreastDataset(valid_df, transforms=data_transforms['valid'])\n","\n","valid_loader = DataLoader(valid_dataset, batch_size = CFG.valid_bs, \n","                                num_workers=1, shuffle=False, drop_last=False)\n","set_seed(1)\n","out_file = 'swa_model_fold3_5.pth' \n","iteration = [\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4625_0.367.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4766_0.251.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_12_0.4824_0.297.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_13_0.4771_0.241.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_15_0.4878_0.242.pth'\n","    'foldsensemble/tf_efficientnetv2_b2_fold_3_model_epoch_6_0.4648_0.444.pth',\n","    'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_7_0.4545_0.354.pth',\n","    'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_2_0.4528_0.320.pth',\n","    'foldsensemble/tf_efficientnetv2_b2_fold_3_model_epoch_8_0.4471_0.371.pth',\n","    'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_4_0.4379_0.392.pth',\n","    'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_3_0.4317_0.364.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_3_0.4224_0.288.pth',\n","    # 'foldsensemble/tf_efficientnetv2_b2_fold_3_model_epoch_7_0.4192_0.270.pth',\n","    # 'foldsensemble/tf_efficientnetv2_b2_fold_3_model_epoch_4_0.4103_0.343.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_2_0.4528_0.320.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_3_0.4317_0.364.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_4_0.4311_0.361.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_6_0.4304_0.332.pth'\n","]\n","\n","criterion = nn.CrossEntropyLoss().to(CFG.device)\n","best_metric = 0\n","torch.cuda.empty_cache()\n","def objective(trial):\n","#     a2 = 0.12003546043452194 \n","#     a3 = 0.8649578775769542\n","#     a1 = 0.020317850755860567 \n","#     a2 = 0.1293785181217534 \n","#     a3 = 0.850303631122386\n","    # a1 = 0.2\n","    # a2 = 0.2    \n","    # a3 = 0.2\n","    # a4 = 0.2\n","    # a5 = 0.2\n","    # a1 = 1\n","    a1 = trial.suggest_uniform('a1', 0.001, 0.99)\n","    a2 = trial.suggest_uniform('a2', 0.0009, 1-a1-0.001)\n","    a3 = trial.suggest_loguniform('a3', 0.00009, 1-a1-a2-0.001)\n","    # a4 = 1-a1-a2-a3\n","    a4 = trial.suggest_loguniform('a4', 0.000009, 1-a1-a2-a3-0.001)\n","    # a5 = 1-a1-a2-a3-a4\n","    a5 = trial.suggest_loguniform('a5', 0.0000009, 1-a1-a2-a3-a4-0.001)\n","    a6 = 1-a1-a2-a3-a4-a5\n","    # a4 = 1-a1-a2-a3\n","    # a1 = 0.4700450486328235 \n","    # a2 = 0.23862687145742947 \n","    # a3 = 0.2913280799097471\n","    state_dict = None\n","    for i in iteration:\n","        f = i\n","        # print(f)\n","        f = torch.load(f, map_location=lambda storage, loc: storage)\n","        if state_dict is None:\n","            print(\"none: \", i)\n","            state_dict = f['state_dict']\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = f['state_dict'][k]*a1\n","        elif i=='fold3/tf_efficientnetv2_b2_fold_3_model_epoch_7_0.4545_0.354.pth': \n","            print(\"hehe\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a2*f['state_dict'][k]\n","        elif i=='fold3/tf_efficientnetv2_b2_fold_3_model_epoch_2_0.4528_0.320.pth': \n","            print(\"hehe\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a3*f['state_dict'][k]\n","        elif i=='foldsensemble/tf_efficientnetv2_b2_fold_3_model_epoch_8_0.4471_0.371.pth':\n","            print(\"noob\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a4*f['state_dict'][k]\n","        elif i=='fold3/tf_efficientnetv2_b2_fold_3_model_epoch_4_0.4379_0.392.pth':\n","            print(\"noobie\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a5*f['state_dict'][k]\n","        elif i=='fold3/tf_efficientnetv2_b2_fold_3_model_epoch_3_0.4317_0.364.pth':\n","            print(\"noobie\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a6*f['state_dict'][k]\n","    print(a1, a2, a3, a4, a5, a6)\n","    # for k in key:\n","    #     state_dict[k] = state_dict[k] / len(iteration)\n","    print('')\n","\n","    # print(out_file)\n","    torch.save({'state_dict': state_dict}, out_file)\n","\n","    model = Model(model_name=CFG.model_name).to(CFG.device)\n","    checkpoint = torch.load(\"swa_model_fold3_5.pth\")\n","    model.load_state_dict(checkpoint['state_dict'])\n","#     model = nn.DataParallel(model)\n","\n","    loss_valid, valid_preds, _ = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","    valid_preds = valid_preds[:, 1]\n","    valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n","    valid_preds = np.array(valid_preds).flatten()\n","    \n","    valid_df['raw_pred'] = valid_preds\n","    LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n","    grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n","    grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n","    valid_labels_mean = grp_df['cancer'].values\n","    valid_preds_mean = grp_df['raw_pred'].values\n","    # print(valid_labels[:5], valid_preds_mean[:5])\n","    val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n","    LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n","    best_metric_mean_at_epoch = 0\n","    best_metric = 0\n","    \n","    best_threshold_mean = 0\n","    best_auc = 0\n","    best_cf = None\n","    for i in np.arange(0.001, 0.599, 0.001):\n","        valid_argmax = (valid_preds_mean>i).astype(np.int32)\n","        val_metric = pfbeta_np(valid_labels_mean, valid_argmax)\n","        val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n","        val_f1 = f1_score(valid_labels_mean, valid_argmax)\n","        val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n","        cf = confusion_matrix(valid_labels_mean, valid_argmax)\n","        if val_metric> best_metric:\n","            best_metric = val_metric\n","            # best_metric_mean_at_epoch = val_metric\n","            best_threshold_mean = i\n","            best_auc = val_auc\n","            best_cf = cf\n","    if best_metric>0.51:\n","        state = {'state_dict': model.state_dict()}\n","        path = f'swa_{CFG.model_name}_fold_{fold}_model_{best_metric:.4f}_{best_threshold_mean:.3f}.pth'\n","        torch.save(state, path)\n","    \n","    LOGGER.info(f\"Best metric at: {best_metric:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n","    LOGGER.info(f\"Cf: {best_cf}\")\n","    torch.cuda.empty_cache()\n","    return best_metric\n","\n","study = optuna.create_study(direction='maximize', sampler = TPESampler(seed=666))\n","study.optimize(func=objective, n_trials=200)\n","study.best_params"]}],"metadata":{"kernelspec":{"display_name":"zaloenv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"d81213625f550c7b434bbb4e964cd1250716e6d81b88f327aa7e418dc0078b84"}}},"nbformat":4,"nbformat_minor":4}
