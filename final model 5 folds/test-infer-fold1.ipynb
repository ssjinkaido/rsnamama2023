{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc1c9c06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:23:11.672209Z",
     "iopub.status.busy": "2023-02-15T14:23:11.671691Z",
     "iopub.status.idle": "2023-02-15T14:23:23.152178Z",
     "shell.execute_reply": "2023-02-15T14:23:23.151047Z"
    },
    "papermill": {
     "duration": 11.4902,
     "end_time": "2023-02-15T14:23:23.154864",
     "exception": false,
     "start_time": "2023-02-15T14:23:11.664664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from glob import glob\n",
    "import os, shutil\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import copy\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "from IPython import display as ipd\n",
    "import math\n",
    "# visualization\n",
    "import cv2\n",
    "from glob import glob\n",
    "# Sklearn\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix, roc_curve\n",
    "import timm\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from collections import defaultdict\n",
    "# import matplotlib.pyplot as plt\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "import albumentations\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f83dbb66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:23:23.166460Z",
     "iopub.status.busy": "2023-02-15T14:23:23.165836Z",
     "iopub.status.idle": "2023-02-15T14:23:23.173044Z",
     "shell.execute_reply": "2023-02-15T14:23:23.171899Z"
    },
    "papermill": {
     "duration": 0.018075,
     "end_time": "2023-02-15T14:23:23.177901",
     "exception": false,
     "start_time": "2023-02-15T14:23:23.159826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    seed = 1\n",
    "    model_name = \"tf_efficientnetv2_b2\"\n",
    "    train_bs = 16\n",
    "    valid_bs = train_bs*4\n",
    "    image_size = 1024\n",
    "    epochs = 25\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(CFG.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c86054ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:23:23.189163Z",
     "iopub.status.busy": "2023-02-15T14:23:23.188843Z",
     "iopub.status.idle": "2023-02-15T14:23:23.332553Z",
     "shell.execute_reply": "2023-02-15T14:23:23.331314Z"
    },
    "papermill": {
     "duration": 0.152003,
     "end_time": "2023-02-15T14:23:23.335022",
     "exception": false,
     "start_time": "2023-02-15T14:23:23.183019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>laterality</th>\n",
       "      <th>view</th>\n",
       "      <th>age</th>\n",
       "      <th>cancer</th>\n",
       "      <th>biopsy</th>\n",
       "      <th>invasive</th>\n",
       "      <th>BIRADS</th>\n",
       "      <th>implant</th>\n",
       "      <th>density</th>\n",
       "      <th>machine_id</th>\n",
       "      <th>difficult_negative_case</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>10006</td>\n",
       "      <td>462822612</td>\n",
       "      <td>L</td>\n",
       "      <td>CC</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10006</td>\n",
       "      <td>1459541791</td>\n",
       "      <td>L</td>\n",
       "      <td>MLO</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10006</td>\n",
       "      <td>1864590858</td>\n",
       "      <td>R</td>\n",
       "      <td>MLO</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>10006</td>\n",
       "      <td>1874946579</td>\n",
       "      <td>R</td>\n",
       "      <td>CC</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>10011</td>\n",
       "      <td>220375232</td>\n",
       "      <td>L</td>\n",
       "      <td>CC</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_id  patient_id    image_id laterality view   age  cancer  biopsy  \\\n",
       "0        2       10006   462822612          L   CC  61.0       0       0   \n",
       "1        2       10006  1459541791          L  MLO  61.0       0       0   \n",
       "2        2       10006  1864590858          R  MLO  61.0       0       0   \n",
       "3        2       10006  1874946579          R   CC  61.0       0       0   \n",
       "4        2       10011   220375232          L   CC  55.0       0       0   \n",
       "\n",
       "   invasive  BIRADS  implant density  machine_id  difficult_negative_case  \\\n",
       "0         0     NaN        0     NaN          29                    False   \n",
       "1         0     NaN        0     NaN          29                    False   \n",
       "2         0     NaN        0     NaN          29                    False   \n",
       "3         0     NaN        0     NaN          29                    False   \n",
       "4         0     0.0        0     NaN          21                     True   \n",
       "\n",
       "   fold  \n",
       "0     1  \n",
       "1     1  \n",
       "2     1  \n",
       "3     1  \n",
       "4     0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/5folds/train_5folds.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1786a227",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:23:23.347076Z",
     "iopub.status.busy": "2023-02-15T14:23:23.346177Z",
     "iopub.status.idle": "2023-02-15T14:23:23.355246Z",
     "shell.execute_reply": "2023-02-15T14:23:23.354311Z"
    },
    "papermill": {
     "duration": 0.017084,
     "end_time": "2023-02-15T14:23:23.357233",
     "exception": false,
     "start_time": "2023-02-15T14:23:23.340149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Date :02/15/2023, 14:23:23\n"
     ]
    }
   ],
   "source": [
    "def init_logger(log_file='train1.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "now = datetime.now()\n",
    "datetime_now = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "LOGGER.info(f\"Date :{datetime_now}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1a1edc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:23:23.368161Z",
     "iopub.status.busy": "2023-02-15T14:23:23.367709Z",
     "iopub.status.idle": "2023-02-15T14:23:23.384990Z",
     "shell.execute_reply": "2023-02-15T14:23:23.383854Z"
    },
    "papermill": {
     "duration": 0.025605,
     "end_time": "2023-02-15T14:23:23.387669",
     "exception": false,
     "start_time": "2023-02-15T14:23:23.362064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train transformCompose([\n",
      "  VerticalFlip(always_apply=False, p=0.5),\n",
      "  ColorJitter(always_apply=False, p=0.5, brightness=[0.8, 1.2], contrast=[0.8, 1.2], saturation=[0.8, 1.2], hue=[-0.2, 0.2]),\n",
      "  ShiftScaleRotate(always_apply=False, p=0.5, shift_limit_x=(-0.0625, 0.0625), shift_limit_y=(-0.0625, 0.0625), scale_limit=(-0.050000000000000044, 0.050000000000000044), rotate_limit=(-10, 10), interpolation=1, border_mode=4, value=None, mask_value=None, rotate_method='largest_box'),\n",
      "  HorizontalFlip(always_apply=False, p=0.5),\n",
      "  Cutout(always_apply=False, p=0.5, num_holes=5, max_h_size=102, max_w_size=102),\n",
      "  ToTensorV2(always_apply=True, p=1.0, transpose_mask=False),\n",
      "], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={})\n"
     ]
    }
   ],
   "source": [
    "from albumentations import DualTransform\n",
    "image_size = 1024\n",
    "def isotropically_resize_image(img, size, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC):\n",
    "    h, w = img.shape[:2]\n",
    "    if max(w, h) == size:\n",
    "        return img\n",
    "    if w > h:\n",
    "        scale = size / w\n",
    "        h = h * scale\n",
    "        w = size\n",
    "    else:\n",
    "        scale = size / h\n",
    "        w = w * scale\n",
    "        h = size\n",
    "    interpolation = interpolation_up if scale > 1 else interpolation_down\n",
    "    resized = cv2.resize(img, (int(w), int(h)), interpolation=interpolation)\n",
    "    return resized\n",
    "\n",
    "\n",
    "class IsotropicResize(DualTransform):\n",
    "    def __init__(self, max_side, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC,\n",
    "                 always_apply=False, p=1):\n",
    "        super(IsotropicResize, self).__init__(always_apply, p)\n",
    "        self.max_side = max_side\n",
    "        self.interpolation_down = interpolation_down\n",
    "        self.interpolation_up = interpolation_up\n",
    "\n",
    "    def apply(self, img, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC, **params):\n",
    "        return isotropically_resize_image(img, size=self.max_side, interpolation_down=interpolation_down,\n",
    "                                          interpolation_up=interpolation_up)\n",
    "\n",
    "    def apply_to_mask(self, img, **params):\n",
    "        return self.apply(img, interpolation_down=cv2.INTER_NEAREST, interpolation_up=cv2.INTER_NEAREST, **params)\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return (\"max_side\", \"interpolation_down\", \"interpolation_up\")\n",
    "    \n",
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        # A.Resize(image_size, image_size),\n",
    "        # IsotropicResize(max_side = image_size),\n",
    "        # A.PadIfNeeded(min_height=image_size, min_width=image_size, border_mode=cv2.BORDER_CONSTANT),\n",
    "        # A.RandomBrightnessContrast(),\n",
    "        A.VerticalFlip(p=0.5),   \n",
    "        A.ColorJitter(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Cutout(max_h_size=int(image_size*0.1), max_w_size=int(image_size*0.1), num_holes=5, p=0.5), \n",
    "        # A.OneOf([\n",
    "        #         A.OpticalDistortion(),\n",
    "        #         A.IAAPiecewiseAffine(),\n",
    "        #     ], p=0.1),\n",
    "        # A.OneOf([\n",
    "        #     A.GaussNoise(),\n",
    "        #     A.MotionBlur(blur_limit=(3, 5)),\n",
    "        # ], p=0.1),\n",
    "        # A.ColorJitter(),\n",
    "        # A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n",
    "        # A.HorizontalFlip(p=0.5),\n",
    "        # A.Cutout(max_h_size=102, max_w_size=102, num_holes=5, p=0.5),\n",
    "        # A.CLAHE(p=1.0),\n",
    "        # albumentations.HorizontalFlip(p=0.5),\n",
    "        # # albumentations.VerticalFlip(p=0.5),\n",
    "        # albumentations.RandomBrightness(limit=0.2, p=0.75),\n",
    "        # albumentations.RandomContrast(limit=0.2, p=0.75),\n",
    "\n",
    "        # albumentations.OneOf([\n",
    "        #     albumentations.OpticalDistortion(distort_limit=1.),\n",
    "        #     albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "        # ], p=0.75),\n",
    "\n",
    "        # albumentations.HueSaturationValue(hue_shift_limit=40, sat_shift_limit=40, val_shift_limit=0, p=0.75),\n",
    "        # albumentations.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.3, rotate_limit=30, border_mode=0, p=0.75),\n",
    "        # A.Cutout(always_apply=False, p=0.5, num_holes=1, max_h_size=409, max_w_size=409),\n",
    "        # A.OneOf([ \n",
    "        # A.OpticalDistortion(distort_limit=1.0), \n",
    "        # A.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "        # A.ElasticTransform(alpha=3), ], p=0.2),\n",
    "        # A.OneOf([\n",
    "        #     # A.GaussNoise(var_limit=[10, 50]),\n",
    "        #     A.GaussianBlur(),\n",
    "        #     A.MotionBlur(),\n",
    "        #     A.MedianBlur(), ], p=0.2),\n",
    "        # A.OneOf([\n",
    "        #     A.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n",
    "        #     A.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=1.0),\n",
    "        #     A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n",
    "        # ], p=0.25),\n",
    "        # A.CoarseDropout(max_holes=8, max_height=image_size//20, max_width=image_size//20,\n",
    "        #                  min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n",
    "        # A.Normalize(mean=0, std=1),\n",
    "        ToTensorV2(),], p=1.0),\n",
    "    \n",
    "    \"valid\": A.Compose([\n",
    "        # IsotropicResize(max_side =image_size),\n",
    "        # A.PadIfNeeded(min_height=image_size, min_width=image_size, border_mode=cv2.BORDER_CONSTANT),\n",
    "        # A.Normalize(mean=0, std=1),\n",
    "        # A.Resize(image_size, image_size),\n",
    "        ToTensorV2(),\n",
    "        ], p=1.0)\n",
    "}\n",
    "\n",
    "LOGGER.info(f\"train transform{data_transforms['train']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "991abf17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:23:23.400097Z",
     "iopub.status.busy": "2023-02-15T14:23:23.398458Z",
     "iopub.status.idle": "2023-02-15T14:23:23.616649Z",
     "shell.execute_reply": "2023-02-15T14:23:23.615622Z"
    },
    "papermill": {
     "duration": 0.227169,
     "end_time": "2023-02-15T14:23:23.619832",
     "exception": false,
     "start_time": "2023-02-15T14:23:23.392663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1344, 840]) tensor(0)\n",
      "tensor(249.)\n"
     ]
    }
   ],
   "source": [
    "def pad(array, target_shape):\n",
    "    return np.pad(\n",
    "        array,\n",
    "        [(0, target_shape[i] - array.shape[i]) for i in range(len(array.shape))],\n",
    "        \"constant\",\n",
    "    )\n",
    "\n",
    "def load_img2(img_path):\n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "class BreastDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        if (os.path.exists(f\"/kaggle/input/27300next/output/{row.patient_id}_{row.image_id}.png\")):\n",
    "            img_path = f\"/kaggle/input/27300next/output/{row.patient_id}_{row.image_id}.png\"\n",
    "        else:\n",
    "            img_path = f\"/kaggle/input/1024bicubic/output/{row.patient_id}_{row.image_id}.png\"\n",
    "        img = load_img2(img_path)\n",
    "        label = row['cancer']\n",
    "        # img = np.transpose(img, (2, 0, 1))\n",
    "        data = self.transforms(image=img)\n",
    "        img  = data['image']\n",
    "        # img = img/255\n",
    "        return torch.tensor(img).float(), torch.tensor(label).long()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "fold0 = df[df['fold']==0]\n",
    "train_dataset = BreastDataset(fold0, transforms = data_transforms['train'])\n",
    "image, label = train_dataset[0]\n",
    "print(image.shape, label)\n",
    "print(image.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc718ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:23:23.631814Z",
     "iopub.status.busy": "2023-02-15T14:23:23.631118Z",
     "iopub.status.idle": "2023-02-15T14:23:23.638449Z",
     "shell.execute_reply": "2023-02-15T14:23:23.637554Z"
    },
    "papermill": {
     "duration": 0.015183,
     "end_time": "2023-02-15T14:23:23.640616",
     "exception": false,
     "start_time": "2023-02-15T14:23:23.625433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class ModelOld(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        # ,drop_rate = 0.3, drop_path_rate = 0.2\n",
    "        self.backbone = timm.create_model(CFG.model_name, pretrained=False,drop_rate = 0.3, drop_path_rate = 0.2)\n",
    "        self.fc = nn.Linear(self.backbone.classifier.in_features,2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.fc(self.dropout(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7bb79f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:23:23.652384Z",
     "iopub.status.busy": "2023-02-15T14:23:23.651487Z",
     "iopub.status.idle": "2023-02-15T14:23:23.659731Z",
     "shell.execute_reply": "2023-02-15T14:23:23.658858Z"
    },
    "papermill": {
     "duration": 0.016211,
     "end_time": "2023-02-15T14:23:23.661749",
     "exception": false,
     "start_time": "2023-02-15T14:23:23.645538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d169e3b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:23:23.673179Z",
     "iopub.status.busy": "2023-02-15T14:23:23.672323Z",
     "iopub.status.idle": "2023-02-15T14:23:23.681449Z",
     "shell.execute_reply": "2023-02-15T14:23:23.680586Z"
    },
    "papermill": {
     "duration": 0.017001,
     "end_time": "2023-02-15T14:23:23.683640",
     "exception": false,
     "start_time": "2023-02-15T14:23:23.666639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def valid_fn_two(val_dataloader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    truth = []\n",
    "    preds = []\n",
    "    valid_labels = []\n",
    "    start = end = time.time()\n",
    "    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n",
    "    for step, (images, labels) in pbar:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "        valid_labels.append(labels.cpu().numpy())\n",
    "        loss = criterion(outputs, labels)\n",
    "#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "#         print(outputs)\n",
    "        preds.append(F.softmax(outputs).to('cpu').numpy())\n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n",
    "                        gpu_mem=f'{mem:0.2f} GB')\n",
    "    predictions = np.concatenate(preds)\n",
    "    valid_labels = np.concatenate(valid_labels)\n",
    "    return losses.avg, predictions, valid_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "924b859c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:23:23.694960Z",
     "iopub.status.busy": "2023-02-15T14:23:23.694646Z",
     "iopub.status.idle": "2023-02-15T14:23:23.954252Z",
     "shell.execute_reply": "2023-02-15T14:23:23.953245Z"
    },
    "papermill": {
     "duration": 0.267632,
     "end_time": "2023-02-15T14:23:23.956429",
     "exception": false,
     "start_time": "2023-02-15T14:23:23.688797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SEEDING DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5 fold\n",
      "Fold: 1\n",
      "Model name: tf_efficientnetv2_b2\n",
      "Len valid df: 10879\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def pfbeta(labels, predictions, beta=1):\n",
    "    y_true_count = 0\n",
    "    ctp = 0\n",
    "    cfp = 0\n",
    "\n",
    "    for idx in range(len(labels)):\n",
    "        prediction = min(max(predictions[idx], 0), 1)\n",
    "        if (labels[idx]):\n",
    "            y_true_count += 1\n",
    "            ctp += prediction\n",
    "        else:\n",
    "            cfp += prediction\n",
    "\n",
    "    beta_squared = beta * beta\n",
    "    c_precision = ctp / (ctp + cfp)\n",
    "    c_recall = ctp / y_true_count\n",
    "    if (c_precision > 0 and c_recall > 0):\n",
    "        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n",
    "        return result\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def pfbeta_np(labels, preds, beta=1):\n",
    "    preds = preds.clip(0, 1)\n",
    "    y_true_count = labels.sum()\n",
    "    ctp = preds[labels==1].sum()\n",
    "    cfp = preds[labels==0].sum()\n",
    "    beta_squared = beta * beta\n",
    "    c_precision = ctp / (ctp + cfp)\n",
    "    c_recall = ctp / y_true_count\n",
    "    if (c_precision > 0 and c_recall > 0):\n",
    "        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n",
    "        return result\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "def dfs_freeze(module):\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "def dfs_unfreeze(module):\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "def set_seed(seed = 42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print('> SEEDING DONE')\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "def valid_fn_two(val_dataloader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n",
    "    for step, (images, labels) in pbar:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            with autocast(enabled=True):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "#         print(outputs)\n",
    "        preds.append(F.softmax(outputs).to('cpu').numpy())\n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n",
    "                        gpu_mem=f'{mem:0.2f} GB')\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions\n",
    "set_seed(1)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "for fold in [1]:\n",
    "    LOGGER.info(\"5 fold\")\n",
    "    LOGGER.info(f\"Fold: {fold}\")\n",
    "    LOGGER.info(f\"Model name: {CFG.model_name}\")\n",
    "    valid_df = df[df['fold']==fold].reset_index(drop=True)\n",
    "    LOGGER.info(f\"Len valid df: {len(valid_df)}\")\n",
    "    \n",
    "    valid_dataset = BreastDataset(valid_df, transforms=data_transforms['valid'])\n",
    "\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size = CFG.valid_bs, \n",
    "                                  num_workers=1, shuffle=False, pin_memory=True, drop_last=False)\n",
    "    # model = Model(model_name=CFG.model_name).to(device)\n",
    "    best_f1 = 0\n",
    "    best_metric = 0\n",
    "    total_epoch = 30\n",
    "    warmup = 1     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48f9027d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:23:23.968656Z",
     "iopub.status.busy": "2023-02-15T14:23:23.968091Z",
     "iopub.status.idle": "2023-02-15T14:23:24.249643Z",
     "shell.execute_reply": "2023-02-15T14:23:24.248509Z"
    },
    "papermill": {
     "duration": 0.290427,
     "end_time": "2023-02-15T14:23:24.252339",
     "exception": false,
     "start_time": "2023-02-15T14:23:23.961912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "def valid_fn_two(val_dataloader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n",
    "    for step, (images, labels) in pbar:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            with autocast(enabled=True):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "#         print(outputs)\n",
    "        preds.append(F.softmax(outputs).to('cpu').numpy())\n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n",
    "                        gpu_mem=f'{mem:0.2f} GB')\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98e76148",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:23:24.272093Z",
     "iopub.status.busy": "2023-02-15T14:23:24.271702Z",
     "iopub.status.idle": "2023-02-15T14:23:24.282613Z",
     "shell.execute_reply": "2023-02-15T14:23:24.281609Z"
    },
    "papermill": {
     "duration": 0.023009,
     "end_time": "2023-02-15T14:23:24.284620",
     "exception": false,
     "start_time": "2023-02-15T14:23:24.261611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# set_seed(1)\n",
    "# out_file = 'swa_model_fold0_5.pth' \n",
    "# iteration = [\n",
    "#     '/kaggle/input/5folds/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth',\n",
    "#     '/kaggle/input/5folds/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth',\n",
    "#     '/kaggle/input/5folds/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth',\n",
    "#     '/kaggle/input/5folds/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth',\n",
    "#     '/kaggle/input/5folds/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth',\n",
    "#     '/kaggle/input/5folds/tf_efficientnetv2_b2_fold_0_model_epoch_8_0.4403_0.415.pth'\n",
    "# ]\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss().to(CFG.device)\n",
    "# best_metric = 0\n",
    "# torch.cuda.empty_cache()\n",
    "# def objective(trial):\n",
    "# #     a1 = 0.036839841333967636 \n",
    "# #     a2 = 0.6490629183820655\n",
    "# #     a3 = 0.3140972402839668\n",
    "# #     a2 = 0.47142151346976024 \n",
    "# #     a3 = 0.3596277792186039\n",
    "# #     a1 = trial.suggest_uniform('a1', 0.01, 0.99)\n",
    "# #     a2 = 1-a1\n",
    "#     a1 = trial.suggest_uniform('a1', 0.001, 0.99)\n",
    "#     a2 = trial.suggest_uniform('a2', 0.0009, 1-a1)\n",
    "#     a3 = trial.suggest_uniform('a3', 0.0008, 1-a1-a2)\n",
    "#     a4 = trial.suggest_uniform('a4', 0.0007, 1-a1-a2-a3)\n",
    "#     a5 = trial.suggest_uniform('a5', 0.0006, 1-a1-a2-a3-a4)\n",
    "#     a6 = 1-a1-a2-a3-a4-a5\n",
    "#     state_dict = None\n",
    "#     for i in iteration:\n",
    "#         f = i\n",
    "#         print(f)\n",
    "#         f = torch.load(f, map_location=lambda storage, loc: storage)\n",
    "#         if state_dict is None:\n",
    "#             print(\"none: \", i)\n",
    "#             state_dict = f['state_dict']\n",
    "#             key = list(f['state_dict'].keys())\n",
    "#             for k in key:\n",
    "#                 state_dict[k] = f['state_dict'][k]*a1\n",
    "#         elif i=='/kaggle/input/5folds/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth': \n",
    "#             print(\"hehe\", i)\n",
    "#             key = list(f['state_dict'].keys())\n",
    "#             for k in key:\n",
    "#                 state_dict[k] = state_dict[k] + a2*f['state_dict'][k]\n",
    "#         elif i=='/kaggle/input/5folds/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth':\n",
    "#             print(\"noob\", i)\n",
    "#             key = list(f['state_dict'].keys())\n",
    "#             for k in key:\n",
    "#                 state_dict[k] = state_dict[k] + a3*f['state_dict'][k]\n",
    "#         elif i=='/kaggle/input/5folds/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth':\n",
    "#             print(\"noob\", i)\n",
    "#             key = list(f['state_dict'].keys())\n",
    "#             for k in key:\n",
    "#                 state_dict[k] = state_dict[k] + a4*f['state_dict'][k]\n",
    "                \n",
    "#         elif i=='/kaggle/input/5folds/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth':\n",
    "#             print(\"noob\", i)\n",
    "#             key = list(f['state_dict'].keys())\n",
    "#             for k in key:\n",
    "#                 state_dict[k] = state_dict[k] + a5*f['state_dict'][k]\n",
    "#         elif i=='/kaggle/input/5folds/tf_efficientnetv2_b2_fold_0_model_epoch_8_0.4403_0.415.pth':\n",
    "#             print(\"noob\", i)\n",
    "#             key = list(f['state_dict'].keys())\n",
    "#             for k in key:\n",
    "#                 state_dict[k] = state_dict[k] + a5*f['state_dict'][k]\n",
    "#     print(a1, a2, a3, a4, a5)\n",
    "#     # for k in key:\n",
    "#     #     state_dict[k] = state_dict[k] / len(iteration)\n",
    "#     print('')\n",
    "\n",
    "#     # print(out_file)\n",
    "#     torch.save({'state_dict': state_dict}, out_file)\n",
    "\n",
    "#     model = ModelOld(model_name=CFG.model_name).to(CFG.device)\n",
    "#     checkpoint = torch.load(\"swa_model_fold0_5.pth\")\n",
    "#     model.load_state_dict(checkpoint['state_dict'])\n",
    "# #     model = nn.DataParallel(model)\n",
    "\n",
    "#     loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n",
    "#     valid_preds = valid_preds[:, 1]\n",
    "#     valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n",
    "#     valid_preds = np.array(valid_preds).flatten()\n",
    "    \n",
    "#     valid_df['raw_pred'] = valid_preds\n",
    "#     LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n",
    "#     grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n",
    "#     grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n",
    "#     valid_labels_mean = grp_df['cancer'].values\n",
    "#     valid_preds_mean = grp_df['raw_pred'].values\n",
    "#     # print(valid_labels[:5], valid_preds_mean[:5])\n",
    "#     val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n",
    "#     LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n",
    "#     best_metric_mean_at_epoch = 0\n",
    "#     best_metric = 0\n",
    "    \n",
    "#     best_threshold_mean = 0\n",
    "#     best_auc = 0\n",
    "#     best_cf = None\n",
    "#     for i in np.arange(0.001, 0.599, 0.001):\n",
    "#         valid_argmax = (valid_preds_mean>i).astype(np.int32)\n",
    "#         val_metric = pfbeta_np(valid_labels_mean, valid_argmax)\n",
    "#         val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n",
    "#         val_f1 = f1_score(valid_labels_mean, valid_argmax)\n",
    "#         val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n",
    "#         cf = confusion_matrix(valid_labels_mean, valid_argmax)\n",
    "#         if val_metric> best_metric:\n",
    "#             best_metric = val_metric\n",
    "#             # best_metric_mean_at_epoch = val_metric\n",
    "#             best_threshold_mean = i\n",
    "#             best_auc = val_auc\n",
    "#             best_cf = cf\n",
    "#     state = {'state_dict': model.state_dict()}\n",
    "#     path = f'swa_{CFG.model_name}_fold_{fold}_model_{best_metric:.4f}_{best_threshold_mean:.4f}.pth'\n",
    "#     torch.save(state, path)\n",
    "    \n",
    "#     LOGGER.info(f\"Best metric at: {best_metric:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n",
    "#     LOGGER.info(f\"Cf: {best_cf}\")\n",
    "#     return best_metric\n",
    "\n",
    "# study = optuna.create_study(direction='maximize', sampler = TPESampler(seed=1))\n",
    "# study.optimize(func=objective, n_trials=30)\n",
    "# study.best_params\n",
    "# # # 0.5563409550491111 0.4436590449508889 fold 0\n",
    "# # # 0.12634002523631388 0.8351954705276587 0.03846450423602743 0.5393 \n",
    "# # # 0.583301614081906 0.3673525472043472 0.04934583871374687 fold 2 0.50\n",
    "# # # 0.1689507073116359 0.47142151346976024 0.3596277792186039 fold 2 0.5055 0.5055 0.3670  0.7261"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efde08d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:23:24.302442Z",
     "iopub.status.busy": "2023-02-15T14:23:24.302099Z",
     "iopub.status.idle": "2023-02-15T14:23:24.313066Z",
     "shell.execute_reply": "2023-02-15T14:23:24.312071Z"
    },
    "papermill": {
     "duration": 0.022489,
     "end_time": "2023-02-15T14:23:24.315127",
     "exception": false,
     "start_time": "2023-02-15T14:23:24.292638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set_seed(1)\n",
    "# out_file = 'swa_model_fold2_5.pth' \n",
    "# iteration = [\n",
    "#     '/kaggle/input/5folds/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth',\n",
    "#     '/kaggle/input/5folds/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth',\n",
    "#     '/kaggle/input/5folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth',\n",
    "# ]\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss().to(CFG.device)\n",
    "# best_metric = 0\n",
    "# torch.cuda.empty_cache()\n",
    "# def objective(trial):\n",
    "#     a1 = 0.4360187712961733\n",
    "#     a2 = 0.31005592868022136\n",
    "#     a3 = 0.25392530002360536\n",
    "# #     a1 = 0.015006661988523864 \n",
    "# #     a2 = 0.12003546043452194 \n",
    "# #     a3 = 0.8649578775769542\n",
    "# #     a1 = 0.020317850755860567 \n",
    "# #     a2 = 0.1293785181217534 \n",
    "# #     a3 = 0.850303631122386\n",
    "# #     a1 = 0.12634002523631388\n",
    "# #     a2 = 0.8351954705276587\n",
    "# #     a3 = 0.03846450423602743\n",
    "# #     a1 = trial.suggest_uniform('a1', 0.001, 0.99)\n",
    "# #     a2 = trial.suggest_uniform('a2', 0.002, 1-a1)\n",
    "# #     a3 = trial.suggest_uniform('a3', 0.003, 1-a1-a2)\n",
    "#     a3 = 1-a1-a2\n",
    "#     state_dict = None\n",
    "#     for i in iteration:\n",
    "#         f = i\n",
    "#         print(f)\n",
    "#         f = torch.load(f, map_location=lambda storage, loc: storage)\n",
    "#         if state_dict is None:\n",
    "#             print(\"none: \", i)\n",
    "#             state_dict = f['state_dict']\n",
    "#             key = list(f['state_dict'].keys())\n",
    "#             for k in key:\n",
    "#                 state_dict[k] = f['state_dict'][k]*a1\n",
    "#         elif i=='/kaggle/input/5folds/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth': \n",
    "#             print(\"hehe\", i)\n",
    "#             key = list(f['state_dict'].keys())\n",
    "#             for k in key:\n",
    "#                 state_dict[k] = state_dict[k] + a2*f['state_dict'][k]\n",
    "#         elif i=='/kaggle/input/5folds/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4469_0.454.pth':\n",
    "#             print(\"noob\", i)\n",
    "#             key = list(f['state_dict'].keys())\n",
    "#             for k in key:\n",
    "#                 state_dict[k] = state_dict[k] + a3*f['state_dict'][k]\n",
    "# #         elif i=='/kaggle/input/5folds/tf_efficientnetv2_b2_fold_2_model_epoch_9_0.4681_0.319.pth':\n",
    "# #             print(\"noobie\", i)\n",
    "# #             key = list(f['state_dict'].keys())\n",
    "# #             for k in key:\n",
    "# #                 state_dict[k] = state_dict[k] + a4*f['state_dict'][k]\n",
    "#     print(a1, a2, a3)\n",
    "#     # for k in key:\n",
    "#     #     state_dict[k] = state_dict[k] / len(iteration)\n",
    "#     print('')\n",
    "\n",
    "#     # print(out_file)\n",
    "#     torch.save({'state_dict': state_dict}, out_file)\n",
    "\n",
    "#     model = ModelOld(model_name=CFG.model_name).to(CFG.device)\n",
    "#     checkpoint = torch.load(\"swa_model_fold2_5.pth\")\n",
    "#     model.load_state_dict(checkpoint['state_dict'])\n",
    "# #     model = nn.DataParallel(model)\n",
    "\n",
    "#     loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n",
    "#     valid_preds = valid_preds[:, 1]\n",
    "#     valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n",
    "#     valid_preds = np.array(valid_preds).flatten()\n",
    "    \n",
    "#     valid_df['raw_pred'] = valid_preds\n",
    "#     LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n",
    "#     grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n",
    "#     grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n",
    "#     valid_labels_mean = grp_df['cancer'].values\n",
    "#     valid_preds_mean = grp_df['raw_pred'].values\n",
    "#     # print(valid_labels[:5], valid_preds_mean[:5])\n",
    "#     val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n",
    "#     LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n",
    "#     best_metric_mean_at_epoch = 0\n",
    "#     best_metric = 0\n",
    "    \n",
    "#     best_threshold_mean = 0\n",
    "#     best_auc = 0\n",
    "#     best_cf = None\n",
    "#     for i in np.arange(0.001, 0.599, 0.001):\n",
    "#         valid_argmax = (valid_preds_mean>i).astype(np.int32)\n",
    "#         val_metric = pfbeta_np(valid_labels_mean, valid_argmax)\n",
    "#         val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n",
    "#         val_f1 = f1_score(valid_labels_mean, valid_argmax)\n",
    "#         val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n",
    "#         cf = confusion_matrix(valid_labels_mean, valid_argmax)\n",
    "#         if val_metric> best_metric:\n",
    "#             best_metric = val_metric\n",
    "#             # best_metric_mean_at_epoch = val_metric\n",
    "#             best_threshold_mean = i\n",
    "#             best_auc = val_auc\n",
    "#             best_cf = cf\n",
    "#     state = {'state_dict': model.state_dict()}\n",
    "#     path = f'swa_{CFG.model_name}_fold_{fold}_model_{best_metric:.4f}_{best_threshold_mean:.3f}.pth'\n",
    "#     torch.save(state, path)\n",
    "    \n",
    "#     LOGGER.info(f\"Best metric at: {best_metric:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n",
    "#     LOGGER.info(f\"Cf: {best_cf}\")\n",
    "#     return best_metric\n",
    "\n",
    "# study = optuna.create_study(direction='maximize', sampler = TPESampler(seed=666))\n",
    "# study.optimize(func=objective, n_trials=40)\n",
    "# study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcb08435",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:23:24.330885Z",
     "iopub.status.busy": "2023-02-15T14:23:24.330528Z",
     "iopub.status.idle": "2023-02-15T15:10:22.438829Z",
     "shell.execute_reply": "2023-02-15T15:10:22.437105Z"
    },
    "papermill": {
     "duration": 2818.11983,
     "end_time": "2023-02-15T15:10:22.440824",
     "exception": true,
     "start_time": "2023-02-15T14:23:24.320994",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-15 14:23:24,368]\u001b[0m A new study created in memory with name: no-name-631ab7c5-366e-4344-8f30-c18a8c25d50a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SEEDING DONE\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n",
      "none:  /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n",
      "hehe /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n",
      "noob /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n",
      "noob /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n",
      "noob /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_11_0.4211_0.242.pth\n",
      "hehe /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_11_0.4211_0.242.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4231_0.320.pth\n",
      "hehe /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4231_0.320.pth\n",
      "0.41343476265084567 0.4227690154202109 0.0008186426631110296 0.04976179801990641 0.017127029296811005 0.009326531030684463 0.08676222091843054\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 170/170 [09:36<00:00,  3.39s/it, eval_loss=0.0884, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0884\n",
      "Val metric mean prob: 0.2930\n",
      "Best metric at: 0.4731 0.3250  0.7114\n",
      "Cf: [[4622   40]\n",
      " [  58   44]]\n",
      "\u001b[32m[I 2023-02-15 14:33:16,897]\u001b[0m Trial 0 finished with value: 0.4731182795698925 and parameters: {'a1': 0.41343476265084567, 'a2': 0.4227690154202109, 'a3': 0.0008186426631110296, 'a4': 0.04976179801990641, 'a5': 0.017127029296811005, 'a6': 0.009326531030684463}. Best is trial 0 with value: 0.4731182795698925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n",
      "none:  /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n",
      "hehe /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n",
      "noob /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n",
      "noob /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n",
      "noob /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_11_0.4211_0.242.pth\n",
      "hehe /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_11_0.4211_0.242.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4231_0.320.pth\n",
      "hehe /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4231_0.320.pth\n",
      "0.18521134905251652 0.28214795395349773 0.21181709003938282 0.17318795637665355 0.06223653814399608 0.05867452740612188 0.026724585027831545\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 170/170 [07:10<00:00,  2.53s/it, eval_loss=0.0839, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0839\n",
      "Val metric mean prob: 0.2811\n",
      "Best metric at: 0.4742 0.3050  0.7206\n",
      "Cf: [[4616   46]\n",
      " [  56   46]]\n",
      "\u001b[32m[I 2023-02-15 14:40:39,188]\u001b[0m Trial 1 finished with value: 0.4742268041237114 and parameters: {'a1': 0.18521134905251652, 'a2': 0.28214795395349773, 'a3': 0.21181709003938282, 'a4': 0.17318795637665355, 'a5': 0.06223653814399608, 'a6': 0.05867452740612188}. Best is trial 1 with value: 0.4742268041237114.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n",
      "none:  /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n",
      "hehe /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n",
      "noob /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n",
      "noob /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n",
      "noob /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_11_0.4211_0.242.pth\n",
      "hehe /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_11_0.4211_0.242.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4231_0.320.pth\n",
      "hehe /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4231_0.320.pth\n",
      "0.20320327498447074 0.6997907918025857 0.0034348489620629496 0.0629670446252565 0.013120829826186486 0.009988346569305974 0.007494863230131576\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 170/170 [08:04<00:00,  2.85s/it, eval_loss=0.0829, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0829\n",
      "Val metric mean prob: 0.2514\n",
      "Best metric at: 0.4677 0.2480  0.7248\n",
      "Cf: [[4610   52]\n",
      " [  55   47]]\n",
      "\u001b[32m[I 2023-02-15 14:48:48,218]\u001b[0m Trial 2 finished with value: 0.46766169154228854 and parameters: {'a1': 0.20320327498447074, 'a2': 0.6997907918025857, 'a3': 0.0034348489620629496, 'a4': 0.0629670446252565, 'a5': 0.013120829826186486, 'a6': 0.009988346569305974}. Best is trial 1 with value: 0.4742268041237114.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n",
      "none:  /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n",
      "hehe /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n",
      "noob /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n",
      "noob /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n",
      "noob /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_11_0.4211_0.242.pth\n",
      "hehe /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_11_0.4211_0.242.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4231_0.320.pth\n",
      "hehe /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4231_0.320.pth\n",
      "0.1398426822706862 0.17112015414925588 0.5519021706973883 0.13280476119183846 0.0017691448020423191 0.001926937065968019 0.000634149822820822\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 170/170 [08:10<00:00,  2.88s/it, eval_loss=0.0818, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0818\n",
      "Val metric mean prob: 0.2522\n",
      "Best metric at: 0.4947 0.2950  0.7260\n",
      "Cf: [[4621   41]\n",
      " [  55   47]]\n",
      "\u001b[32m[I 2023-02-15 14:57:02,925]\u001b[0m Trial 3 finished with value: 0.4947368421052631 and parameters: {'a1': 0.1398426822706862, 'a2': 0.17112015414925588, 'a3': 0.5519021706973883, 'a4': 0.13280476119183846, 'a5': 0.0017691448020423191, 'a6': 0.001926937065968019}. Best is trial 3 with value: 0.4947368421052631.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n",
      "none:  /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n",
      "hehe /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n",
      "noob /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n",
      "noob /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n",
      "noob /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_11_0.4211_0.242.pth\n",
      "hehe /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_11_0.4211_0.242.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4231_0.320.pth\n",
      "hehe /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4231_0.320.pth\n",
      "0.8677488716207818 0.11840759470679785 0.001909277034646128 0.0011387514577708402 0.0023315069223927023 0.007493525367245686 0.0009704728903649484\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 170/170 [06:34<00:00,  2.32s/it, eval_loss=0.1031, gpu_mem=6.88 GB]\n",
      "Valid loss:0.1031\n",
      "Val metric mean prob: 0.3108\n",
      "Best metric at: 0.4516 0.2940  0.7014\n",
      "Cf: [[4620   42]\n",
      " [  60   42]]\n",
      "\u001b[32m[I 2023-02-15 15:03:45,735]\u001b[0m Trial 4 finished with value: 0.45161290322580644 and parameters: {'a1': 0.8677488716207818, 'a2': 0.11840759470679785, 'a3': 0.001909277034646128, 'a4': 0.0011387514577708402, 'a5': 0.0023315069223927023, 'a6': 0.007493525367245686}. Best is trial 3 with value: 0.4947368421052631.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n",
      "none:  /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n",
      "hehe /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n",
      "noob /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n",
      "noob /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n",
      "noob /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_11_0.4211_0.242.pth\n",
      "hehe /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_11_0.4211_0.242.pth\n",
      "/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4231_0.320.pth\n",
      "hehe /kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4231_0.320.pth\n",
      "0.09826501866088655 0.3802484795131846 0.4995601485897475 0.012017154672106588 0.007040821435703983 0.0012472600041182548 0.0016211171242525913\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val: 100%|██████████| 170/170 [06:31<00:00,  2.30s/it, eval_loss=0.0806, gpu_mem=6.88 GB]\n",
      "Valid loss:0.0806\n",
      "Val metric mean prob: 0.2371\n",
      "Best metric at: 0.4828 0.2510  0.7346\n",
      "Cf: [[4610   52]\n",
      " [  53   49]]\n",
      "\u001b[32m[I 2023-02-15 15:10:21,952]\u001b[0m Trial 5 finished with value: 0.48275862068965514 and parameters: {'a1': 0.09826501866088655, 'a2': 0.3802484795131846, 'a3': 0.4995601485897475, 'a4': 0.012017154672106588, 'a5': 0.007040821435703983, 'a6': 0.0012472600041182548}. Best is trial 3 with value: 0.4947368421052631.\u001b[0m\n",
      "\u001b[33m[W 2023-02-15 15:10:21,956]\u001b[0m Trial 6 failed with parameters: {'a1': 0.6799494174770863, 'a2': 0.26727126937462486, 'a3': 0.0017506120950165028, 'a4': 0.038453788973677065, 'a5': 0.012441524598588155} because of the following error: ValueError('The `low` value must be smaller than or equal to the `high` value (low=0.0005, high=0.00013338748100715468).').\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_25/1911114919.py\", line 30, in objective\n",
      "    a6 = trial.suggest_uniform('a6', 0.0005, 1-a1-a2-a3-a4-a5)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/optuna/_deprecated.py\", line 113, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/optuna/trial/_trial.py\", line 181, in suggest_uniform\n",
      "    return self.suggest_float(name, low, high)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/optuna/trial/_trial.py\", line 156, in suggest_float\n",
      "    distribution = FloatDistribution(low, high, log=log, step=step)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/optuna/distributions.py\", line 149, in __init__\n",
      "    \"(low={}, high={}).\".format(low, high)\n",
      "ValueError: The `low` value must be smaller than or equal to the `high` value (low=0.0005, high=0.00013338748100715468).\n",
      "\u001b[33m[W 2023-02-15 15:10:21,962]\u001b[0m Trial 6 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The `low` value must be smaller than or equal to the `high` value (low=0.0005, high=0.00013338748100715468).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25/1911114919.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;31m# # 0.5563409550491111 0.4436590449508889 fold 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m         )\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_25/1911114919.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0ma4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0007\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0ma5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0006\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma3\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0ma6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a6'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma3\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma4\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0ma7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma3\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma4\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma5\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/_deprecated.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/trial/_trial.py\u001b[0m in \u001b[0;36msuggest_uniform\u001b[0;34m(self, name, low, high)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \"\"\"\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecated_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3.0.0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"6.0.0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_suggest_deprecated_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/trial/_trial.py\u001b[0m in \u001b[0;36msuggest_float\u001b[0;34m(self, name, low, high, step, log)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \"\"\"\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFloatDistribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0msuggested_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_suggest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/distributions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, low, high, log, step)\u001b[0m\n\u001b[1;32m    147\u001b[0m             raise ValueError(\n\u001b[1;32m    148\u001b[0m                 \u001b[0;34m\"The `low` value must be smaller than or equal to the `high` value \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0;34m\"(low={}, high={}).\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             )\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The `low` value must be smaller than or equal to the `high` value (low=0.0005, high=0.00013338748100715468)."
     ]
    }
   ],
   "source": [
    "\n",
    "set_seed(1)\n",
    "out_file = 'swa_model_fold1_5.pth' \n",
    "iteration = [\n",
    "    '/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth',\n",
    "    \n",
    "    '/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth',\n",
    "    '/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth',\n",
    "    '/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth',\n",
    "    '/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth',\n",
    "    '/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_11_0.4211_0.242.pth',\n",
    "    '/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4231_0.320.pth'\n",
    "]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(CFG.device)\n",
    "best_metric = 0\n",
    "torch.cuda.empty_cache()\n",
    "def objective(trial):\n",
    "#     a1 = 0.036839841333967636 \n",
    "#     a2 = 0.6490629183820655\n",
    "#     a3 = 0.3140972402839668\n",
    "#     a2 = 0.47142151346976024 \n",
    "#     a3 = 0.3596277792186039\n",
    "#     a1 = trial.suggest_uniform('a1', 0.01, 0.99)\n",
    "#     a2 = 1-a1\n",
    "    a1 = trial.suggest_uniform('a1', 0.001, 0.99)\n",
    "    a2 = trial.suggest_uniform('a2', 0.0009, 1-a1)\n",
    "    a3 = trial.suggest_uniform('a3', 0.0008, 1-a1-a2)\n",
    "    a4 = trial.suggest_uniform('a4', 0.0007, 1-a1-a2-a3)\n",
    "    a5 = trial.suggest_uniform('a5', 0.0006, 1-a1-a2-a3-a4)\n",
    "    a6 = trial.suggest_uniform('a6', 0.0005, 1-a1-a2-a3-a4-a5)\n",
    "    a7 = 1-a1-a2-a3-a4-a5-a6\n",
    "    state_dict = None\n",
    "    for i in iteration:\n",
    "        f = i\n",
    "        print(f)\n",
    "        f = torch.load(f, map_location=lambda storage, loc: storage)\n",
    "        if state_dict is None:\n",
    "            print(\"none: \", i)\n",
    "            state_dict = f['state_dict']\n",
    "            key = list(f['state_dict'].keys())\n",
    "            for k in key:\n",
    "                state_dict[k] = f['state_dict'][k]*a1\n",
    "        elif i=='/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth': \n",
    "            print(\"hehe\", i)\n",
    "            key = list(f['state_dict'].keys())\n",
    "            for k in key:\n",
    "                state_dict[k] = state_dict[k] + a2*f['state_dict'][k]\n",
    "        elif i=='/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth':\n",
    "            print(\"noob\", i)\n",
    "            key = list(f['state_dict'].keys())\n",
    "            for k in key:\n",
    "                state_dict[k] = state_dict[k] + a3*f['state_dict'][k]\n",
    "        elif i=='/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth':\n",
    "            print(\"noob\", i)\n",
    "            key = list(f['state_dict'].keys())\n",
    "            for k in key:\n",
    "                state_dict[k] = state_dict[k] + a4*f['state_dict'][k]\n",
    "                \n",
    "        elif i=='/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth':\n",
    "            print(\"noob\", i)\n",
    "            key = list(f['state_dict'].keys())\n",
    "            for k in key:\n",
    "                state_dict[k] = state_dict[k] + a5*f['state_dict'][k]\n",
    "                \n",
    "        elif i=='/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_11_0.4211_0.242.pth': \n",
    "            print(\"hehe\", i)\n",
    "            key = list(f['state_dict'].keys())\n",
    "            for k in key:\n",
    "                state_dict[k] = state_dict[k] + a6*f['state_dict'][k]\n",
    "                \n",
    "        elif i=='/kaggle/input/5folds/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4231_0.320.pth': \n",
    "            print(\"hehe\", i)\n",
    "            key = list(f['state_dict'].keys())\n",
    "            for k in key:\n",
    "                state_dict[k] = state_dict[k] + a7*f['state_dict'][k]\n",
    "    print(a1, a2, a3, a4, a5, a6, a7)\n",
    "    # for k in key:\n",
    "    #     state_dict[k] = state_dict[k] / len(iteration)\n",
    "    print('')\n",
    "\n",
    "    # print(out_file)\n",
    "    torch.save({'state_dict': state_dict}, out_file)\n",
    "\n",
    "    model = ModelOld(model_name=CFG.model_name).to(CFG.device)\n",
    "    checkpoint = torch.load(\"swa_model_fold1_5.pth\")\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "#     model = nn.DataParallel(model)\n",
    "\n",
    "    loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n",
    "    valid_preds = valid_preds[:, 1]\n",
    "    valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n",
    "    valid_preds = np.array(valid_preds).flatten()\n",
    "    \n",
    "    valid_df['raw_pred'] = valid_preds\n",
    "    LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n",
    "    grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n",
    "    grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n",
    "    valid_labels_mean = grp_df['cancer'].values\n",
    "    valid_preds_mean = grp_df['raw_pred'].values\n",
    "    # print(valid_labels[:5], valid_preds_mean[:5])\n",
    "    val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n",
    "    LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n",
    "    best_metric_mean_at_epoch = 0\n",
    "    best_metric = 0\n",
    "    \n",
    "    best_threshold_mean = 0\n",
    "    best_auc = 0\n",
    "    best_cf = None\n",
    "    for i in np.arange(0.001, 0.599, 0.001):\n",
    "        valid_argmax = (valid_preds_mean>i).astype(np.int32)\n",
    "        val_metric = pfbeta_np(valid_labels_mean, valid_argmax)\n",
    "        val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n",
    "        val_f1 = f1_score(valid_labels_mean, valid_argmax)\n",
    "        val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n",
    "        cf = confusion_matrix(valid_labels_mean, valid_argmax)\n",
    "        if val_metric> best_metric:\n",
    "            best_metric = val_metric\n",
    "            # best_metric_mean_at_epoch = val_metric\n",
    "            best_threshold_mean = i\n",
    "            best_auc = val_auc\n",
    "            best_cf = cf\n",
    "    state = {'state_dict': model.state_dict()}\n",
    "    path = f'swa_{CFG.model_name}_fold_{fold}_model_{best_metric:.4f}_{best_threshold_mean:.4f}.pth'\n",
    "    torch.save(state, path)\n",
    "    \n",
    "    LOGGER.info(f\"Best metric at: {best_metric:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n",
    "    LOGGER.info(f\"Cf: {best_cf}\")\n",
    "    return best_metric\n",
    "\n",
    "study = optuna.create_study(direction='maximize', sampler = TPESampler(seed=1))\n",
    "study.optimize(func=objective, n_trials=30)\n",
    "study.best_params\n",
    "# # 0.5563409550491111 0.4436590449508889 fold 0\n",
    "# # 0.12634002523631388 0.8351954705276587 0.03846450423602743 0.5393 \n",
    "# # 0.583301614081906 0.3673525472043472 0.04934583871374687 fold 2 0.50\n",
    "# # 0.1689507073116359 0.47142151346976024 0.3596277792186039 fold 2 0.5055 0.5055 0.3670  0.7261"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d0d034",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-02-15T12:39:15.805047Z",
     "iopub.status.idle": "2023-02-15T12:39:15.805828Z",
     "shell.execute_reply": "2023-02-15T12:39:15.805613Z",
     "shell.execute_reply.started": "2023-02-15T12:39:15.805591Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set_seed(1)\n",
    "# out_file = 'swa_model_fold6_10.pth' \n",
    "# iteration = [\n",
    "#     '/kaggle/input/10folds/tf_efficientnetv2_b2_fold_6_model_epoch_6_0.5128_0.307.pth',\n",
    "#     '/kaggle/input/10folds/tf_efficientnetv2_b2_fold_6_model_epoch_7_0.5385_0.423.pth',\n",
    "#     '/kaggle/input/10folds/tf_efficientnetv2_b2_fold_6_model_epoch_9_0.5135_0.338.pth'\n",
    "# ]\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss().to(CFG.device)\n",
    "# best_metric = 0\n",
    "# torch.cuda.empty_cache()\n",
    "# def objective(trial):\n",
    "# #     a1 = 0.015006661988523864 \n",
    "# #     a2 = 0.12003546043452194 \n",
    "# #     a3 = 0.8649578775769542\n",
    "# #     a1 = 0.020317850755860567 \n",
    "# #     a2 = 0.1293785181217534 \n",
    "# #     a3 = 0.850303631122386\n",
    "# #     a1 = 0.12634002523631388\n",
    "# #     a2 = 0.8351954705276587\n",
    "# #     a3 = 0.03846450423602743\n",
    "#     a1 = trial.suggest_uniform('a1', 0.01, 0.99)\n",
    "#     a2 = trial.suggest_uniform('a2', 0.01, 1-a1)\n",
    "#     a3 = 1-a1-a2\n",
    "#     state_dict = None\n",
    "#     for i in iteration:\n",
    "#         f = i\n",
    "#         print(f)\n",
    "#         f = torch.load(f, map_location=lambda storage, loc: storage)\n",
    "#         if state_dict is None:\n",
    "#             print(\"none: \", i)\n",
    "#             state_dict = f['state_dict']\n",
    "#             key = list(f['state_dict'].keys())\n",
    "#             for k in key:\n",
    "#                 state_dict[k] = f['state_dict'][k]*a1\n",
    "#         elif i=='/kaggle/input/10folds/tf_efficientnetv2_b2_fold_6_model_epoch_7_0.5385_0.423.pth': \n",
    "#             print(\"hehe\", i)\n",
    "#             key = list(f['state_dict'].keys())\n",
    "#             for k in key:\n",
    "#                 state_dict[k] = state_dict[k] + a2*f['state_dict'][k]\n",
    "#         elif i=='/kaggle/input/10folds/tf_efficientnetv2_b2_fold_6_model_epoch_9_0.5135_0.338.pth':\n",
    "#             print(\"noob\", i)\n",
    "#             key = list(f['state_dict'].keys())\n",
    "#             for k in key:\n",
    "#                 state_dict[k] = state_dict[k] + a3*f['state_dict'][k]\n",
    "#     print(a1, a2, a3)\n",
    "#     # for k in key:\n",
    "#     #     state_dict[k] = state_dict[k] / len(iteration)\n",
    "#     print('')\n",
    "\n",
    "#     # print(out_file)\n",
    "#     torch.save({'state_dict': state_dict}, out_file)\n",
    "\n",
    "#     model = ModelOld(model_name=CFG.model_name).to(CFG.device)\n",
    "#     checkpoint = torch.load(\"swa_model_fold6_10.pth\")\n",
    "#     model.load_state_dict(checkpoint['state_dict'])\n",
    "# #     model = nn.DataParallel(model)\n",
    "\n",
    "#     loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n",
    "#     valid_preds = valid_preds[:, 1]\n",
    "#     valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n",
    "#     valid_preds = np.array(valid_preds).flatten()\n",
    "    \n",
    "#     valid_df['raw_pred'] = valid_preds\n",
    "#     LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n",
    "#     grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n",
    "#     grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n",
    "#     valid_labels_mean = grp_df['cancer'].values\n",
    "#     valid_preds_mean = grp_df['raw_pred'].values\n",
    "#     # print(valid_labels[:5], valid_preds_mean[:5])\n",
    "#     val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n",
    "#     LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n",
    "#     best_metric_mean_at_epoch = 0\n",
    "#     best_metric = 0\n",
    "    \n",
    "#     best_threshold_mean = 0\n",
    "#     best_auc = 0\n",
    "#     best_cf = None\n",
    "#     for i in np.arange(0.001, 0.599, 0.001):\n",
    "#         valid_argmax = (valid_preds_mean>i).astype(np.int32)\n",
    "#         val_metric = pfbeta_np(valid_labels_mean, valid_argmax)\n",
    "#         val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n",
    "#         val_f1 = f1_score(valid_labels_mean, valid_argmax)\n",
    "#         val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n",
    "#         cf = confusion_matrix(valid_labels_mean, valid_argmax)\n",
    "#         if val_metric> best_metric:\n",
    "#             best_metric = val_metric\n",
    "#             # best_metric_mean_at_epoch = val_metric\n",
    "#             best_threshold_mean = i\n",
    "#             best_auc = val_auc\n",
    "#             best_cf = cf\n",
    "#     state = {'state_dict': model.state_dict()}\n",
    "#     path = f'swa_{CFG.model_name}_fold_{fold}_model_{best_metric:.4f}_{best_threshold_mean:.3f}.pth'\n",
    "#     torch.save(state, path)\n",
    "    \n",
    "#     LOGGER.info(f\"Best metric at: {best_metric:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n",
    "#     LOGGER.info(f\"Cf: {best_cf}\")\n",
    "#     return best_metric\n",
    "\n",
    "# study = optuna.create_study(direction='maximize', sampler = TPESampler(seed=666))\n",
    "# study.optimize(func=objective, n_trials=40)\n",
    "# study.best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2842.807543,
   "end_time": "2023-02-15T15:10:26.362467",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-15T14:23:03.554924",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
