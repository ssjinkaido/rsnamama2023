{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:20.757433Z","iopub.status.busy":"2022-12-30T08:23:20.756596Z","iopub.status.idle":"2022-12-30T08:23:20.769292Z","shell.execute_reply":"2022-12-30T08:23:20.768338Z","shell.execute_reply.started":"2022-12-30T08:23:20.757395Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import random\n","from glob import glob\n","import os, shutil\n","from tqdm import tqdm\n","tqdm.pandas()\n","import time\n","import copy\n","import joblib\n","from collections import defaultdict\n","import gc\n","from IPython import display as ipd\n","import math\n","# visualization\n","import cv2\n","from glob import glob\n","# Sklearn\n","from sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\n","from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix, roc_curve\n","import timm\n","# PyTorch \n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","from torch.cuda.amp import autocast, GradScaler\n","import torch.nn.functional as F\n","from torch.optim.swa_utils import AveragedModel, SWALR\n","from transformers import get_cosine_schedule_with_warmup\n","from collections import defaultdict\n","# import matplotlib.pyplot as plt\n","# Albumentations for augmentations\n","import albumentations as A\n","import albumentations\n","import albumentations as albu\n","from albumentations.pytorch import ToTensorV2\n","from datetime import datetime\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:20.771750Z","iopub.status.busy":"2022-12-30T08:23:20.771281Z","iopub.status.idle":"2022-12-30T08:23:20.782962Z","shell.execute_reply":"2022-12-30T08:23:20.782013Z","shell.execute_reply.started":"2022-12-30T08:23:20.771715Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["class CFG:\n","    seed = 1\n","    model_name = \"tf_efficientnetv2_b2\"\n","    train_bs = 12\n","    valid_bs = 48\n","    image_size = 1024\n","    epochs = 25\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","print(CFG.device)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:20.784720Z","iopub.status.busy":"2022-12-30T08:23:20.784325Z","iopub.status.idle":"2022-12-30T08:23:20.912644Z","shell.execute_reply":"2022-12-30T08:23:20.911668Z","shell.execute_reply.started":"2022-12-30T08:23:20.784684Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>site_id</th>\n","      <th>patient_id</th>\n","      <th>image_id</th>\n","      <th>laterality</th>\n","      <th>view</th>\n","      <th>age</th>\n","      <th>cancer</th>\n","      <th>biopsy</th>\n","      <th>invasive</th>\n","      <th>BIRADS</th>\n","      <th>implant</th>\n","      <th>density</th>\n","      <th>machine_id</th>\n","      <th>difficult_negative_case</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>10006</td>\n","      <td>462822612</td>\n","      <td>L</td>\n","      <td>CC</td>\n","      <td>61.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>29</td>\n","      <td>False</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>10006</td>\n","      <td>1459541791</td>\n","      <td>L</td>\n","      <td>MLO</td>\n","      <td>61.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>29</td>\n","      <td>False</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>10006</td>\n","      <td>1864590858</td>\n","      <td>R</td>\n","      <td>MLO</td>\n","      <td>61.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>29</td>\n","      <td>False</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>10006</td>\n","      <td>1874946579</td>\n","      <td>R</td>\n","      <td>CC</td>\n","      <td>61.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>29</td>\n","      <td>False</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>10011</td>\n","      <td>220375232</td>\n","      <td>L</td>\n","      <td>CC</td>\n","      <td>55.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>21</td>\n","      <td>True</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   site_id  patient_id    image_id laterality view   age  cancer  biopsy  \\\n","0        2       10006   462822612          L   CC  61.0       0       0   \n","1        2       10006  1459541791          L  MLO  61.0       0       0   \n","2        2       10006  1864590858          R  MLO  61.0       0       0   \n","3        2       10006  1874946579          R   CC  61.0       0       0   \n","4        2       10011   220375232          L   CC  55.0       0       0   \n","\n","   invasive  BIRADS  implant density  machine_id  difficult_negative_case  \\\n","0         0     NaN        0     NaN          29                    False   \n","1         0     NaN        0     NaN          29                    False   \n","2         0     NaN        0     NaN          29                    False   \n","3         0     NaN        0     NaN          29                    False   \n","4         0     0.0        0     NaN          21                     True   \n","\n","   fold  \n","0     1  \n","1     1  \n","2     1  \n","3     1  \n","4     0  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\"train_5folds.csv\")\n","df.head()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["55864\n"]}],"source":["is_hol = df['cancer'] == 1\n","df_try = df[is_hol]\n","df1 = df.append([df_try]*1,ignore_index=True)\n","print(len(df1))"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Date :02/24/2023, 11:39:14\n"]}],"source":["def init_logger(log_file='train3.log'):\n","    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=log_file)\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = init_logger()\n","now = datetime.now()\n","datetime_now = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n","LOGGER.info(f\"Date :{datetime_now}\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["train transformCompose([\n","  VerticalFlip(always_apply=False, p=0.5),\n","  ColorJitter(always_apply=False, p=0.5, brightness=[0.8, 1.2], contrast=[0.8, 1.2], saturation=[0.8, 1.2], hue=[-0.2, 0.2]),\n","  ShiftScaleRotate(always_apply=False, p=0.5, shift_limit_x=(-0.0625, 0.0625), shift_limit_y=(-0.0625, 0.0625), scale_limit=(-0.050000000000000044, 0.050000000000000044), rotate_limit=(-10, 10), interpolation=1, border_mode=4, value=None, mask_value=None, rotate_method='largest_box'),\n","  HorizontalFlip(always_apply=False, p=0.5),\n","  Cutout(always_apply=False, p=0.5, num_holes=5, max_h_size=102, max_w_size=102),\n","  ToTensorV2(always_apply=True, p=1.0, transpose_mask=False),\n","], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={})\n"]}],"source":["from albumentations import DualTransform\n","image_size = 1024\n","def isotropically_resize_image(img, size, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC):\n","    h, w = img.shape[:2]\n","    if max(w, h) == size:\n","        return img\n","    if w > h:\n","        scale = size / w\n","        h = h * scale\n","        w = size\n","    else:\n","        scale = size / h\n","        w = w * scale\n","        h = size\n","    interpolation = interpolation_up if scale > 1 else interpolation_down\n","    resized = cv2.resize(img, (int(w), int(h)), interpolation=interpolation)\n","    return resized\n","\n","\n","class IsotropicResize(DualTransform):\n","    def __init__(self, max_side, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC,\n","                 always_apply=False, p=1):\n","        super(IsotropicResize, self).__init__(always_apply, p)\n","        self.max_side = max_side\n","        self.interpolation_down = interpolation_down\n","        self.interpolation_up = interpolation_up\n","\n","    def apply(self, img, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC, **params):\n","        return isotropically_resize_image(img, size=self.max_side, interpolation_down=interpolation_down,\n","                                          interpolation_up=interpolation_up)\n","\n","    def apply_to_mask(self, img, **params):\n","        return self.apply(img, interpolation_down=cv2.INTER_NEAREST, interpolation_up=cv2.INTER_NEAREST, **params)\n","\n","    def get_transform_init_args_names(self):\n","        return (\"max_side\", \"interpolation_down\", \"interpolation_up\")\n","    \n","data_transforms = {\n","    \"train\": A.Compose([\n","        # A.Resize(image_size, image_size),\n","        # IsotropicResize(max_side = image_size),\n","        # A.PadIfNeeded(min_height=image_size, min_width=image_size, border_mode=cv2.BORDER_CONSTANT),\n","        # A.RandomBrightnessContrast(),\n","        # A.VerticalFlip(p=0.5),   \n","        # A.ColorJitter(),\n","        # A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n","        # A.HorizontalFlip(p=0.5),\n","        # A.Cutout(max_h_size=int(image_size * 0.1), max_w_size=int(image_size * 0.1), num_holes=5, p=0.5),\n","        A.VerticalFlip(p=0.5),   \n","        A.ColorJitter(),\n","        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n","        A.HorizontalFlip(p=0.5),\n","        A.Cutout(max_h_size=int(image_size * 0.1), max_w_size=int(image_size * 0.1), num_holes=5, p=0.5),\n","        # A.OneOf([ \n","        # A.OpticalDistortion(distort_limit=1.0), \n","        # A.GridDistortion(num_steps=5, distort_limit=1.),\n","        # A.ElasticTransform(alpha=3), ], p=0.2),\n","        # A.OneOf([\n","            # A.GaussNoise(var_limit=[10, 50]),\n","            # A.GaussianBlur(),\n","            # A.MotionBlur(),\n","            # A.MedianBlur(), ], p=0.2),\n","        # A.OneOf([\n","        #     A.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n","        #     A.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=1.0),\n","        #     A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n","        # ], p=0.25),\n","        # A.CoarseDropout(max_holes=8, max_height=image_size//20, max_width=image_size//20,\n","        #                  min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n","        # A.Normalize(mean=0, std=1),\n","        ToTensorV2(),], p=1.0),\n","    \n","    \"valid\": A.Compose([\n","        # IsotropicResize(max_side =image_size),\n","        # A.PadIfNeeded(min_height=image_size, min_width=image_size, border_mode=cv2.BORDER_CONSTANT),\n","        # A.Normalize(mean=0, std=1),\n","        # A.Resize(image_size, image_size),\n","        ToTensorV2(),\n","        ], p=1.0)\n","}\n","\n","LOGGER.info(f\"train transform{data_transforms['train']}\")\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:20.915927Z","iopub.status.busy":"2022-12-30T08:23:20.915346Z","iopub.status.idle":"2022-12-30T08:23:20.931477Z","shell.execute_reply":"2022-12-30T08:23:20.930433Z","shell.execute_reply.started":"2022-12-30T08:23:20.915890Z"},"trusted":true},"outputs":[],"source":["# from albumentations import DualTransform\n","# image_size = 1024\n","# def isotropically_resize_image(img, size, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC):\n","#     h, w = img.shape[:2]\n","#     if max(w, h) == size:\n","#         return img\n","#     if w > h:\n","#         scale = size / w\n","#         h = h * scale\n","#         w = size\n","#     else:\n","#         scale = size / h\n","#         w = w * scale\n","#         h = size\n","#     interpolation = interpolation_up if scale > 1 else interpolation_down\n","#     resized = cv2.resize(img, (int(w), int(h)), interpolation=interpolation)\n","#     return resized\n","\n","\n","# class IsotropicResize(DualTransform):\n","#     def __init__(self, max_side, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC,\n","#                  always_apply=False, p=1):\n","#         super(IsotropicResize, self).__init__(always_apply, p)\n","#         self.max_side = max_side\n","#         self.interpolation_down = interpolation_down\n","#         self.interpolation_up = interpolation_up\n","\n","#     def apply(self, img, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC, **params):\n","#         return isotropically_resize_image(img, size=self.max_side, interpolation_down=interpolation_down,\n","#                                           interpolation_up=interpolation_up)\n","\n","#     def apply_to_mask(self, img, **params):\n","#         return self.apply(img, interpolation_down=cv2.INTER_NEAREST, interpolation_up=cv2.INTER_NEAREST, **params)\n","\n","#     def get_transform_init_args_names(self):\n","#         return (\"max_side\", \"interpolation_down\", \"interpolation_up\")\n","    \n","# data_transforms = {\n","#     \"train\": A.Compose([\n","# #         A.Resize(image_size, image_size),\n","#         # IsotropicResize(max_side = image_size),\n","#        A.PadIfNeeded(min_width=image_size, border_mode=cv2.BORDER_CONSTANT),\n","#         albumentations.HorizontalFlip(p=0.5),\n","#         albumentations.VerticalFlip(p=0.5),\n","#         # albumentations.RandomBrightness(limit=0.2, p=0.75),\n","#         # albumentations.RandomContrast(limit=0.2, p=0.75),\n","\n","#         # albumentations.OneOf([\n","#         #     albumentations.OpticalDistortion(distort_limit=1.),\n","#         #     albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n","#         # ], p=0.75),\n","\n","#         # albumentations.HueSaturationValue(hue_shift_limit=40, sat_shift_limit=40, val_shift_limit=0, p=0.75),\n","#         albumentations.ShiftScaleRotate(p = 0.5),\n","#         A.Cutout(always_apply=False, p=0.5, num_holes=5, max_h_size=image_size//10, max_w_size=image_size//10),\n","#         # A.RandomBrightnessContrast(),\n","#         # A.VerticalFlip(p=0.5),   \n","#         A.ColorJitter(p = 0.7),\n","#         # A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n","#         # A.HorizontalFlip(p=0.5),\n","#         # A.Cutout(max_h_size=int(image_size * 0.1), max_w_size=int(image_size * 0.1), num_holes=5, p=0.5),\n","#         # albumentations.RandomBrightness(limit=0.2, p=0.75),\n","#         # albumentations.RandomContrast(limit=0.2, p=0.75),\n","\n","#         # albumentations.OneOf([\n","#         #     albumentations.OpticalDistortion(distort_limit=1.),\n","#         #     albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n","#         # ], p=0.75),\n","\n","#         # albumentations.HueSaturationValue(hue_shift_limit=40, sat_shift_limit=40, val_shift_limit=0, p=0.75),\n","#         # albumentations.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.3, rotate_limit=30, border_mode=0, p=0.75),\n","#         # A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=10, val_shift_limit=10, p=0.7),\n","#         # A.RandomBrightnessContrast(brightness_limit=(-0.2,0.2), contrast_limit=(-0.2, 0.2), p=0.7),\n","#         # A.CLAHE(p=0.5),\n","#         # albumentations.OneOf([\n","#         # albumentations.OpticalDistortion(distort_limit=1.),\n","#         # albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n","#         # ], p=0.75),\n","#         # A.OneOf([\n","#         # A.GaussianBlur(),\n","#         # A.MotionBlur(),\n","#         # A.MedianBlur(), ], p=0.5),\n","#         # A.IAASharpen(p = 0.2),\n","#         # A.JpegCompression(p=0.2),\n","#         # A.Downscale(scale_min=0.5, scale_max=0.75),\n","#         # A.OneOf([ A.JpegCompression(), A.Downscale(scale_min=0.1, scale_max=0.15), ], p=0.2), \n","#         # A.IAAPiecewiseAffine(),\n","# #         A.OneOf([ \n","# #         A.OpticalDistortion(distort_limit=1.0), \n","# #         A.GridDistortion(num_steps=5, distort_limit=1.),\n","# #         A.ElasticTransform(alpha=3), ], p=0.2),\n","# #         A.OneOf([\n","# #             A.GaussNoise(var_limit=[10, 50]),\n","# #             A.GaussianBlur(),\n","# #             A.MotionBlur(),\n","# #             A.MedianBlur(), ], p=0.2),\n","#         # A.OneOf([\n","#         #     A.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n","#         #     A.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=1.0),\n","#         #     A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n","#         # ], p=0.25),\n","#         # A.CoarseDropout(max_holes=8, max_height=image_size//20, max_width=image_size//20,\n","#         #                  min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n","#         # A.Normalize(mean=0, std=1),\n","#         ToTensorV2(),], p=1.0),\n","    \n","#     \"valid\": A.Compose([\n","#         # IsotropicResize(max_side = image_size),\n","#         A.PadIfNeeded(min_height=image_size, min_width=image_size, border_mode=cv2.BORDER_CONSTANT),\n","#         # A.Normalize(mean=0, std=1),\n","# #         A.Resize(image_size, image_size),\n","#         ToTensorV2(),\n","#         ], p=1.0)\n","# }\n","\n","# LOGGER.info(f\"train transform{data_transforms['train']}\")\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:20.934703Z","iopub.status.busy":"2022-12-30T08:23:20.933649Z","iopub.status.idle":"2022-12-30T08:23:21.010802Z","shell.execute_reply":"2022-12-30T08:23:21.009678Z","shell.execute_reply.started":"2022-12-30T08:23:20.934663Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3, 1344, 840]) tensor(0)\n","tensor(255.)\n"]}],"source":["def pad(array, target_shape):\n","    return np.pad(\n","        array,\n","        [(0, target_shape[i] - array.shape[i]) for i in range(len(array.shape))],\n","        \"constant\",\n","    )\n","    \n","def load_img(img_path):\n","    image = cv2.imread(img_path)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    # image = pad(image, (1024, 800, 3))\n","        # img = img.reshape((*resize))\n","    return image\n","#     image = cv2.resize(image, (320, 320), cv2.INTER_NEAREST)\n","#     image = image.astype(np.float32)\n","#     mx = np.max(image)\n","#     if mx:\n","#         image/=mx\n","#     image = image /255.0\n","    \n","    return image\n","class BreastDataset(Dataset):\n","    def __init__(self, df, transforms=None):\n","        self.df = df\n","        self.transforms = transforms\n","        \n","    def __getitem__(self, index):\n","        row = self.df.iloc[index]\n","        img_path = f\"flip/{row.patient_id}_{row.image_id}.png\"\n","        img = load_img(img_path)\n","        label = row['cancer']\n","        # img = np.transpose(img, (2, 0, 1))\n","        data = self.transforms(image=img)\n","        img  = data['image']\n","        # img = img/255.0\n","        return torch.tensor(img).float(), torch.tensor(label).long()\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","fold0 = df[df['fold']==0]\n","train_dataset = BreastDataset(fold0, transforms = data_transforms['train'])\n","image, label = train_dataset[0]\n","print(image.shape, label)\n","print(image.max())"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["\n","# from pylab import rcParams\n","\n","# f, axarr = plt.subplots(1,15, figsize = (20, 20))\n","# imgs = []\n","# for p in range(15):\n","#     img, label = train_dataset[p]\n","#     img = img.transpose(0, 1).transpose(1,2).cpu().numpy()\n","#     img = img.astype(np.uint8)\n","#     imgs.append(img)\n","#     axarr[p].imshow(img)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:21.012682Z","iopub.status.busy":"2022-12-30T08:23:21.012267Z","iopub.status.idle":"2022-12-30T08:23:21.020148Z","shell.execute_reply":"2022-12-30T08:23:21.019023Z","shell.execute_reply.started":"2022-12-30T08:23:21.012626Z"},"trusted":true},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(model_name, pretrained=True,drop_rate = 0.3, drop_path_rate = 0.2)\n","        self.fc = nn.Linear(self.backbone.classifier.in_features,2)\n","        self.backbone.classifier = nn.Identity()\n","        self.dropout = nn.Dropout(0.5)\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.fc(self.dropout(x))\n","        return x"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:21.022923Z","iopub.status.busy":"2022-12-30T08:23:21.022147Z","iopub.status.idle":"2022-12-30T08:23:21.032555Z","shell.execute_reply":"2022-12-30T08:23:21.031346Z","shell.execute_reply.started":"2022-12-30T08:23:21.022887Z"},"trusted":true},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim.optimizer import Optimizer, required\n","import math\n","\n","class AdamP(Optimizer):\n","    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n","                 weight_decay=0, delta=0.1, wd_ratio=0.1, nesterov=False):\n","        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay,\n","                        delta=delta, wd_ratio=wd_ratio, nesterov=nesterov)\n","        super(AdamP, self).__init__(params, defaults)\n","\n","    def _channel_view(self, x):\n","        return x.view(x.size(0), -1)\n","\n","    def _layer_view(self, x):\n","        return x.view(1, -1)\n","\n","    def _cosine_similarity(self, x, y, eps, view_func):\n","        x = view_func(x)\n","        y = view_func(y)\n","\n","        return F.cosine_similarity(x, y, dim=1, eps=eps).abs_()\n","\n","    def _projection(self, p, grad, perturb, delta, wd_ratio, eps):\n","        wd = 1\n","        expand_size = [-1] + [1] * (len(p.shape) - 1)\n","        for view_func in [self._channel_view, self._layer_view]:\n","\n","            cosine_sim = self._cosine_similarity(grad, p.data, eps, view_func)\n","\n","            if cosine_sim.max() < delta / math.sqrt(view_func(p.data).size(1)):\n","                p_n = p.data / view_func(p.data).norm(dim=1).view(expand_size).add_(eps)\n","                perturb -= p_n * view_func(p_n * perturb).sum(dim=1).view(expand_size)\n","                wd = wd_ratio\n","\n","                return perturb, wd\n","\n","        return perturb, wd\n","\n","    def step(self, closure=None):\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","\n","                grad = p.grad.data\n","                beta1, beta2 = group['betas']\n","                nesterov = group['nesterov']\n","\n","                state = self.state[p]\n","\n","                # State initialization\n","                if len(state) == 0:\n","                    state['step'] = 0\n","                    state['exp_avg'] = torch.zeros_like(p.data)\n","                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n","\n","                # Adam\n","                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n","\n","                state['step'] += 1\n","                bias_correction1 = 1 - beta1 ** state['step']\n","                bias_correction2 = 1 - beta2 ** state['step']\n","\n","                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n","                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n","\n","                denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n","                step_size = group['lr'] / bias_correction1\n","\n","                if nesterov:\n","                    perturb = (beta1 * exp_avg + (1 - beta1) * grad) / denom\n","                else:\n","                    perturb = exp_avg / denom\n","\n","                # Projection\n","                wd_ratio = 1\n","                if len(p.shape) > 1:\n","                    perturb, wd_ratio = self._projection(p, grad, perturb, group['delta'], group['wd_ratio'], group['eps'])\n","\n","                # Weight decay\n","                if group['weight_decay'] > 0:\n","                    p.data.mul_(1 - group['lr'] * group['weight_decay'] * wd_ratio)\n","\n","                # Step\n","                p.data.add_(perturb, alpha=-step_size)\n","\n","        return loss\n","\n","class SGDP(Optimizer):\n","    def __init__(self, params, lr=required, momentum=0, dampening=0,\n","                 weight_decay=0, nesterov=False, eps=1e-8, delta=0.1, wd_ratio=0.1):\n","        defaults = dict(lr=lr, momentum=momentum, dampening=dampening, weight_decay=weight_decay,\n","                        nesterov=nesterov, eps=eps, delta=delta, wd_ratio=wd_ratio)\n","        super(SGDP, self).__init__(params, defaults)\n","\n","    def _channel_view(self, x):\n","        return x.view(x.size(0), -1)\n","\n","    def _layer_view(self, x):\n","        return x.view(1, -1)\n","\n","    def _cosine_similarity(self, x, y, eps, view_func):\n","        x = view_func(x)\n","        y = view_func(y)\n","\n","        return F.cosine_similarity(x, y, dim=1, eps=eps).abs_()\n","\n","    def _projection(self, p, grad, perturb, delta, wd_ratio, eps):\n","        wd = 1\n","        expand_size = [-1] + [1] * (len(p.shape) - 1)\n","        for view_func in [self._channel_view, self._layer_view]:\n","\n","            cosine_sim = self._cosine_similarity(grad, p.data, eps, view_func)\n","\n","            if cosine_sim.max() < delta / math.sqrt(view_func(p.data).size(1)):\n","                p_n = p.data / view_func(p.data).norm(dim=1).view(expand_size).add_(eps)\n","                perturb -= p_n * view_func(p_n * perturb).sum(dim=1).view(expand_size)\n","                wd = wd_ratio\n","\n","                return perturb, wd\n","\n","        return perturb, wd\n","\n","    def step(self, closure=None):\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","            momentum = group['momentum']\n","            dampening = group['dampening']\n","            nesterov = group['nesterov']\n","\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                grad = p.grad.data\n","                state = self.state[p]\n","\n","                # State initialization\n","                if len(state) == 0:\n","                    state['momentum'] = torch.zeros_like(p.data)\n","\n","                # SGD\n","                buf = state['momentum']\n","                buf.mul_(momentum).add_(grad, alpha=1 - dampening)\n","                if nesterov:\n","                    d_p = grad + momentum * buf\n","                else:\n","                    d_p = buf\n","\n","                # Projection\n","                wd_ratio = 1\n","                if len(p.shape) > 1:\n","                    d_p, wd_ratio = self._projection(p, grad, d_p, group['delta'], group['wd_ratio'], group['eps'])\n","\n","                # Weight decay\n","                if group['weight_decay'] > 0:\n","                    p.data.mul_(1 - group['lr'] * group['weight_decay'] * wd_ratio / (1-momentum))\n","\n","                # Step\n","                p.data.add_(d_p, alpha=-group['lr'])\n","\n","        return loss\n","\n","class SAM(torch.optim.Optimizer):\n","    def __init__(self, params, base_optimizer, rho=0.05, **kwargs):\n","        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n","\n","        defaults = dict(rho=rho, **kwargs)\n","        super(SAM, self).__init__(params, defaults)\n","\n","        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n","        self.param_groups = self.base_optimizer.param_groups\n","\n","    @torch.no_grad()\n","    def first_step(self, zero_grad=False):\n","        grad_norm = self._grad_norm()\n","        for group in self.param_groups:\n","            scale = group[\"rho\"] / (grad_norm + 1e-12)\n","\n","            for p in group[\"params\"]:\n","                if p.grad is None: continue\n","                e_w = p.grad * scale.to(p)\n","                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n","                self.state[p][\"e_w\"] = e_w\n","\n","        if zero_grad: self.zero_grad()\n","\n","    @torch.no_grad()\n","    def second_step(self, zero_grad=False):\n","        for group in self.param_groups:\n","            for p in group[\"params\"]:\n","                if p.grad is None: continue\n","                p.sub_(self.state[p][\"e_w\"])  # get back to \"w\" from \"w + e(w)\"\n","\n","        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n","\n","        if zero_grad: self.zero_grad()\n","\n","    def step(self, closure=None):\n","        raise NotImplementedError(\"SAM doesn't work like the other optimizers, you should first call `first_step` and the `second_step`; see the documentation for more info.\")\n","\n","    def _grad_norm(self):\n","        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n","        norm = torch.norm(\n","                    torch.stack([\n","                        p.grad.norm(p=2).to(shared_device)\n","                        for group in self.param_groups for p in group[\"params\"]\n","                        if p.grad is not None\n","                    ]),\n","                    p=2\n","               )\n","        return norm"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["from torch.optim.lr_scheduler import _LRScheduler\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","\n","class GradualWarmupScheduler(_LRScheduler):\n","    \"\"\" Gradually warm-up(increasing) learning rate in optimizer.\n","    Proposed in 'Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour'.\n","    Args:\n","        optimizer (Optimizer): Wrapped optimizer.\n","        multiplier: target learning rate = base lr * multiplier if multiplier > 1.0. if multiplier = 1.0, lr starts from 0 and ends up with the base_lr.\n","        total_epoch: target learning rate is reached at total_epoch, gradually\n","        after_scheduler: after target_epoch, use this scheduler(eg. ReduceLROnPlateau)\n","    \"\"\"\n","\n","    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n","        self.multiplier = multiplier\n","        if self.multiplier < 1.:\n","            raise ValueError('multiplier should be greater thant or equal to 1.')\n","        self.total_epoch = total_epoch\n","        self.after_scheduler = after_scheduler\n","        self.finished = False\n","        super(GradualWarmupScheduler, self).__init__(optimizer)\n","\n","    def get_lr(self):\n","        if self.last_epoch > self.total_epoch:\n","            if self.after_scheduler:\n","                if not self.finished:\n","                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n","                    self.finished = True\n","                return self.after_scheduler.get_last_lr()\n","            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n","\n","        if self.multiplier == 1.0:\n","            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n","        else:\n","            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n","\n","    def step_ReduceLROnPlateau(self, metrics, epoch=None):\n","        if epoch is None:\n","            epoch = self.last_epoch + 1\n","        self.last_epoch = epoch if epoch != 0 else 1  # ReduceLROnPlateau is called at the end of epoch, whereas others are called at beginning\n","        if self.last_epoch <= self.total_epoch:\n","            warmup_lr = [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n","            for param_group, lr in zip(self.optimizer.param_groups, warmup_lr):\n","                param_group['lr'] = lr\n","        else:\n","            if epoch is None:\n","                self.after_scheduler.step(metrics, None)\n","            else:\n","                self.after_scheduler.step(metrics, epoch - self.total_epoch)\n","\n","    def step(self, epoch=None, metrics=None):\n","        if type(self.after_scheduler) != ReduceLROnPlateau:\n","            if self.finished and self.after_scheduler:\n","                if epoch is None:\n","                    self.after_scheduler.step(None)\n","                else:\n","                    self.after_scheduler.step(epoch - self.total_epoch)\n","                self._last_lr = self.after_scheduler.get_last_lr()\n","            else:\n","                return super(GradualWarmupScheduler, self).step(epoch)\n","        else:\n","            self.step_ReduceLROnPlateau(metrics, epoch)\n","\n","class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n","    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n","        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n","    def get_lr(self):\n","        if self.last_epoch > self.total_epoch:\n","            if self.after_scheduler:\n","                if not self.finished:\n","                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n","                    self.finished = True\n","                return self.after_scheduler.get_lr()\n","            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n","        if self.multiplier == 1.0:\n","            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n","        else:\n","            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n","\n","class Lookahead(optim.Optimizer):\n","    def __init__(self, base_optimizer, alpha=0.5, k=6):\n","        if not 0.0 <= alpha <= 1.0:\n","            raise ValueError(f'Invalid slow update rate: {alpha}')\n","        if not 1 <= k:\n","            raise ValueError(f'Invalid lookahead steps: {k}')\n","        defaults = dict(lookahead_alpha=alpha, lookahead_k=k, lookahead_step=0)\n","        self.base_optimizer = base_optimizer\n","        self.param_groups = self.base_optimizer.param_groups\n","        self.defaults = base_optimizer.defaults\n","        self.defaults.update(defaults)\n","        self.state = defaultdict(dict)\n","        # manually add our defaults to the param groups\n","        for name, default in defaults.items():\n","            for group in self.param_groups:\n","                group.setdefault(name, default)\n","\n","    def update_slow(self, group):\n","        for fast_p in group[\"params\"]:\n","            if fast_p.grad is None:\n","                continue\n","            param_state = self.state[fast_p]\n","            if 'slow_buffer' not in param_state:\n","                param_state['slow_buffer'] = torch.empty_like(fast_p.data)\n","                param_state['slow_buffer'].copy_(fast_p.data)\n","            slow = param_state['slow_buffer']\n","            slow.add_(group['lookahead_alpha'], fast_p.data - slow)\n","            fast_p.data.copy_(slow)\n","\n","    def sync_lookahead(self):\n","        for group in self.param_groups:\n","            self.update_slow(group)\n","\n","    def step(self, closure=None):\n","        #assert id(self.param_groups) == id(self.base_optimizer.param_groups)\n","        loss = self.base_optimizer.step(closure)\n","        for group in self.param_groups:\n","            group['lookahead_step'] += 1\n","            if group['lookahead_step'] % group['lookahead_k'] == 0:\n","                self.update_slow(group)\n","        return loss\n","\n","    def state_dict(self):\n","        fast_state_dict = self.base_optimizer.state_dict()\n","        slow_state = {\n","            (id(k) if isinstance(k, torch.Tensor) else k): v\n","            for k, v in self.state.items()\n","        }\n","        fast_state = fast_state_dict['state']\n","        param_groups = fast_state_dict['param_groups']\n","        return {\n","            'state': fast_state,\n","            'slow_state': slow_state,\n","            'param_groups': param_groups,\n","        }\n","\n","    def load_state_dict(self, state_dict):\n","        fast_state_dict = {\n","            'state': state_dict['state'],\n","            'param_groups': state_dict['param_groups'],\n","        }\n","        self.base_optimizer.load_state_dict(fast_state_dict)\n","\n","        # We want to restore the slow state, but share param_groups reference\n","        # with base_optimizer. This is a bit redundant but least code\n","        slow_state_new = False\n","        if 'slow_state' not in state_dict:\n","            print('Loading state_dict from optimizer without Lookahead applied.')\n","            state_dict['slow_state'] = defaultdict(dict)\n","            slow_state_new = True\n","        slow_state_dict = {\n","            'state': state_dict['slow_state'],\n","            'param_groups': state_dict['param_groups'],  # this is pointless but saves code\n","        }\n","        super(Lookahead, self).load_state_dict(slow_state_dict)\n","        self.param_groups = self.base_optimizer.param_groups  # make both ref same container\n","        if slow_state_new:\n","            # reapply defaults to catch missing lookahead specific ones\n","            for name, default in self.defaults.items():\n","                for group in self.param_groups:\n","                    group.setdefault(name, default)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:21.036233Z","iopub.status.busy":"2022-12-30T08:23:21.035928Z","iopub.status.idle":"2022-12-30T08:23:21.059619Z","shell.execute_reply":"2022-12-30T08:23:21.058523Z","shell.execute_reply.started":"2022-12-30T08:23:21.036197Z"},"trusted":true},"outputs":[],"source":["\n","def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    # switch to train mode\n","    model.train()\n","    start = end = time.time()\n","    truth = []\n","    pred = []\n","    global_step = 0\n","    scaler = GradScaler()\n","    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc='Train')\n","    for step, (images, labels) in pbar:\n","        optimizer.zero_grad()\n","        data_time.update(time.time() - end)\n","        images = images.to(device)\n","        \n","        \n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with autocast():\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            # loss.backward()\n","            # optimizer.first_step(zero_grad=True)\n","            # criterion(model(images), labels).backward()\n","            # optimizer.second_step(zero_grad=True)\n","            # record loss\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        # global_step += 1\n","        scheduler.step()\n","            # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","#         if step % 100 == 0 or step == (len(train_loader)-1):\n","#             print('Epoch: [{0}][{1}/{2}] '\n","#                       'Data {data_time.val:.6f} ({data_time.avg:.6f}) '\n","#                       'Elapsed {remain:s} '\n","#                       'Loss: {loss.val:.6f}({loss.avg:.6f}) '\n","#                       'LR: {lr:.6f}  '\n","#                       .format(\n","#                        epoch+1, step, len(train_loader), batch_time=batch_time,\n","#                        data_time=data_time, loss=losses,\n","#                        remain=timeSince(start, float(step+1)/len(train_loader)),\n","#                        lr=scheduler.get_lr()[0],\n","#                        ))\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","        current_lr = optimizer.param_groups[0]['lr']\n","        pbar.set_postfix(train_loss=f'{losses.avg:0.4f}',\n","                        lr=f'{current_lr:0.8f}',\n","                        gpu_mem=f'{mem:0.2f} GB')\n","\n","    return losses.avg\n","\n","def valid_fn_no_sigmoid(val_dataloader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    truth = []\n","    preds = []\n","    valid_labels = []\n","    start = end = time.time()\n","    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n","    for step, (images, labels) in pbar:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            outputs = model(images)\n","        valid_labels.append(labels.cpu().numpy())\n","        loss = criterion(outputs, labels)\n","#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n","        losses.update(loss.item(), batch_size)\n","#         print(outputs)\n","        preds.append((outputs).to('cpu').numpy())\n","        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n","                        gpu_mem=f'{mem:0.2f} GB')\n","    predictions = np.concatenate(preds)\n","    valid_labels = np.concatenate(valid_labels)\n","    return losses.avg, predictions, valid_labels\n","\n","\n","def valid_fn(val_dataloader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    truth = []\n","    preds = []\n","    valid_labels = []\n","    start = end = time.time()\n","    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n","    for step, (images, labels) in pbar:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            outputs = model(images)\n","        valid_labels.append(labels.cpu().numpy())\n","        loss = criterion(outputs, labels)\n","#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n","        losses.update(loss.item(), batch_size)\n","#         print(outputs)\n","        preds.append(torch.sigmoid(outputs).to('cpu').numpy())\n","        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n","                        gpu_mem=f'{mem:0.2f} GB')\n","    predictions = np.concatenate(preds)\n","    valid_labels = np.concatenate(valid_labels)\n","    return losses.avg, predictions, valid_labels\n","def valid_fn_two(val_dataloader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    truth = []\n","    preds = []\n","    valid_labels = []\n","    start = end = time.time()\n","    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n","    for step, (images, labels) in pbar:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            outputs = model(images)\n","        valid_labels.append(labels.cpu().numpy())\n","        loss = criterion(outputs, labels)\n","#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n","        losses.update(loss.item(), batch_size)\n","#         print(outputs)\n","        preds.append(F.softmax(outputs).to('cpu').numpy())\n","        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n","                        gpu_mem=f'{mem:0.2f} GB')\n","    predictions = np.concatenate(preds)\n","    valid_labels = np.concatenate(valid_labels)\n","    return losses.avg, predictions, valid_labels\n","def valid_fn_flip(val_dataloader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    truth = []\n","    preds = []\n","    valid_labels = []\n","    start = end = time.time()\n","    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n","    for step, (images, labels) in pbar:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        images = torch.flip(images, [3])\n","        with torch.no_grad():\n","            outputs = model(images)\n","        valid_labels.append(labels.cpu().numpy())\n","        loss = criterion(outputs, labels)\n","#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n","        losses.update(loss.item(), batch_size)\n","#         print(outputs)\n","        preds.append(torch.sigmoid(outputs).to('cpu').numpy())\n","        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n","                        gpu_mem=f'{mem:0.2f} GB')\n","    predictions = np.concatenate(preds)\n","    valid_labels = np.concatenate(valid_labels)\n","    return losses.avg, predictions, valid_labels"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:32:56.198968Z","iopub.status.busy":"2022-12-30T08:32:56.198538Z","iopub.status.idle":"2022-12-30T08:38:54.946641Z","shell.execute_reply":"2022-12-30T08:38:54.945288Z","shell.execute_reply.started":"2022-12-30T08:32:56.198933Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Fold: 0\n"]},{"name":"stdout","output_type":"stream","text":["> SEEDING DONE\n"]},{"name":"stderr","output_type":"stream","text":["Len train df: 44652\n","Train bs: 12\n","optimizer: AdamW (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    eps: 1e-08\n","    foreach: None\n","    initial_lr: 0.0001\n","    lr: 0.0\n","    maximize: False\n","    weight_decay: 0.0005\n",")\n","total_epoch :1\n"]}],"source":["from exhaustive_weighted_random_sampler import ExhaustiveWeightedRandomSampler\n","def pfbeta(labels, predictions, beta=1):\n","    y_true_count = 0\n","    ctp = 0\n","    cfp = 0\n","\n","    for idx in range(len(labels)):\n","        prediction = min(max(predictions[idx], 0), 1)\n","        if (labels[idx]):\n","            y_true_count += 1\n","            ctp += prediction\n","        else:\n","            cfp += prediction\n","\n","    beta_squared = beta * beta\n","    c_precision = ctp / (ctp + cfp)\n","    c_recall = ctp / y_true_count\n","    if (c_precision > 0 and c_recall > 0):\n","        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n","        return result\n","    else:\n","        return 0\n","    \n","def dfs_freeze(module):\n","    for param in module.parameters():\n","        param.requires_grad = False\n","        \n","def dfs_unfreeze(module):\n","    for param in module.parameters():\n","        param.requires_grad = True\n","    \n","def set_seed(seed = 42):\n","    '''Sets the seed of the entire notebook so results are the same every time we run.\n","    This is for REPRODUCIBILITY.'''\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    # When running on the CuDNN backend, two further options must be set\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    # Set a fixed value for the hash seed\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    print('> SEEDING DONE')\n","\n","def sigmoid(x):\n","  return 1 / (1 + math.exp(-x))\n","\n","set_seed(1)\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","gc.collect()\n","torch.cuda.empty_cache()\n","for fold in [0]:\n","    LOGGER.info(f\"Fold: {fold}\")\n","    model = Model(model_name=CFG.model_name).to(device)\n","    # model = ModelVIT().to(CFG.device)\n","    train_df = df1[df1['fold']!=fold].reset_index(drop=True)\n","    valid_df = df[df['fold']==fold].reset_index(drop=True)\n","    # print(len(valid_df))\n","    LOGGER.info(f\"Len train df: {len(train_df)}\")\n","    cancer_labels = train_df['cancer'].values.tolist()\n","    class_zero =len(train_df[train_df['cancer']==0])\n","    class_one = len(train_df[train_df['cancer']==1])\n","    class_sample_count = np.array([class_zero, class_one*32])\n","    weight = 1. / class_sample_count\n","    samples_weight = np.array([weight[t] for t in cancer_labels])\n","    samples_weight = torch.from_numpy(samples_weight)\n","    samples_weight = samples_weight.double()\n","#     print(samples_weight)\n","    sampler = ExhaustiveWeightedRandomSampler(samples_weight, len(samples_weight))\n","    \n","    train_dataset = BreastDataset(train_df, transforms=data_transforms['train'])\n","\n","    train_loader = DataLoader(train_dataset, batch_size = CFG.train_bs,\n","                                  num_workers=1, shuffle=True, pin_memory=True, drop_last=True)\n","    \n","    valid_dataset = BreastDataset(valid_df, transforms=data_transforms['valid'])\n","\n","    valid_loader = DataLoader(valid_dataset, batch_size = CFG.valid_bs, \n","                                  num_workers=1, shuffle=False, pin_memory=True, drop_last=False)\n","    \n","    LEN_DL_TRAIN = len(train_loader)\n","    best_f1 = 0\n","    best_metric = 0\n","    total_epoch = 1\n","    # checkpoint = torch.load(\"swa_tf_efficientnetv2_b2_fold_3_model_0.5325_0.428.pth\")\n","    # model.load_state_dict(checkpoint['state_dict'])\n","    # base_optimizer = AdamP\n","    # optimizer = SAM(model.parameters(),\n","    #                 base_optimizer,\n","    #                 rho=0.05,\n","    #                 lr=1e-4,\n","    #                 weight_decay=0.0,\n","    #                 nesterov=True)\n","    optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-4, weight_decay = 5e-4)\n","    # optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)  \n","    # optimizer.load_state_dict(checkpoint['optimizer'])\n","    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps = 1*LEN_DL_TRAIN, num_training_steps =total_epoch*LEN_DL_TRAIN)\n","    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, total_epoch)\n","    # scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, total_epoch-1)\n","    # scheduler = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n","    # swa_model = AveragedModel(model)\n","    # swa_scheduler = SWALR(optimizer, swa_lr=1e-4, anneal_epochs=0)\n","    # scheduler.load_state_dict(checkpoint['scheduler'])\n","    criterion = nn.CrossEntropyLoss().to(device)\n","    # criterion1 = nn.BCEWithLogitsLoss().to(device)\n","    # criterion = nn.BCEWithLogitsLoss().to(CFG.device)\n","    LOGGER.info(f\"Train bs: {CFG.train_bs}\")\n","    # LOGGER.info(f\"Model: {model}\")\n","    \n","    LOGGER.info(f\"optimizer: {optimizer}\")\n","    LOGGER.info(f\"total_epoch :{total_epoch}\")\n","    # criterion = FocalLoss().to(device)\n","    # for epoch in range(1, total_epoch+1):\n","    #     # if epoch >=7:\n","    #     #     swa_model.update_parameters(model)\n","    #     #     swa_scheduler.step()\n","    #     # else:\n","    #     # scheduler.step(epoch-1)\n","    #     LOGGER.info(f\"Epoch: {epoch}/{total_epoch}\")\n","    #     # loss_train = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","    #     # state = {'epoch': epoch, 'state_dict': model.state_dict(),'optimizer': optimizer.state_dict(), 'scheduler':scheduler.state_dict()}\n","    #     # path = f'{CFG.model_name}_fold_{fold}_model_epoch_{epoch}.pth'\n","    #     # torch.save(state, path)\n","    #     loss_valid, valid_preds, valid_labels = valid_fn_two(valid_loader, model, criterion, device)\n","    #     # print(valid_preds)\n","    #     valid_preds = valid_preds[:, 1]\n","    #     valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n","    #     valid_preds = np.array(valid_preds).flatten()\n","        \n","    #     valid_df['raw_pred'] = valid_preds\n","        # LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n","    #     LOGGER.info(f\"Train loss:{loss_train:.4f}, Valid loss:{loss_valid:.4f}\")\n","    #     # print(valid_df.head())\n","    #     grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n","    #     grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n","    #     valid_labels_mean = grp_df['cancer'].values.tolist()\n","    #     valid_preds_mean = grp_df['raw_pred'].values.tolist()\n","    #     # print(valid_labels[:5], valid_preds_mean[:5])\n","    #     val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n","    #     LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n","    #     best_metric_mean_at_epoch = 0\n","    #     best_threshold_mean = 0\n","    #     best_auc = 0\n","    #     best_cf = None\n","    #     for i in np.arange(0.001, 0.599, 0.001):\n","    #         valid_argmax = (valid_preds_mean>i).astype(np.int32)\n","    # #             print(valid_argmax)\n","    #         val_metric = pfbeta(valid_labels_mean, valid_argmax)\n","    #         val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n","    #         val_f1 = f1_score(valid_labels_mean, valid_argmax)\n","    #         val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n","    #         cf = confusion_matrix(valid_labels_mean, valid_argmax)\n","    #         if val_metric> best_metric_mean_at_epoch:\n","    #             best_metric_mean_at_epoch = val_metric\n","    #             best_threshold_mean = i\n","    #             best_auc = val_auc\n","    #             best_cf = cf\n","    #         # print(f\"Threshold: {i:.4f}, val_acc: {val_acc:.4f}, val_f1: {val_f1:.4f}, val_auc: {val_auc:.4f}, val_metric: {val_metric:.4f}\")\n","    #     LOGGER.info(f\"Best metric at epoch {epoch}: {best_metric_mean_at_epoch:.4f} {best_threshold_mean:.4f} {best_auc:.4f}\")\n","    #     LOGGER.info(f\"Cf: {best_cf}\")\n","    # #         print(f\"Train loss: {loss_train:.4f}, eval loss: {loss_valid.avg:.4f}\") \n","    # #         print(f\"Accuracy score: {val_acc:.4f}, f1 score: {val_f1:.4f}\")\n","    # #         print(f\"Comp metric: {val_metric:.4f}\")\n","    #     if best_metric_mean_at_epoch > best_metric:\n","\n","    #         LOGGER.info(f\"Model improve: {best_metric:.4f} -> {best_metric_mean_at_epoch:.4f}\")\n","    #         best_metric = best_metric_mean_at_epoch\n","    #     state = {'epoch': epoch, 'state_dict': model.state_dict(),'optimizer': optimizer.state_dict(), 'scheduler':scheduler.state_dict()}\n","    #     path = f'{CFG.model_name}_fold_{fold}_model_epoch_{epoch}_{best_metric_mean_at_epoch:.4f}_{best_threshold_mean:.3f}.pth'\n","    #     torch.save(state, path)\n","        "]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# from sklearn import metrics\n","# def np_binary_cross_entropy_loss(probability, truth):\n","#     probability = probability.astype(np.float64)\n","#     probability = np.nan_to_num(probability, nan=1, posinf=1, neginf=0)\n","\n","#     p = np.clip(probability, 1e-5, 1 - 1e-5)\n","#     y = truth\n","\n","#     loss = -y * np.log(p) - (1 - y) * np.log(1 - p)\n","#     loss = loss.mean()\n","#     return loss\n","\n","# def get_f1score(probability, truth, threshold = np.linspace(0.2, 0.5, 5000)):\n","#     f1score = []\n","#     precision=[]\n","#     recall=[]\n","#     for t in threshold:\n","#         predict = (probability > t).astype(np.float32)\n","\n","#         tp = ((predict >= 0.5) & (truth >= 0.5)).sum()\n","#         fp = ((predict >= 0.5) & (truth < 0.5)).sum()\n","#         fn = ((predict < 0.5) & (truth >= 0.5)).sum()\n","\n","#         r = tp / (tp + fn + 1e-3)\n","#         p = tp / (tp + fp + 1e-3)\n","#         f1 = 2 * r * p / (r + p + 1e-3)\n","#         f1score.append(f1)\n","#         precision.append(p)\n","#         recall.append(r)\n","#     f1score = np.array(f1score)\n","#     precision = np.array(precision)\n","#     recall = np.array(recall)\n","#     return f1score, precision, recall, threshold\n","\n","\n","# def compute_metric(cancer_p, cancer_t):\n","\n","#     fpr, tpr, thresholds = metrics.roc_curve(cancer_t, cancer_p)\n","#     auc = metrics.auc(fpr, tpr)\n","\n","#     f1score, precision, recall, threshold = get_f1score(cancer_p, cancer_t)\n","#     i = f1score.argmax()\n","#     f1score, precision, recall, threshold = f1score[i], precision[i], recall[i], threshold[i]\n","\n","#     specificity = ((cancer_p < threshold ) & ((cancer_t <= 0.5))).sum() / (cancer_t <= 0.5).sum()\n","#     sensitivity = ((cancer_p >= threshold) & ((cancer_t >= 0.5))).sum() / (cancer_t >= 0.5).sum()\n","\n","#     return {\n","#         'auc': auc,\n","#         'threshold': threshold,\n","#         'f1score': f1score,\n","#         'precision': precision,\n","#         'recall': recall,\n","#         'sensitivity': sensitivity,\n","#         'specificity': specificity,\n","#     }\n","\n","# def compute_pfbeta(labels, predictions, beta=1):\n","#     y_true_count = 0\n","#     ctp = 0\n","#     cfp = 0\n","\n","#     for idx in range(len(labels)):\n","#         prediction = min(max(predictions[idx], 0), 1)\n","#         if (labels[idx]):\n","#             y_true_count += 1\n","#             ctp += prediction\n","#             #cfp += 1 - prediction\n","#         else:\n","#             cfp += prediction\n","\n","#     beta_squared = beta * beta\n","#     c_precision = ctp / (ctp + cfp+1e-8)\n","#     c_recall = ctp / y_true_count\n","#     if (c_precision > 0 and c_recall > 0):\n","#         result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n","#         return result\n","#     else:\n","#         return 0\n","\n","# def print_all_metric(valid_df):\n","\n","# \tprint(f'{\"    \": <16}    \\tauc      @th     f1      | \tprec    recall  | \tsens    spec ')\n","# \t#log.write(f'{\"    \": <16}    \\t0.77902\t0.44898\t0.28654 | \t0.32461\t0.25726 | \t0.25726\t0.98794\\n')\n","# \tfor site_id in [0,1,2]:\n","\n","# \t\t#log.write(f'*** site_id [{site_id}] ***\\n')\n","# \t\t#log.write(f'\\n')\n","\n","# \t\tif site_id>0:\n","# \t\t\tsite_df = valid_df[valid_df.site_id == site_id].reset_index(drop=True)\n","# \t\telse:\n","# \t\t\tsite_df = valid_df\n","# \t\t# ---\n","\n","# \t\tgb = site_df\n","# \t\tm = compute_metric(gb.raw_pred, gb.cancer)\n","# \t\ttext = f'{\"single image\": <16} [{site_id}]'\n","# \t\ttext += f'\\t{m[\"auc\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"threshold\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"f1score\"]:0.5f} | '\n","# \t\ttext += f'\\t{m[\"precision\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"recall\"]:0.5f} | '\n","# \t\ttext += f'\\t{m[\"sensitivity\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"specificity\"]:0.5f}'\n","# \t\t#text += '\\n'\n","# \t\tprint(text)\n","\n","\n","# \t\t# ---\n","\n","# \t\tgb = site_df[['patient_id', 'laterality', 'cancer', 'raw_pred']].groupby(['patient_id', 'laterality']).mean()\n","# \t\tm = compute_metric(gb.raw_pred, gb.cancer)\n","# \t\ttext = f'{\"grouby mean()\": <16} [{site_id}]'\n","# \t\ttext += f'\\t{m[\"auc\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"threshold\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"f1score\"]:0.5f} | '\n","# \t\ttext += f'\\t{m[\"precision\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"recall\"]:0.5f} | '\n","# \t\ttext += f'\\t{m[\"sensitivity\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"specificity\"]:0.5f}'\n","# \t\t#text += '\\n'\n","# \t\tprint(text)\n","\n","# \t\t# ---\n","# \t\tgb = site_df[['patient_id', 'laterality', 'cancer', 'raw_pred']].groupby(['patient_id', 'laterality']).max()\n","# \t\tm = compute_metric(gb.raw_pred, gb.cancer)\n","# \t\ttext = f'{\"grouby max()\": <16} [{site_id}]'\n","# \t\ttext += f'\\t{m[\"auc\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"threshold\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"f1score\"]:0.5f} | '\n","# \t\ttext += f'\\t{m[\"precision\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"recall\"]:0.5f} | '\n","# \t\ttext += f'\\t{m[\"sensitivity\"]:0.5f}'\n","# \t\ttext += f'\\t{m[\"specificity\"]:0.5f}'\n","# \t\t#text += '\\n'\n","# \t\tprint(text)\n","# \t\tprint(f'--------------\\n')\n","\n","\n","# # valid_df.loc[:, 'cancer_t'] = valid_preds\n","# print_all_metric(valid_df)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["import optuna\n","from optuna.samplers import TPESampler"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def pfbeta_np(labels, preds, beta=1):\n","    preds = preds.clip(0, 1)\n","    y_true_count = labels.sum()\n","    ctp = preds[labels==1].sum()\n","    cfp = preds[labels==0].sum()\n","    beta_squared = beta * beta\n","    c_precision = ctp / (ctp + cfp)\n","    c_recall = ctp / y_true_count\n","    if (c_precision > 0 and c_recall > 0):\n","        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n","        return result\n","    else:\n","        return 0.0"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2023-02-24 11:39:17,949]\u001b[0m A new study created in memory with name: no-name-07e7c83a-a934-4eff-85bc-5d66b29fd75f\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["> SEEDING DONE\n","none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.15198443381740748 0.25672863401172846 0.591286932170864\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:49<00:00,  1.26s/it, eval_loss=0.0838, gpu_mem=10.07 GB]\n","Valid loss:0.0838\n","Val metric mean prob: 0.2287\n","Best metric at: 0.4857 0.2910  0.7487\n","Cf: [[4607   59]\n"," [  49   51]]\n","\u001b[32m[I 2023-02-24 11:44:16,782]\u001b[0m Trial 0 finished with value: 0.4857142857142857 and parameters: {'a1': 0.15198443381740748, 'a2': 0.25672863401172846}. Best is trial 0 with value: 0.4857142857142857.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.06235401415270182 0.43121246871095986 0.5064335171363383\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:29<00:00,  1.18s/it, eval_loss=0.0838, gpu_mem=10.07 GB]\n","Valid loss:0.0838\n","Val metric mean prob: 0.2540\n","Best metric at: 0.4804 0.3600  0.7111\n","Cf: [[4630   36]\n"," [  57   43]]\n","\u001b[32m[I 2023-02-24 11:48:55,690]\u001b[0m Trial 1 finished with value: 0.4804469273743017 and parameters: {'a1': 0.06235401415270182, 'a2': 0.43121246871095986}. Best is trial 0 with value: 0.4857142857142857.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.8270655972088143 0.15944838645109546 0.013486016340090196\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:28<00:00,  1.17s/it, eval_loss=0.1087, gpu_mem=10.07 GB]\n","Valid loss:0.1087\n","Val metric mean prob: 0.1974\n","Best metric at: 0.5116 0.4940  0.7170\n","Cf: [[4638   28]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 11:53:33,890]\u001b[0m Trial 2 finished with value: 0.5116279069767442 and parameters: {'a1': 0.8270655972088143, 'a2': 0.15944838645109546}. Best is trial 2 with value: 0.5116279069767442.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.7199921054915603 0.21462486621604113 0.06538302829239853\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:30<00:00,  1.18s/it, eval_loss=0.1068, gpu_mem=10.07 GB]\n","Valid loss:0.1068\n","Val metric mean prob: 0.1930\n","Best metric at: 0.5202 0.4740  0.7220\n","Cf: [[4638   28]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 11:58:16,187]\u001b[0m Trial 3 finished with value: 0.5202312138728323 and parameters: {'a1': 0.7199921054915603, 'a2': 0.21462486621604113}. Best is trial 3 with value: 0.5202312138728323.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.2672438107409991 0.4715927941741754 0.2611633950848255\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:30<00:00,  1.18s/it, eval_loss=0.0893, gpu_mem=10.07 GB]\n","Valid loss:0.0893\n","Val metric mean prob: 0.2304\n","Best metric at: 0.4854 0.3390  0.7440\n","Cf: [[4610   56]\n"," [  50   50]]\n","\u001b[32m[I 2023-02-24 12:02:56,402]\u001b[0m Trial 4 finished with value: 0.4854368932038835 and parameters: {'a1': 0.2672438107409991, 'a2': 0.4715927941741754}. Best is trial 3 with value: 0.5202312138728323.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.09334615100410686 0.07299611171763565 0.8336577372782575\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:31<00:00,  1.18s/it, eval_loss=0.0812, gpu_mem=10.07 GB]\n","Valid loss:0.0812\n","Val metric mean prob: 0.2208\n","Best metric at: 0.4804 0.2570  0.7391\n","Cf: [[4611   55]\n"," [  51   49]]\n","\u001b[32m[I 2023-02-24 12:07:37,032]\u001b[0m Trial 5 finished with value: 0.4803921568627451 and parameters: {'a1': 0.09334615100410686, 'a2': 0.07299611171763565}. Best is trial 3 with value: 0.5202312138728323.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.5841280021678498 0.1430333685445009 0.27283862928764935\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:47<00:00,  1.25s/it, eval_loss=0.1024, gpu_mem=10.07 GB]\n","Valid loss:0.1024\n","Val metric mean prob: 0.1842\n","Best metric at: 0.5085 0.4250  0.7216\n","Cf: [[4634   32]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 12:12:33,761]\u001b[0m Trial 6 finished with value: 0.5084745762711864 and parameters: {'a1': 0.5841280021678498, 'a2': 0.1430333685445009}. Best is trial 3 with value: 0.5202312138728323.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.9789985109384551 0.01286657109614868 0.008134917965396185\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:48<00:00,  1.26s/it, eval_loss=0.1123, gpu_mem=10.07 GB]\n","Valid loss:0.1123\n","Val metric mean prob: 0.2041\n","Best metric at: 0.4884 0.5070  0.7068\n","Cf: [[4636   30]\n"," [  58   42]]\n","\u001b[32m[I 2023-02-24 12:17:32,027]\u001b[0m Trial 7 finished with value: 0.4883720930232558 and parameters: {'a1': 0.9789985109384551, 'a2': 0.01286657109614868}. Best is trial 3 with value: 0.5202312138728323.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6752797077033628 0.1791797060334395 0.14554058626319774\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:29<00:00,  1.18s/it, eval_loss=0.1056, gpu_mem=10.07 GB]\n","Valid loss:0.1056\n","Val metric mean prob: 0.1889\n","Best metric at: 0.5172 0.4530  0.7219\n","Cf: [[4637   29]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 12:22:11,250]\u001b[0m Trial 8 finished with value: 0.5172413793103449 and parameters: {'a1': 0.6752797077033628, 'a2': 0.1791797060334395}. Best is trial 3 with value: 0.5202312138728323.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.2669025972514883 0.27382629391412533 0.45927110883438643\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:31<00:00,  1.19s/it, eval_loss=0.0879, gpu_mem=10.07 GB]\n","Valid loss:0.0879\n","Val metric mean prob: 0.2151\n","Best metric at: 0.4898 0.3390  0.7349\n","Cf: [[4618   48]\n"," [  52   48]]\n","\u001b[32m[I 2023-02-24 12:26:52,279]\u001b[0m Trial 9 finished with value: 0.4897959183673469 and parameters: {'a1': 0.2669025972514883, 'a2': 0.27382629391412533}. Best is trial 3 with value: 0.5202312138728323.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.4561712336624775 0.35094144785237463 0.1928873184851479\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:34<00:00,  1.20s/it, eval_loss=0.0976, gpu_mem=10.07 GB]\n","Valid loss:0.0976\n","Val metric mean prob: 0.2026\n","Best metric at: 0.5081 0.4090  0.7309\n","Cf: [[4628   38]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 12:31:36,056]\u001b[0m Trial 10 finished with value: 0.508108108108108 and parameters: {'a1': 0.4561712336624775, 'a2': 0.35094144785237463}. Best is trial 3 with value: 0.5202312138728323.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6876988626090789 0.1763789844093658 0.13592215298155533\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:31<00:00,  1.19s/it, eval_loss=0.1059, gpu_mem=10.07 GB]\n","Valid loss:0.1059\n","Val metric mean prob: 0.1893\n","Best metric at: 0.5198 0.4550  0.7267\n","Cf: [[4635   31]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 12:36:17,163]\u001b[0m Trial 11 finished with value: 0.5197740112994351 and parameters: {'a1': 0.6876988626090789, 'a2': 0.1763789844093658}. Best is trial 3 with value: 0.5202312138728323.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.7283056933387498 0.10900841903423822 0.16268588762701194\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:30<00:00,  1.18s/it, eval_loss=0.1065, gpu_mem=10.07 GB]\n","Valid loss:0.1065\n","Val metric mean prob: 0.1880\n","Best metric at: 0.5169 0.4520  0.7266\n","Cf: [[4634   32]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 12:40:57,251]\u001b[0m Trial 12 finished with value: 0.5168539325842696 and parameters: {'a1': 0.7283056933387498, 'a2': 0.10900841903423822}. Best is trial 3 with value: 0.5202312138728323.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.4638432854542873 0.2315173954009313 0.3046393191447814\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:37<00:00,  1.21s/it, eval_loss=0.0974, gpu_mem=10.07 GB]\n","Valid loss:0.0974\n","Val metric mean prob: 0.1934\n","Best metric at: 0.5081 0.4000  0.7309\n","Cf: [[4628   38]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 12:45:44,604]\u001b[0m Trial 13 finished with value: 0.508108108108108 and parameters: {'a1': 0.4638432854542873, 'a2': 0.2315173954009313}. Best is trial 3 with value: 0.5202312138728323.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.8819066755985823 0.009230384682945465 0.10886293971847227\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:30<00:00,  1.18s/it, eval_loss=0.1089, gpu_mem=10.07 GB]\n","Valid loss:0.1089\n","Val metric mean prob: 0.1970\n","Best metric at: 0.4859 0.4850  0.7114\n","Cf: [[4632   34]\n"," [  57   43]]\n","\u001b[32m[I 2023-02-24 12:50:24,587]\u001b[0m Trial 14 finished with value: 0.48587570621468923 and parameters: {'a1': 0.8819066755985823, 'a2': 0.009230384682945465}. Best is trial 3 with value: 0.5202312138728323.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6196615168494861 0.20957100013457192 0.17076748301594197\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:32<00:00,  1.19s/it, eval_loss=0.1041, gpu_mem=10.07 GB]\n","Valid loss:0.1041\n","Val metric mean prob: 0.1890\n","Best metric at: 0.5087 0.4520  0.7169\n","Cf: [[4637   29]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 12:55:06,530]\u001b[0m Trial 15 finished with value: 0.508670520231214 and parameters: {'a1': 0.6196615168494861, 'a2': 0.20957100013457192}. Best is trial 3 with value: 0.5202312138728323.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.7464410803082124 0.12082818993370192 0.13273072975808564\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:29<00:00,  1.18s/it, eval_loss=0.1070, gpu_mem=10.07 GB]\n","Valid loss:0.1070\n","Val metric mean prob: 0.1899\n","Best metric at: 0.5169 0.4590  0.7266\n","Cf: [[4634   32]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 12:59:45,737]\u001b[0m Trial 16 finished with value: 0.5168539325842696 and parameters: {'a1': 0.7464410803082124, 'a2': 0.12082818993370192}. Best is trial 3 with value: 0.5202312138728323.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.5551085513925993 0.28858937027296483 0.15630207833443588\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:31<00:00,  1.18s/it, eval_loss=0.1019, gpu_mem=10.07 GB]\n","Valid loss:0.1019\n","Val metric mean prob: 0.1942\n","Best metric at: 0.5222 0.4320  0.7315\n","Cf: [[4633   33]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 13:04:26,332]\u001b[0m Trial 17 finished with value: 0.5222222222222221 and parameters: {'a1': 0.5551085513925993, 'a2': 0.28858937027296483}. Best is trial 17 with value: 0.5222222222222221.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.5282118020373872 0.30105242091330753 0.17073577704930532\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:31<00:00,  1.19s/it, eval_loss=0.1008, gpu_mem=10.07 GB]\n","Valid loss:0.1008\n","Val metric mean prob: 0.1957\n","Best metric at: 0.5222 0.4320  0.7315\n","Cf: [[4633   33]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 13:09:07,474]\u001b[0m Trial 18 finished with value: 0.5222222222222221 and parameters: {'a1': 0.5282118020373872, 'a2': 0.30105242091330753}. Best is trial 17 with value: 0.5222222222222221.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.5309916569158131 0.31150839445855893 0.157499948625628\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:29<00:00,  1.18s/it, eval_loss=0.1009, gpu_mem=10.07 GB]\n","Valid loss:0.1009\n","Val metric mean prob: 0.1963\n","Best metric at: 0.5193 0.4310  0.7314\n","Cf: [[4632   34]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 13:13:47,112]\u001b[0m Trial 19 finished with value: 0.5193370165745855 and parameters: {'a1': 0.5309916569158131, 'a2': 0.31150839445855893}. Best is trial 17 with value: 0.5222222222222221.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.39602955584156474 0.5921852237048515 0.011785220453583767\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:33<00:00,  1.20s/it, eval_loss=0.0952, gpu_mem=10.07 GB]\n","Valid loss:0.0952\n","Val metric mean prob: 0.2253\n","Best metric at: 0.4970 0.4560  0.7071\n","Cf: [[4639   27]\n"," [  58   42]]\n","\u001b[32m[I 2023-02-24 13:18:30,677]\u001b[0m Trial 20 finished with value: 0.4970414201183433 and parameters: {'a1': 0.39602955584156474, 'a2': 0.5921852237048515}. Best is trial 17 with value: 0.5222222222222221.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.5748382553337678 0.2225159394968799 0.20264580516935235\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:30<00:00,  1.18s/it, eval_loss=0.1025, gpu_mem=10.07 GB]\n","Valid loss:0.1025\n","Val metric mean prob: 0.1895\n","Best metric at: 0.5111 0.4280  0.7264\n","Cf: [[4632   34]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 13:23:10,991]\u001b[0m Trial 21 finished with value: 0.5111111111111112 and parameters: {'a1': 0.5748382553337678, 'a2': 0.2225159394968799}. Best is trial 17 with value: 0.5222222222222221.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6239622382426943 0.19665564397567842 0.17938211778162733\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:32<00:00,  1.19s/it, eval_loss=0.1042, gpu_mem=10.07 GB]\n","Valid loss:0.1042\n","Val metric mean prob: 0.1883\n","Best metric at: 0.5087 0.4510  0.7169\n","Cf: [[4637   29]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 13:27:53,025]\u001b[0m Trial 22 finished with value: 0.508670520231214 and parameters: {'a1': 0.6239622382426943, 'a2': 0.19665564397567842}. Best is trial 17 with value: 0.5222222222222221.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.4868127805898678 0.29264739789746264 0.2205398215126695\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:30<00:00,  1.18s/it, eval_loss=0.0988, gpu_mem=10.07 GB]\n","Valid loss:0.0988\n","Val metric mean prob: 0.1967\n","Best metric at: 0.5109 0.4170  0.7310\n","Cf: [[4629   37]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 13:32:32,729]\u001b[0m Trial 23 finished with value: 0.5108695652173914 and parameters: {'a1': 0.4868127805898678, 'a2': 0.29264739789746264}. Best is trial 17 with value: 0.5222222222222221.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.7840012236450524 0.08209382449652852 0.13390495185841905\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:32<00:00,  1.19s/it, eval_loss=0.1075, gpu_mem=10.07 GB]\n","Valid loss:0.1075\n","Val metric mean prob: 0.1910\n","Best metric at: 0.4974 0.4500  0.7305\n","Cf: [[4624   42]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 13:37:15,284]\u001b[0m Trial 24 finished with value: 0.4973544973544973 and parameters: {'a1': 0.7840012236450524, 'a2': 0.08209382449652852}. Best is trial 17 with value: 0.5222222222222221.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6471627140262406 0.24676138042650175 0.10607590554725765\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:30<00:00,  1.18s/it, eval_loss=0.1051, gpu_mem=10.07 GB]\n","Valid loss:0.1051\n","Val metric mean prob: 0.1919\n","Best metric at: 0.5172 0.4550  0.7219\n","Cf: [[4637   29]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 13:41:55,211]\u001b[0m Trial 25 finished with value: 0.5172413793103449 and parameters: {'a1': 0.6471627140262406, 'a2': 0.24676138042650175}. Best is trial 17 with value: 0.5222222222222221.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.5418845541150757 0.2170452344460431 0.24107021143888116\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:32<00:00,  1.19s/it, eval_loss=0.1011, gpu_mem=10.07 GB]\n","Valid loss:0.1011\n","Val metric mean prob: 0.1895\n","Best metric at: 0.5165 0.4220  0.7312\n","Cf: [[4631   35]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 13:46:37,831]\u001b[0m Trial 26 finished with value: 0.5164835164835165 and parameters: {'a1': 0.5418845541150757, 'a2': 0.2170452344460431}. Best is trial 17 with value: 0.5222222222222221.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.40100975728992605 0.3454531766082324 0.25353706610184157\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:30<00:00,  1.18s/it, eval_loss=0.0948, gpu_mem=10.07 GB]\n","Valid loss:0.0948\n","Val metric mean prob: 0.2063\n","Best metric at: 0.5029 0.4150  0.7167\n","Cf: [[4635   31]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 13:51:17,932]\u001b[0m Trial 27 finished with value: 0.5028571428571429 and parameters: {'a1': 0.40100975728992605, 'a2': 0.3454531766082324}. Best is trial 17 with value: 0.5222222222222221.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.7055907819654187 0.1984373196832644 0.09597189835131692\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:31<00:00,  1.19s/it, eval_loss=0.1064, gpu_mem=10.07 GB]\n","Valid loss:0.1064\n","Val metric mean prob: 0.1913\n","Best metric at: 0.5227 0.4660  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 13:55:58,996]\u001b[0m Trial 28 finished with value: 0.5227272727272727 and parameters: {'a1': 0.7055907819654187, 'a2': 0.1984373196832644}. Best is trial 28 with value: 0.5227272727272727.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.5827614361189276 0.2543995363721063 0.16283902750896606\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:31<00:00,  1.19s/it, eval_loss=0.1029, gpu_mem=10.07 GB]\n","Valid loss:0.1029\n","Val metric mean prob: 0.1916\n","Best metric at: 0.5111 0.4330  0.7264\n","Cf: [[4632   34]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 14:00:40,498]\u001b[0m Trial 29 finished with value: 0.5111111111111112 and parameters: {'a1': 0.5827614361189276, 'a2': 0.2543995363721063}. Best is trial 28 with value: 0.5227272727272727.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6693802093814523 0.1926514737306175 0.13796831688793024\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:30<00:00,  1.18s/it, eval_loss=0.1055, gpu_mem=10.07 GB]\n","Valid loss:0.1055\n","Val metric mean prob: 0.1894\n","Best metric at: 0.5172 0.4520  0.7219\n","Cf: [[4637   29]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 14:05:20,495]\u001b[0m Trial 30 finished with value: 0.5172413793103449 and parameters: {'a1': 0.6693802093814523, 'a2': 0.1926514737306175}. Best is trial 28 with value: 0.5227272727272727.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.7255632059461911 0.15415804951523257 0.12027874453857637\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:32<00:00,  1.19s/it, eval_loss=0.1067, gpu_mem=10.07 GB]\n","Valid loss:0.1067\n","Val metric mean prob: 0.1901\n","Best metric at: 0.5198 0.4630  0.7267\n","Cf: [[4635   31]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 14:10:02,656]\u001b[0m Trial 31 finished with value: 0.5197740112994351 and parameters: {'a1': 0.7255632059461911, 'a2': 0.15415804951523257}. Best is trial 28 with value: 0.5227272727272727.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.7908258666671129 0.13466510906504978 0.07450902426783737\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:32<00:00,  1.19s/it, eval_loss=0.1079, gpu_mem=10.07 GB]\n","Valid loss:0.1079\n","Val metric mean prob: 0.1937\n","Best metric at: 0.5000 0.4930  0.7072\n","Cf: [[4640   26]\n"," [  58   42]]\n","\u001b[32m[I 2023-02-24 14:14:44,361]\u001b[0m Trial 32 finished with value: 0.5 and parameters: {'a1': 0.7908258666671129, 'a2': 0.13466510906504978}. Best is trial 28 with value: 0.5227272727272727.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.8430048962701027 0.05450574697557872 0.10248935675431861\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:31<00:00,  1.19s/it, eval_loss=0.1084, gpu_mem=10.07 GB]\n","Valid loss:0.1084\n","Val metric mean prob: 0.1950\n","Best metric at: 0.4943 0.4860  0.7117\n","Cf: [[4635   31]\n"," [  57   43]]\n","\u001b[32m[I 2023-02-24 14:19:25,899]\u001b[0m Trial 33 finished with value: 0.49425287356321834 and parameters: {'a1': 0.8430048962701027, 'a2': 0.05450574697557872}. Best is trial 28 with value: 0.5227272727272727.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6236456327508684 0.23326717607670286 0.14308719117242877\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:32<00:00,  1.19s/it, eval_loss=0.1043, gpu_mem=10.07 GB]\n","Valid loss:0.1043\n","Val metric mean prob: 0.1906\n","Best metric at: 0.5114 0.4490  0.7217\n","Cf: [[4635   31]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 14:24:08,192]\u001b[0m Trial 34 finished with value: 0.5113636363636364 and parameters: {'a1': 0.6236456327508684, 'a2': 0.23326717607670286}. Best is trial 28 with value: 0.5227272727272727.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.0014064481955573527 0.39690969715410673 0.6016838546503359\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:33<00:00,  1.20s/it, eval_loss=0.0833, gpu_mem=10.07 GB]\n","Valid loss:0.0833\n","Val metric mean prob: 0.2582\n","Best metric at: 0.4780 0.2860  0.7390\n","Cf: [[4610   56]\n"," [  51   49]]\n","\u001b[32m[I 2023-02-24 14:28:51,565]\u001b[0m Trial 35 finished with value: 0.47804878048780486 and parameters: {'a1': 0.0014064481955573527, 'a2': 0.39690969715410673}. Best is trial 28 with value: 0.5227272727272727.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.5379071130026845 0.2699131557086035 0.19217973128871202\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:33<00:00,  1.19s/it, eval_loss=0.1011, gpu_mem=10.07 GB]\n","Valid loss:0.1011\n","Val metric mean prob: 0.1932\n","Best metric at: 0.5222 0.4300  0.7315\n","Cf: [[4633   33]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 14:33:34,536]\u001b[0m Trial 36 finished with value: 0.5222222222222221 and parameters: {'a1': 0.5379071130026845, 'a2': 0.2699131557086035}. Best is trial 28 with value: 0.5227272727272727.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.512759847300014 0.2613484800396575 0.2258916726603285\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:33<00:00,  1.19s/it, eval_loss=0.0999, gpu_mem=10.07 GB]\n","Valid loss:0.0999\n","Val metric mean prob: 0.1933\n","Best metric at: 0.5137 0.4190  0.7311\n","Cf: [[4630   36]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 14:38:17,223]\u001b[0m Trial 37 finished with value: 0.5136612021857923 and parameters: {'a1': 0.512759847300014, 'a2': 0.2613484800396575}. Best is trial 28 with value: 0.5227272727272727.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.5450842011418318 0.2777881871626844 0.17712761169548386\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:31<00:00,  1.19s/it, eval_loss=0.1015, gpu_mem=10.07 GB]\n","Valid loss:0.1015\n","Val metric mean prob: 0.1936\n","Best metric at: 0.5222 0.4310  0.7315\n","Cf: [[4633   33]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 14:42:58,631]\u001b[0m Trial 38 finished with value: 0.5222222222222221 and parameters: {'a1': 0.5450842011418318, 'a2': 0.2777881871626844}. Best is trial 28 with value: 0.5227272727272727.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.3993034133535204 0.33070532726146706 0.26999125938501256\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:31<00:00,  1.18s/it, eval_loss=0.0946, gpu_mem=10.07 GB]\n","Valid loss:0.0946\n","Val metric mean prob: 0.2054\n","Best metric at: 0.5000 0.4140  0.7166\n","Cf: [[4634   32]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 14:47:39,179]\u001b[0m Trial 39 finished with value: 0.5 and parameters: {'a1': 0.3993034133535204, 'a2': 0.33070532726146706}. Best is trial 28 with value: 0.5227272727272727.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.5947227949367027 0.2373574675755724 0.16791973748772493\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:52<00:00,  1.28s/it, eval_loss=0.1033, gpu_mem=10.07 GB]\n","Valid loss:0.1033\n","Val metric mean prob: 0.1905\n","Best metric at: 0.5085 0.4360  0.7216\n","Cf: [[4634   32]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 14:52:41,637]\u001b[0m Trial 40 finished with value: 0.5084745762711864 and parameters: {'a1': 0.5947227949367027, 'a2': 0.2373574675755724}. Best is trial 28 with value: 0.5227272727272727.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.5460562017603949 0.278730942386057 0.17521285585354807\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:30<00:00,  1.18s/it, eval_loss=0.1015, gpu_mem=10.07 GB]\n","Valid loss:0.1015\n","Val metric mean prob: 0.1937\n","Best metric at: 0.5222 0.4310  0.7315\n","Cf: [[4633   33]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 14:57:21,849]\u001b[0m Trial 41 finished with value: 0.5222222222222221 and parameters: {'a1': 0.5460562017603949, 'a2': 0.278730942386057}. Best is trial 28 with value: 0.5227272727272727.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.49650830311430344 0.29431224471087947 0.20917945217481715\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:33<00:00,  1.19s/it, eval_loss=0.0993, gpu_mem=10.07 GB]\n","Valid loss:0.0993\n","Val metric mean prob: 0.1963\n","Best metric at: 0.5109 0.4200  0.7310\n","Cf: [[4629   37]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 15:02:05,042]\u001b[0m Trial 42 finished with value: 0.5108695652173914 and parameters: {'a1': 0.49650830311430344, 'a2': 0.29431224471087947}. Best is trial 28 with value: 0.5227272727272727.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6505148403805285 0.2598395285854341 0.08964563103403739\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:31<00:00,  1.18s/it, eval_loss=0.1052, gpu_mem=10.07 GB]\n","Valid loss:0.1052\n","Val metric mean prob: 0.1928\n","Best metric at: 0.5257 0.4560  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 15:06:45,580]\u001b[0m Trial 43 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6505148403805285, 'a2': 0.2598395285854341}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6693480876169364 0.24766131233481972 0.08299060004824385\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:31<00:00,  1.19s/it, eval_loss=0.1057, gpu_mem=10.07 GB]\n","Valid loss:0.1057\n","Val metric mean prob: 0.1926\n","Best metric at: 0.5257 0.4610  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 15:11:27,190]\u001b[0m Trial 44 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6693480876169364, 'a2': 0.24766131233481972}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6877619981693374 0.2459043487537935 0.06633365307686914\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:30<00:00,  1.18s/it, eval_loss=0.1061, gpu_mem=10.07 GB]\n","Valid loss:0.1061\n","Val metric mean prob: 0.1932\n","Best metric at: 0.5202 0.4670  0.7220\n","Cf: [[4638   28]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 15:16:07,348]\u001b[0m Trial 45 finished with value: 0.5202312138728323 and parameters: {'a1': 0.6877619981693374, 'a2': 0.2459043487537935}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6405789673570168 0.258377662519918 0.10104337012306519\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:32<00:00,  1.19s/it, eval_loss=0.1049, gpu_mem=10.07 GB]\n","Valid loss:0.1049\n","Val metric mean prob: 0.1925\n","Best metric at: 0.5172 0.4560  0.7219\n","Cf: [[4637   29]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 15:20:49,004]\u001b[0m Trial 46 finished with value: 0.5172413793103449 and parameters: {'a1': 0.6405789673570168, 'a2': 0.258377662519918}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6922359632939046 0.22213533091865906 0.08562870578743637\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:39<00:00,  1.22s/it, eval_loss=0.1062, gpu_mem=10.07 GB]\n","Valid loss:0.1062\n","Val metric mean prob: 0.1920\n","Best metric at: 0.5257 0.4650  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 15:25:38,381]\u001b[0m Trial 47 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6922359632939046, 'a2': 0.22213533091865906}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6975086905386345 0.22281556832545193 0.07967574113591355\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:32<00:00,  1.19s/it, eval_loss=0.1063, gpu_mem=10.07 GB]\n","Valid loss:0.1063\n","Val metric mean prob: 0.1923\n","Best metric at: 0.5202 0.4690  0.7220\n","Cf: [[4638   28]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 15:30:20,124]\u001b[0m Trial 48 finished with value: 0.5202312138728323 and parameters: {'a1': 0.6975086905386345, 'a2': 0.22281556832545193}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.7437491950800323 0.20227839262559313 0.05397241229437452\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:32<00:00,  1.19s/it, eval_loss=0.1072, gpu_mem=10.07 GB]\n","Valid loss:0.1072\n","Val metric mean prob: 0.1936\n","Best metric at: 0.5140 0.4650  0.7265\n","Cf: [[4633   33]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 15:35:02,059]\u001b[0m Trial 49 finished with value: 0.5139664804469275 and parameters: {'a1': 0.7437491950800323, 'a2': 0.20227839262559313}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6671165496236314 0.17538287890649332 0.15750057146987526\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:33<00:00,  1.19s/it, eval_loss=0.1054, gpu_mem=10.07 GB]\n","Valid loss:0.1054\n","Val metric mean prob: 0.1883\n","Best metric at: 0.5146 0.4590  0.7171\n","Cf: [[4639   27]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 15:39:44,753]\u001b[0m Trial 50 finished with value: 0.5146198830409356 and parameters: {'a1': 0.6671165496236314, 'a2': 0.17538287890649332}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.5923270732503344 0.23049043533977773 0.17718249140988787\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:30<00:00,  1.18s/it, eval_loss=0.1032, gpu_mem=10.07 GB]\n","Valid loss:0.1032\n","Val metric mean prob: 0.1900\n","Best metric at: 0.5085 0.4350  0.7216\n","Cf: [[4634   32]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 15:44:25,316]\u001b[0m Trial 51 finished with value: 0.5084745762711864 and parameters: {'a1': 0.5923270732503344, 'a2': 0.23049043533977773}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.7177615561706523 0.20493773436490337 0.07730070946444434\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:30<00:00,  1.18s/it, eval_loss=0.1067, gpu_mem=10.07 GB]\n","Valid loss:0.1067\n","Val metric mean prob: 0.1923\n","Best metric at: 0.5198 0.4670  0.7267\n","Cf: [[4635   31]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 15:49:05,903]\u001b[0m Trial 52 finished with value: 0.5197740112994351 and parameters: {'a1': 0.7177615561706523, 'a2': 0.20493773436490337}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.647734051578119 0.24504483825496334 0.10722111016691763\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:31<00:00,  1.19s/it, eval_loss=0.1051, gpu_mem=10.07 GB]\n","Valid loss:0.1051\n","Val metric mean prob: 0.1918\n","Best metric at: 0.5172 0.4550  0.7219\n","Cf: [[4637   29]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 15:53:46,878]\u001b[0m Trial 53 finished with value: 0.5172413793103449 and parameters: {'a1': 0.647734051578119, 'a2': 0.24504483825496334}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.760007630113453 0.21686166611251861 0.023130703774028427\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:31<00:00,  1.19s/it, eval_loss=0.1076, gpu_mem=10.07 GB]\n","Valid loss:0.1076\n","Val metric mean prob: 0.1953\n","Best metric at: 0.5140 0.4700  0.7265\n","Cf: [[4633   33]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 15:58:28,026]\u001b[0m Trial 54 finished with value: 0.5139664804469275 and parameters: {'a1': 0.760007630113453, 'a2': 0.21686166611251861}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.7000889392292254 0.18824626171778647 0.1116647990529881\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:32<00:00,  1.19s/it, eval_loss=0.1063, gpu_mem=10.07 GB]\n","Valid loss:0.1063\n","Val metric mean prob: 0.1905\n","Best metric at: 0.5202 0.4650  0.7220\n","Cf: [[4638   28]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 16:03:09,943]\u001b[0m Trial 55 finished with value: 0.5202312138728323 and parameters: {'a1': 0.7000889392292254, 'a2': 0.18824626171778647}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6598846198914557 0.16616486633796812 0.17395051377057613\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:32<00:00,  1.19s/it, eval_loss=0.1052, gpu_mem=10.07 GB]\n","Valid loss:0.1052\n","Val metric mean prob: 0.1875\n","Best metric at: 0.5146 0.4560  0.7171\n","Cf: [[4639   27]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 16:07:51,837]\u001b[0m Trial 56 finished with value: 0.5146198830409356 and parameters: {'a1': 0.6598846198914557, 'a2': 0.16616486633796812}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.5944421083737955 0.267153294604393 0.13840459702181146\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:32<00:00,  1.19s/it, eval_loss=0.1034, gpu_mem=10.07 GB]\n","Valid loss:0.1034\n","Val metric mean prob: 0.1925\n","Best metric at: 0.5114 0.4490  0.7217\n","Cf: [[4635   31]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 16:12:34,361]\u001b[0m Trial 57 finished with value: 0.5113636363636364 and parameters: {'a1': 0.5944421083737955, 'a2': 0.267153294604393}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.614396391232961 0.24875109814359703 0.136852510623442\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:30<00:00,  1.18s/it, eval_loss=0.1040, gpu_mem=10.07 GB]\n","Valid loss:0.1040\n","Val metric mean prob: 0.1914\n","Best metric at: 0.5114 0.4500  0.7217\n","Cf: [[4635   31]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 16:17:14,226]\u001b[0m Trial 58 finished with value: 0.5113636363636364 and parameters: {'a1': 0.614396391232961, 'a2': 0.24875109814359703}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.45952459614987257 0.30765833086474537 0.232817072985382\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:33<00:00,  1.19s/it, eval_loss=0.0976, gpu_mem=10.07 GB]\n","Valid loss:0.0976\n","Val metric mean prob: 0.1992\n","Best metric at: 0.5081 0.4050  0.7309\n","Cf: [[4628   38]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 16:21:57,102]\u001b[0m Trial 59 finished with value: 0.508108108108108 and parameters: {'a1': 0.45952459614987257, 'a2': 0.30765833086474537}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.7934416829474679 0.19506322322002773 0.01149509383250441\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:42<00:00,  1.23s/it, eval_loss=0.1081, gpu_mem=10.07 GB]\n","Valid loss:0.1081\n","Val metric mean prob: 0.1964\n","Best metric at: 0.5057 0.4840  0.7168\n","Cf: [[4636   30]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 16:26:49,666]\u001b[0m Trial 60 finished with value: 0.5057471264367815 and parameters: {'a1': 0.7934416829474679, 'a2': 0.19506322322002773}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.5538512749613784 0.2795407273746234 0.1666079976639982\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:32<00:00,  1.19s/it, eval_loss=0.1018, gpu_mem=10.07 GB]\n","Valid loss:0.1018\n","Val metric mean prob: 0.1936\n","Best metric at: 0.5222 0.4310  0.7315\n","Cf: [[4633   33]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 16:31:31,462]\u001b[0m Trial 61 finished with value: 0.5222222222222221 and parameters: {'a1': 0.5538512749613784, 'a2': 0.2795407273746234}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.5777791516019061 0.2566571718498706 0.16556367654822335\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:31<00:00,  1.18s/it, eval_loss=0.1027, gpu_mem=10.07 GB]\n","Valid loss:0.1027\n","Val metric mean prob: 0.1918\n","Best metric at: 0.5193 0.4310  0.7314\n","Cf: [[4632   34]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 16:36:12,492]\u001b[0m Trial 62 finished with value: 0.5193370165745855 and parameters: {'a1': 0.5777791516019061, 'a2': 0.2566571718498706}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.5269106292378893 0.2953356824802656 0.17775368828184507\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:29<00:00,  1.18s/it, eval_loss=0.1007, gpu_mem=10.07 GB]\n","Valid loss:0.1007\n","Val metric mean prob: 0.1953\n","Best metric at: 0.5193 0.4290  0.7314\n","Cf: [[4632   34]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 16:40:52,045]\u001b[0m Trial 63 finished with value: 0.5193370165745855 and parameters: {'a1': 0.5269106292378893, 'a2': 0.2953356824802656}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6237691260536115 0.26843229000469254 0.107798583941696\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:35<00:00,  1.20s/it, eval_loss=0.1044, gpu_mem=10.07 GB]\n","Valid loss:0.1044\n","Val metric mean prob: 0.1928\n","Best metric at: 0.5114 0.4540  0.7217\n","Cf: [[4635   31]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 16:45:41,216]\u001b[0m Trial 64 finished with value: 0.5113636363636364 and parameters: {'a1': 0.6237691260536115, 'a2': 0.26843229000469254}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.7103513015770109 0.23945120568087938 0.050197492742109745\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:32<00:00,  1.19s/it, eval_loss=0.1066, gpu_mem=10.07 GB]\n","Valid loss:0.1066\n","Val metric mean prob: 0.1938\n","Best metric at: 0.5233 0.4740  0.7221\n","Cf: [[4639   27]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 16:50:23,910]\u001b[0m Trial 65 finished with value: 0.5232558139534884 and parameters: {'a1': 0.7103513015770109, 'a2': 0.23945120568087938}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6951566150602201 0.20605079130927284 0.09879259363050708\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:32<00:00,  1.19s/it, eval_loss=0.1062, gpu_mem=10.07 GB]\n","Valid loss:0.1062\n","Val metric mean prob: 0.1913\n","Best metric at: 0.5257 0.4650  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 16:55:05,856]\u001b[0m Trial 66 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6951566150602201, 'a2': 0.20605079130927284}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6936792793128596 0.20663391497307698 0.09968680571406346\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:32<00:00,  1.19s/it, eval_loss=0.1062, gpu_mem=10.07 GB]\n","Valid loss:0.1062\n","Val metric mean prob: 0.1912\n","Best metric at: 0.5257 0.4640  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 16:59:48,272]\u001b[0m Trial 67 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6936792793128596, 'a2': 0.20663391497307698}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.7115773841828898 0.20985256511032346 0.07857005070678669\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:35<00:00,  1.20s/it, eval_loss=0.1066, gpu_mem=10.07 GB]\n","Valid loss:0.1066\n","Val metric mean prob: 0.1923\n","Best metric at: 0.5172 0.4700  0.7219\n","Cf: [[4637   29]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 17:04:33,205]\u001b[0m Trial 68 finished with value: 0.5172413793103449 and parameters: {'a1': 0.7115773841828898, 'a2': 0.20985256511032346}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.7392915716302465 0.18653772861868845 0.07417069975106505\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:37<00:00,  1.21s/it, eval_loss=0.1071, gpu_mem=10.07 GB]\n","Valid loss:0.1071\n","Val metric mean prob: 0.1926\n","Best metric at: 0.5169 0.4650  0.7266\n","Cf: [[4634   32]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 17:09:20,325]\u001b[0m Trial 69 finished with value: 0.5168539325842696 and parameters: {'a1': 0.7392915716302465, 'a2': 0.18653772861868845}. Best is trial 43 with value: 0.5257142857142858.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6786585254981048 0.22280913149668852 0.09853234300520669\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:32<00:00,  1.19s/it, eval_loss=0.1059, gpu_mem=10.07 GB]\n","Valid loss:0.1059\n","Val metric mean prob: 0.1915\n","Best metric at: 0.5287 0.4630  0.7270\n","Cf: [[4638   28]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 17:14:05,247]\u001b[0m Trial 70 finished with value: 0.5287356321839081 and parameters: {'a1': 0.6786585254981048, 'a2': 0.22280913149668852}. Best is trial 70 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6705983639667862 0.22385102102901 0.10555061500420382\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:31<00:00,  1.18s/it, eval_loss=0.1057, gpu_mem=10.07 GB]\n","Valid loss:0.1057\n","Val metric mean prob: 0.1913\n","Best metric at: 0.5257 0.4560  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 17:18:46,094]\u001b[0m Trial 71 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6705983639667862, 'a2': 0.22385102102901}. Best is trial 70 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6734655243014309 0.22113143663022528 0.1054030390683438\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:33<00:00,  1.19s/it, eval_loss=0.1057, gpu_mem=10.07 GB]\n","Valid loss:0.1057\n","Val metric mean prob: 0.1912\n","Best metric at: 0.5257 0.4570  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 17:23:29,262]\u001b[0m Trial 72 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6734655243014309, 'a2': 0.22113143663022528}. Best is trial 70 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6860347518671207 0.22612909316086924 0.08783615497201006\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:38<00:00,  1.21s/it, eval_loss=0.1061, gpu_mem=10.07 GB]\n","Valid loss:0.1061\n","Val metric mean prob: 0.1920\n","Best metric at: 0.5257 0.4620  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 17:28:16,982]\u001b[0m Trial 73 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6860347518671207, 'a2': 0.22612909316086924}. Best is trial 70 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.7632382441318543 0.21338728641101648 0.02337446945712926\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:30<00:00,  1.18s/it, eval_loss=0.1076, gpu_mem=10.07 GB]\n","Valid loss:0.1076\n","Val metric mean prob: 0.1953\n","Best metric at: 0.5140 0.4700  0.7265\n","Cf: [[4633   33]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 17:32:56,927]\u001b[0m Trial 74 finished with value: 0.5139664804469275 and parameters: {'a1': 0.7632382441318543, 'a2': 0.21338728641101648}. Best is trial 70 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6695965909361217 0.2211438645474582 0.10925954451642012\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:31<00:00,  1.18s/it, eval_loss=0.1056, gpu_mem=10.07 GB]\n","Valid loss:0.1056\n","Val metric mean prob: 0.1911\n","Best metric at: 0.5257 0.4560  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 17:37:39,087]\u001b[0m Trial 75 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6695965909361217, 'a2': 0.2211438645474582}. Best is trial 70 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6471893751129021 0.2315300063824695 0.1212806185046284\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:31<00:00,  1.18s/it, eval_loss=0.1050, gpu_mem=10.07 GB]\n","Valid loss:0.1050\n","Val metric mean prob: 0.1910\n","Best metric at: 0.5202 0.4570  0.7220\n","Cf: [[4638   28]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 17:42:19,887]\u001b[0m Trial 76 finished with value: 0.5202312138728323 and parameters: {'a1': 0.6471893751129021, 'a2': 0.2315300063824695}. Best is trial 70 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.7303381570149872 0.20543183755511837 0.06423000542989446\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:32<00:00,  1.19s/it, eval_loss=0.1070, gpu_mem=10.07 GB]\n","Valid loss:0.1070\n","Val metric mean prob: 0.1930\n","Best metric at: 0.5169 0.4660  0.7266\n","Cf: [[4634   32]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 17:47:01,673]\u001b[0m Trial 77 finished with value: 0.5168539325842696 and parameters: {'a1': 0.7303381570149872, 'a2': 0.20543183755511837}. Best is trial 70 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.8165988243392046 0.17568207630538432 0.007719099355411069\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:33<00:00,  1.19s/it, eval_loss=0.1085, gpu_mem=10.07 GB]\n","Valid loss:0.1085\n","Val metric mean prob: 0.1972\n","Best metric at: 0.5116 0.4930  0.7170\n","Cf: [[4638   28]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 17:51:44,420]\u001b[0m Trial 78 finished with value: 0.5116279069767442 and parameters: {'a1': 0.8165988243392046, 'a2': 0.17568207630538432}. Best is trial 70 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.7542348914221061 0.2129262811914434 0.0328388273864505\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:35<00:00,  1.20s/it, eval_loss=0.1074, gpu_mem=10.07 GB]\n","Valid loss:0.1074\n","Val metric mean prob: 0.1948\n","Best metric at: 0.5137 0.4660  0.7311\n","Cf: [[4630   36]\n"," [  53   47]]\n","\u001b[32m[I 2023-02-24 17:56:29,116]\u001b[0m Trial 79 finished with value: 0.5136612021857923 and parameters: {'a1': 0.7542348914221061, 'a2': 0.2129262811914434}. Best is trial 70 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6830380634256324 0.238054124167146 0.07890781240722156\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:30<00:00,  1.18s/it, eval_loss=0.1060, gpu_mem=10.07 GB]\n","Valid loss:0.1060\n","Val metric mean prob: 0.1925\n","Best metric at: 0.5257 0.4630  0.7269\n","Cf: [[4637   29]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 18:01:09,645]\u001b[0m Trial 80 finished with value: 0.5257142857142858 and parameters: {'a1': 0.6830380634256324, 'a2': 0.238054124167146}. Best is trial 70 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6833108468963346 0.22123699111803405 0.09545216198563136\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:34<00:00,  1.20s/it, eval_loss=0.1060, gpu_mem=10.07 GB]\n","Valid loss:0.1060\n","Val metric mean prob: 0.1916\n","Best metric at: 0.5287 0.4640  0.7270\n","Cf: [[4638   28]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 18:05:56,494]\u001b[0m Trial 81 finished with value: 0.5287356321839081 and parameters: {'a1': 0.6833108468963346, 'a2': 0.22123699111803405}. Best is trial 70 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.641441144874789 0.22315810154567028 0.13540075357954073\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:30<00:00,  1.18s/it, eval_loss=0.1048, gpu_mem=10.07 GB]\n","Valid loss:0.1048\n","Val metric mean prob: 0.1903\n","Best metric at: 0.5116 0.4580  0.7170\n","Cf: [[4638   28]\n"," [  56   44]]\n","\u001b[32m[I 2023-02-24 18:10:37,000]\u001b[0m Trial 82 finished with value: 0.5116279069767442 and parameters: {'a1': 0.641441144874789, 'a2': 0.22315810154567028}. Best is trial 70 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.6131105903689924 0.2006865095373842 0.1862029000936234\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:30<00:00,  1.18s/it, eval_loss=0.1038, gpu_mem=10.07 GB]\n","Valid loss:0.1038\n","Val metric mean prob: 0.1883\n","Best metric at: 0.5111 0.4330  0.7264\n","Cf: [[4632   34]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 18:15:16,936]\u001b[0m Trial 83 finished with value: 0.5111111111111112 and parameters: {'a1': 0.6131105903689924, 'a2': 0.2006865095373842}. Best is trial 70 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.67403053499327 0.22792082840567637 0.09804863660105359\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:30<00:00,  1.18s/it, eval_loss=0.1058, gpu_mem=10.07 GB]\n","Valid loss:0.1058\n","Val metric mean prob: 0.1916\n","Best metric at: 0.5287 0.4620  0.7270\n","Cf: [[4638   28]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 18:19:59,895]\u001b[0m Trial 84 finished with value: 0.5287356321839081 and parameters: {'a1': 0.67403053499327, 'a2': 0.22792082840567637}. Best is trial 70 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.7174705750469376 0.22753387083788884 0.054995554115173595\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:31<00:00,  1.18s/it, eval_loss=0.1068, gpu_mem=10.07 GB]\n","Valid loss:0.1068\n","Val metric mean prob: 0.1935\n","Best metric at: 0.5202 0.4750  0.7220\n","Cf: [[4638   28]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 18:24:40,773]\u001b[0m Trial 85 finished with value: 0.5202312138728323 and parameters: {'a1': 0.7174705750469376, 'a2': 0.22753387083788884}. Best is trial 70 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.7767451641304511 0.20863445211527876 0.014620383754270105\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:34<00:00,  1.20s/it, eval_loss=0.1078, gpu_mem=10.07 GB]\n","Valid loss:0.1078\n","Val metric mean prob: 0.1959\n","Best metric at: 0.5085 0.4790  0.7216\n","Cf: [[4634   32]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 18:29:25,681]\u001b[0m Trial 86 finished with value: 0.5084745762711864 and parameters: {'a1': 0.7767451641304511, 'a2': 0.20863445211527876}. Best is trial 70 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.658738691333155 0.24011797557725215 0.10114333308959286\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:29<00:00,  1.18s/it, eval_loss=0.1054, gpu_mem=10.07 GB]\n","Valid loss:0.1054\n","Val metric mean prob: 0.1918\n","Best metric at: 0.5227 0.4550  0.7268\n","Cf: [[4636   30]\n"," [  54   46]]\n","\u001b[32m[I 2023-02-24 18:34:04,905]\u001b[0m Trial 87 finished with value: 0.5227272727272727 and parameters: {'a1': 0.658738691333155, 'a2': 0.24011797557725215}. Best is trial 70 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.7358701384694011 0.21655081307434443 0.04757904845625449\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 229/229 [04:30<00:00,  1.18s/it, eval_loss=0.1071, gpu_mem=10.07 GB]\n","Valid loss:0.1071\n","Val metric mean prob: 0.1939\n","Best metric at: 0.5172 0.4790  0.7219\n","Cf: [[4637   29]\n"," [  55   45]]\n","\u001b[32m[I 2023-02-24 18:38:45,235]\u001b[0m Trial 88 finished with value: 0.5172413793103449 and parameters: {'a1': 0.7358701384694011, 'a2': 0.21655081307434443}. Best is trial 70 with value: 0.5287356321839081.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth\n","noob fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth\n","0.7047040731686101 0.2335462007025167 0.06174972612887325\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val:  70%|   | 161/229 [03:29<01:23,  1.23s/it, eval_loss=0.1046, gpu_mem=10.07 GB]"]}],"source":["\n","set_seed(1)\n","out_file = 'swa_model_fold0_5.pth' \n","iteration = [\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth',\n","    'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth',\n","    'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth',\n","    'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth',\n","    \n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth',\n","    \n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_8_0.4403_0.415.pth',\n","#     'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_11_0.4387_0.436.pth'\n","]\n","\n","criterion = nn.CrossEntropyLoss().to(CFG.device)\n","best_metric = 0\n","torch.cuda.empty_cache()\n","def objective(trial):\n","#     a1 = 0.036839841333967636 \n","#     a2 = 0.6490629183820655\n","#     a3 = 0.3140972402839668\n","#     a2 = 0.47142151346976024 \n","#     a3 = 0.3596277792186039\n","#     a1 = trial.suggest_uniform('a1', 0.01, 0.99)\n","#     a2 = 1-a1\n","    a1 = trial.suggest_uniform('a1', 0.001, 0.99)\n","    # a2 = 1-a1\n","    a2 = trial.suggest_uniform('a2', 0.0009, 1-a1-0.001)\n","    a3 = 1-a1-a2\n","    # a3 = trial.suggest_uniform('a3', 0.00009, 1-a1-a2-0.001)\n","    # a4 = 1-a1-a2-a3\n","    # a4 = trial.suggest_loguniform('a4', 0.000009, 1-a1-a2-a3-0.001)\n","    # a5 = 1-a1-a2-a3-a4\n","    # a5 = trial.suggest_loguniform('a5', 0.0000009, 1-a1-a2-a3-a4-0.001)\n","    # a6 = 1-a1-a2-a3-a4-a5\n","#     a5 = trial.suggest_loguniform('a5', 0.000009, 1-a1-a2-a3-a4-0.001)\n","#     a6 = trial.suggest_loguniform('a6', 0.0000009, 1-a1-a2-a3-a4-a5-0.001)\n","#     a7 = 1-a1-a2-a3-a4-a5-a6\n","    state_dict = None\n","    for i in iteration:\n","        f = i\n","        f = torch.load(f, map_location=lambda storage, loc: storage)\n","        if state_dict is None:\n","            print(\"none: \", i)\n","            state_dict = f['state_dict']\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = f['state_dict'][k]*a1\n","        elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth':\n","            print(\"noob\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a2*f['state_dict'][k]\n","        elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth':\n","            print(\"noob\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a3*f['state_dict'][k]\n","                \n","        # elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth':\n","        #     print(\"noob\", i)\n","        #     key = list(f['state_dict'].keys())\n","        #     for k in key:\n","        #         state_dict[k] = state_dict[k] + a4*f['state_dict'][k]\n","        # elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth':\n","        #     print(\"noob\", i)\n","        #     key = list(f['state_dict'].keys())\n","        #     for k in key:\n","        #         state_dict[k] = state_dict[k] + a5*f['state_dict'][k]\n","        # elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth':\n","        #     print(\"noob\", i)\n","        #     key = list(f['state_dict'].keys())\n","        #     for k in key:\n","        #         state_dict[k] = state_dict[k] + a6*f['state_dict'][k]\n","    print(a1, a2, a3)\n","    # for k in key:\n","    #     state_dict[k] = state_dict[k] / len(iteration)\n","    print('')\n","\n","    # print(out_file)\n","    torch.save({'state_dict': state_dict}, out_file)\n","\n","    model = Model(model_name=CFG.model_name).to(CFG.device)\n","    checkpoint = torch.load(\"swa_model_fold0_5.pth\")\n","    model.load_state_dict(checkpoint['state_dict'])\n","#     model = nn.DataParallel(model)\n","\n","    loss_valid, valid_preds, _ = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","    valid_preds = valid_preds[:, 1]\n","    valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n","    valid_preds = np.array(valid_preds).flatten()\n","    \n","    valid_df['raw_pred'] = valid_preds\n","    LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n","    grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n","    grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n","    valid_labels_mean = grp_df['cancer'].values\n","    valid_preds_mean = grp_df['raw_pred'].values\n","    # print(valid_labels[:5], valid_preds_mean[:5])\n","    val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n","    LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n","    best_metric_mean_at_epoch = 0\n","    best_metric = 0\n","    \n","    best_threshold_mean = 0\n","    best_auc = 0\n","    best_cf = None\n","    for i in np.arange(0.001, 0.599, 0.001):\n","        valid_argmax = (valid_preds_mean>i).astype(np.int32)\n","        val_metric = pfbeta_np(valid_labels_mean, valid_argmax)\n","        val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n","        val_f1 = f1_score(valid_labels_mean, valid_argmax)\n","        val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n","        cf = confusion_matrix(valid_labels_mean, valid_argmax)\n","        if val_metric> best_metric:\n","            best_metric = val_metric\n","            # best_metric_mean_at_epoch = val_metric\n","            best_threshold_mean = i\n","            best_auc = val_auc\n","            best_cf = cf\n","    if best_metric>0.5269:\n","        state = {'state_dict': model.state_dict()}\n","        path = f'swa_{CFG.model_name}_fold_{fold}_model_{best_metric:.4f}_{best_threshold_mean:.4f}.pth'\n","        torch.save(state, path)\n","    \n","    LOGGER.info(f\"Best metric at: {best_metric:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n","    LOGGER.info(f\"Cf: {best_cf}\")\n","    return best_metric\n","\n","study = optuna.create_study(direction='maximize', sampler = TPESampler(seed=777))\n","study.optimize(func=objective, n_trials=1000)\n","study.best_params\n","# # 0.5563409550491111 0.4436590449508889 fold 0\n","# # 0.12634002523631388 0.8351954705276587 0.03846450423602743 0.5393 \n","# # 0.583301614081906 0.3673525472043472 0.04934583871374687 fold 2 0.50\n","# # 0.1689507073116359 0.47142151346976024 0.3596277792186039 fold 2 0.5055 0.5055 0.3670  0.7261"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'tungenv' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n tungenv ipykernel --update-deps --force-reinstall'"]}],"source":["def pfbeta_np(labels, preds, beta=1):\n","    preds = preds.clip(0, 1)\n","    y_true_count = labels.sum()\n","    ctp = preds[labels==1].sum()\n","    cfp = preds[labels==0].sum()\n","    beta_squared = beta * beta\n","    c_precision = ctp / (ctp + cfp)\n","    c_recall = ctp / y_true_count\n","    if (c_precision > 0 and c_recall > 0):\n","        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n","        return result\n","    else:\n","        return 0.0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'tungenv' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n tungenv ipykernel --update-deps --force-reinstall'"]}],"source":["def pfbeta_np(labels, preds, beta=1):\n","    preds = preds.clip(0, 1)\n","    y_true_count = labels.sum()\n","    ctp = preds[labels==1].sum()\n","    cfp = preds[labels==0].sum()\n","    beta_squared = beta * beta\n","    c_precision = ctp / (ctp + cfp)\n","    c_recall = ctp / y_true_count\n","    if (c_precision > 0 and c_recall > 0):\n","        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n","        return result\n","    else:\n","        return 0.0\n","# fold=3\n","# valid_df = df[df['fold']==fold].reset_index(drop=True)\n","# valid_dataset = BreastDataset(valid_df, transforms=data_transforms['valid'])\n","\n","valid_loader = DataLoader(valid_dataset, batch_size = CFG.valid_bs, \n","                                num_workers=1, shuffle=False, drop_last=False)\n","set_seed(1)\n","out_file = 'swa_model_fold2_5.pth' \n","iteration = [\n","    'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4670_0.406.pth',\n","    'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth',\n","    'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_9_0.4681_0.319.pth',\n","    \n","    'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4585_0.236.pth',\n","    'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4557_0.241.pth',\n","    'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_10_0.4550_0.245.pth',\n","]\n","\n","criterion = nn.CrossEntropyLoss().to(CFG.device)\n","best_metric = 0\n","torch.cuda.empty_cache()\n","def objective(trial):\n","#     a2 = 0.12003546043452194 \n","#     a3 = 0.8649578775769542\n","#     a1 = 0.020317850755860567 \n","#     a2 = 0.1293785181217534 \n","#     a3 = 0.850303631122386\n","    # a1 = 0.2\n","    # a2 = 0.2    \n","    # a3 = 0.2\n","    # a4 = 0.2\n","    # a5 = 0.2\n","    # a1 = 1\n","    a1 = trial.suggest_uniform('a1', 0.001, 0.99)\n","    a2 = trial.suggest_uniform('a2', 0.0009, 1-a1-0.001)\n","    # a3 = 1-a1-a2\n","    a3 = trial.suggest_uniform('a3', 0.0009, 1-a1-a2-0.001)\n","    # a4 = 1-a1-a2-a3\n","    a4 = trial.suggest_loguniform('a4', 0.0009, 1-a1-a2-a3-0.001)\n","    # a5 = 1-a1-a2-a3-a4\n","    a5 = trial.suggest_loguniform('a5', 0.00009, 1-a1-a2-a3-a4-0.001)\n","    a6 = 1-a1-a2-a3-a4-a5\n","    # a4 = 1-a1-a2-a3\n","    # a1 = 0.4700450486328235 \n","    # a2 = 0.23862687145742947 \n","    # a3 = 0.2913280799097471\n","    state_dict = None\n","    for i in iteration:\n","        f = i\n","        # print(f)\n","        f = torch.load(f, map_location=lambda storage, loc: storage)\n","        if state_dict is None:\n","            print(\"none: \", i)\n","            state_dict = f['state_dict']\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = f['state_dict'][k]*a1\n","        elif i=='fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4746_0.314.pth': \n","            print(\"hehe\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a2*f['state_dict'][k]\n","        elif i=='fold2/tf_efficientnetv2_b2_fold_2_model_epoch_9_0.4681_0.319.pth': \n","            print(\"hehe\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a3*f['state_dict'][k]\n","        elif i=='fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4585_0.236.pth':\n","            print(\"noob\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a4*f['state_dict'][k]\n","        elif i=='fold2/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4557_0.241.pth':\n","            print(\"noobie\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a5*f['state_dict'][k]\n","        elif i=='fold2/tf_efficientnetv2_b2_fold_2_model_epoch_10_0.4550_0.245.pth':\n","            print(\"noobie\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a6*f['state_dict'][k]\n","    print(a1, a2, a3, a4, a5, a6)\n","    # for k in key:\n","    #     state_dict[k] = state_dict[k] / len(iteration)\n","    print('')\n","\n","    # print(out_file)\n","    torch.save({'state_dict': state_dict}, out_file)\n","\n","    model = Model(model_name=CFG.model_name).to(CFG.device)\n","    checkpoint = torch.load(\"swa_model_fold2_5.pth\")\n","    model.load_state_dict(checkpoint['state_dict'])\n","#     model = nn.DataParallel(model)\n","\n","    loss_valid, valid_preds, _ = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","    valid_preds = valid_preds[:, 1]\n","    valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n","    valid_preds = np.array(valid_preds).flatten()\n","    \n","    valid_df['raw_pred'] = valid_preds\n","    LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n","    grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n","    grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n","    valid_labels_mean = grp_df['cancer'].values\n","    valid_preds_mean = grp_df['raw_pred'].values\n","    # print(valid_labels[:5], valid_preds_mean[:5])\n","    val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n","    LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n","    best_metric_mean_at_epoch = 0\n","    best_metric = 0\n","    \n","    best_threshold_mean = 0\n","    best_auc = 0\n","    best_cf = None\n","    for i in np.arange(0.001, 0.599, 0.001):\n","        valid_argmax = (valid_preds_mean>i).astype(np.int32)\n","        val_metric = pfbeta_np(valid_labels_mean, valid_argmax)\n","        val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n","        val_f1 = f1_score(valid_labels_mean, valid_argmax)\n","        val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n","        cf = confusion_matrix(valid_labels_mean, valid_argmax)\n","        if val_metric> best_metric:\n","            best_metric = val_metric\n","            # best_metric_mean_at_epoch = val_metric\n","            best_threshold_mean = i\n","            best_auc = val_auc\n","            best_cf = cf\n","    if best_metric>0.52:\n","        state = {'state_dict': model.state_dict()}\n","        path = f'swa_{CFG.model_name}_fold_{fold}_model_{best_metric:.4f}_{best_threshold_mean:.3f}.pth'\n","        torch.save(state, path)\n","    \n","    LOGGER.info(f\"Best metric at: {best_metric:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n","    LOGGER.info(f\"Cf: {best_cf}\")\n","    torch.cuda.empty_cache()\n","    return best_metric\n","\n","study = optuna.create_study(direction='maximize', sampler = TPESampler(seed=777))\n","study.optimize(func=objective, n_trials=200)\n","study.best_params"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'tungenv' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n tungenv ipykernel --update-deps --force-reinstall'"]}],"source":["\n","set_seed(1)\n","out_file = 'swa_model_fold0_5.pth' \n","iteration = [\n","    'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_3_0.4945_0.488.pth',\n","    'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth',\n","    'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth',\n","    \n","    'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth',\n","    'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth',\n","    'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_8_0.4403_0.415.pth',\n","#     'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_11_0.4387_0.436.pth'\n","]\n","\n","criterion = nn.CrossEntropyLoss().to(CFG.device)\n","best_metric = 0\n","torch.cuda.empty_cache()\n","def objective(trial):\n","#     a1 = 0.036839841333967636 \n","#     a2 = 0.6490629183820655\n","#     a3 = 0.3140972402839668\n","#     a2 = 0.47142151346976024 \n","#     a3 = 0.3596277792186039\n","#     a1 = trial.suggest_uniform('a1', 0.01, 0.99)\n","#     a2 = 1-a1\n","    a1 = trial.suggest_uniform('a1', 0.001, 0.99)\n","    a2 = trial.suggest_uniform('a2', 0.0009, 1-a1-0.001)\n","    a3 = trial.suggest_uniform('a3', 0.00009, 1-a1-a2-0.001)\n","    # a4 = 1-a1-a2-a3\n","    a4 = trial.suggest_loguniform('a4', 0.000009, 1-a1-a2-a3-0.001)\n","    # a5 = 1-a1-a2-a3-a4\n","    a5 = trial.suggest_loguniform('a5', 0.0000009, 1-a1-a2-a3-a4-0.001)\n","    a6 = 1-a1-a2-a3-a4-a5\n","#     a5 = trial.suggest_loguniform('a5', 0.000009, 1-a1-a2-a3-a4-0.001)\n","#     a6 = trial.suggest_loguniform('a6', 0.0000009, 1-a1-a2-a3-a4-a5-0.001)\n","#     a7 = 1-a1-a2-a3-a4-a5-a6\n","    state_dict = None\n","    for i in iteration:\n","        f = i\n","        f = torch.load(f, map_location=lambda storage, loc: storage)\n","        if state_dict is None:\n","            print(\"none: \", i)\n","            state_dict = f['state_dict']\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = f['state_dict'][k]*a1\n","        elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth': \n","            print(\"hehe\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a2*f['state_dict'][k]\n","        elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth':\n","            print(\"noob\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a3*f['state_dict'][k]\n","        elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth':\n","            print(\"noob\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a4*f['state_dict'][k]\n","                \n","        elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth':\n","            print(\"noob\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a5*f['state_dict'][k]\n","        elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth':\n","            print(\"noob\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a6*f['state_dict'][k]\n","#         elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_11_0.4387_0.436.pth':\n","#             print(\"noob\", i)\n","#             key = list(f['state_dict'].keys())\n","#             for k in key:\n","#                 state_dict[k] = state_dict[k] + a5*f['state_dict'][k]\n","    print(a1, a2, a3, a4, a5)\n","    # for k in key:\n","    #     state_dict[k] = state_dict[k] / len(iteration)\n","    print('')\n","\n","    # print(out_file)\n","    torch.save({'state_dict': state_dict}, out_file)\n","\n","    model = Model(model_name=CFG.model_name).to(CFG.device)\n","    checkpoint = torch.load(\"swa_model_fold0_5.pth\")\n","    model.load_state_dict(checkpoint['state_dict'])\n","#     model = nn.DataParallel(model)\n","\n","    loss_valid, valid_preds, _ = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","    valid_preds = valid_preds[:, 1]\n","    valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n","    valid_preds = np.array(valid_preds).flatten()\n","    \n","    valid_df['raw_pred'] = valid_preds\n","    LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n","    grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n","    grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n","    valid_labels_mean = grp_df['cancer'].values\n","    valid_preds_mean = grp_df['raw_pred'].values\n","    # print(valid_labels[:5], valid_preds_mean[:5])\n","    val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n","    LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n","    best_metric_mean_at_epoch = 0\n","    best_metric = 0\n","    \n","    best_threshold_mean = 0\n","    best_auc = 0\n","    best_cf = None\n","    for i in np.arange(0.001, 0.599, 0.001):\n","        valid_argmax = (valid_preds_mean>i).astype(np.int32)\n","        val_metric = pfbeta_np(valid_labels_mean, valid_argmax)\n","        val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n","        val_f1 = f1_score(valid_labels_mean, valid_argmax)\n","        val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n","        cf = confusion_matrix(valid_labels_mean, valid_argmax)\n","        if val_metric> best_metric:\n","            best_metric = val_metric\n","            # best_metric_mean_at_epoch = val_metric\n","            best_threshold_mean = i\n","            best_auc = val_auc\n","            best_cf = cf\n","    if best_metric>0.52:\n","        state = {'state_dict': model.state_dict()}\n","        path = f'swa_{CFG.model_name}_fold_{fold}_model_{best_metric:.4f}_{best_threshold_mean:.4f}.pth'\n","        torch.save(state, path)\n","    \n","    LOGGER.info(f\"Best metric at: {best_metric:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n","    LOGGER.info(f\"Cf: {best_cf}\")\n","    return best_metric\n","\n","study = optuna.create_study(direction='maximize', sampler = TPESampler(seed=777))\n","study.optimize(func=objective, n_trials=100)\n","study.best_params\n","# # 0.5563409550491111 0.4436590449508889 fold 0\n","# # 0.12634002523631388 0.8351954705276587 0.03846450423602743 0.5393 \n","# # 0.583301614081906 0.3673525472043472 0.04934583871374687 fold 2 0.50\n","# # 0.1689507073116359 0.47142151346976024 0.3596277792186039 fold 2 0.5055 0.5055 0.3670  0.7261"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'tungenv' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n tungenv ipykernel --update-deps --force-reinstall'"]}],"source":["set_seed(1)\n","out_file = 'swa_model_fold1_5.pth' \n","iteration = [\n","    'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth',\n","    'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4569_0.264.pth',\n","    'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4530_0.274.pth',\n","    'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4444_0.409.pth',\n","    'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth',\n","    'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4430_0.474.pth',\n","    'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4403_0.422.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4403_0.422.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth',\n","]\n","def pfbeta_np(labels, preds, beta=1):\n","    preds = preds.clip(0, 1)\n","    y_true_count = labels.sum()\n","    ctp = preds[labels==1].sum()\n","    cfp = preds[labels==0].sum()\n","    beta_squared = beta * beta\n","    c_precision = ctp / (ctp + cfp)\n","    c_recall = ctp / y_true_count\n","    if (c_precision > 0 and c_recall > 0):\n","        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n","        return result\n","    else:\n","        return 0.0\n","criterion = nn.CrossEntropyLoss().to(CFG.device)\n","best_metric = 0\n","torch.cuda.empty_cache()\n","def objective(trial):\n","#     a1 = 0.036839841333967636 \n","#     a2 = 0.6490629183820655\n","#     a3 = 0.3140972402839668\n","#     a2 = 0.47142151346976024 \n","#     a3 = 0.3596277792186039\n","#     a1 = trial.suggest_uniform('a1', 0.01, 0.99)\n","#     a2 = 1-a1\n","    a1 = trial.suggest_uniform('a1', 0.001, 0.99)\n","    a2 = trial.suggest_uniform('a2', 0.0009, 1-a1-0.001)\n","    a3 = trial.suggest_uniform('a3', 0.0009, 1-a1-a2-0.001)\n","    a4 = trial.suggest_loguniform('a4', 0.0009, 1-a1-a2-a3-0.001)\n","    a5 = trial.suggest_loguniform('a5', 0.0009, 1-a1-a2-a3-0.001)\n","    a6 = trial.suggest_loguniform('a6', 0.0009, 1-a1-a2-a3-0.001)\n","    a7 = 1-a1-a2-a3-a4-a5-a6\n","    # a1 = trial.suggest_uniform('a1', 0.001, 0.99)\n","    # a2 = trial.suggest_uniform('a2', 0.0009, 1-a1)\n","    # a3 = trial.suggest_uniform('a3', 0.0007, 1-a1-a2)\n","    # a4 = trial.suggest_loguniform('a4', 0.0005, 1-a1-a2-a3)\n","    # a5 = trial.suggest_loguniform('a5', 0.00003, 1-a1-a2-a3-a4)\n","    # a6 = trial.suggest_loguniform('a6', 0.00009, 1-a1-a2-a3-a4-a5)\n","    # a7 = 1-a1-a2-a3-a4-a5-a6\n","    state_dict = None\n","    for i in iteration:\n","        f = i\n","        f = torch.load(f, map_location=lambda storage, loc: storage)\n","        if state_dict is None:\n","            print(\"none: \", i)\n","            state_dict = f['state_dict']\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = f['state_dict'][k]*a1\n","        elif i== 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4569_0.264.pth': \n","            print(\"hehe\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a2*f['state_dict'][k]\n","        elif i=='fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4530_0.274.pth':\n","            print(\"noob\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a3*f['state_dict'][k]\n","        elif i=='fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4444_0.409.pth':\n","            print(\"noob\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a4*f['state_dict'][k]\n","                \n","        elif i=='fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth':\n","            print(\"noob\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a5*f['state_dict'][k]\n","                \n","        elif i=='fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4430_0.474.pth': \n","            print(\"hehe\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a6*f['state_dict'][k]\n","        elif i=='fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4403_0.422.pth': \n","            print(\"hehe\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a7*f['state_dict'][k]        \n","        # elif i=='fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth': \n","        #     print(\"hehe\", i)\n","        #     key = list(f['state_dict'].keys())\n","        #     for k in key:\n","        #         state_dict[k] = state_dict[k] + a7*f['state_dict'][k]\n","    print(a1, a2, a3, a4, a5, a6, a7)\n","    # for k in key:\n","    #     state_dict[k] = state_dict[k] / len(iteration)\n","    print('')\n","\n","    # print(out_file)\n","    torch.save({'state_dict': state_dict}, out_file)\n","\n","    model = Model(model_name=CFG.model_name).to(CFG.device)\n","    checkpoint = torch.load(\"swa_model_fold1_5.pth\")\n","    model.load_state_dict(checkpoint['state_dict'])\n","#     model = nn.DataParallel(model)\n","\n","    loss_valid, valid_preds, _ = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","    valid_preds = valid_preds[:, 1]\n","    valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n","    valid_preds = np.array(valid_preds).flatten()\n","    \n","    valid_df['raw_pred'] = valid_preds\n","    LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n","    grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n","    grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n","    valid_labels_mean = grp_df['cancer'].values\n","    valid_preds_mean = grp_df['raw_pred'].values\n","    # print(valid_labels[:5], valid_preds_mean[:5])\n","    val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n","    LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n","    best_metric_mean_at_epoch = 0\n","    best_metric = 0\n","    \n","    best_threshold_mean = 0\n","    best_auc = 0\n","    best_cf = None\n","    for i in np.arange(0.001, 0.599, 0.001):\n","        valid_argmax = (valid_preds_mean>i).astype(np.int32)\n","        val_metric = pfbeta_np(valid_labels_mean, valid_argmax)\n","        val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n","        val_f1 = f1_score(valid_labels_mean, valid_argmax)\n","        val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n","        cf = confusion_matrix(valid_labels_mean, valid_argmax)\n","        if val_metric> best_metric:\n","            best_metric = val_metric\n","            # best_metric_mean_at_epoch = val_metric\n","            best_threshold_mean = i\n","            best_auc = val_auc\n","            best_cf = cf\n","    if best_metric>0.505:\n","        state = {'state_dict': model.state_dict()}\n","        path = f'swa_{CFG.model_name}_fold_{fold}_model_{best_metric:.4f}_{best_threshold_mean:.4f}.pth'\n","        torch.save(state, path)\n","    \n","    LOGGER.info(f\"Best metric at: {best_metric:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n","    LOGGER.info(f\"Cf: {best_cf}\")\n","    return best_metric\n","\n","study = optuna.create_study(direction='maximize', sampler = TPESampler(seed=1))\n","study.optimize(func=objective, n_trials=150)\n","study.best_params"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'tungenv' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n tungenv ipykernel --update-deps --force-reinstall'"]}],"source":["def pfbeta_np(labels, preds, beta=1):\n","    preds = preds.clip(0, 1)\n","    y_true_count = labels.sum()\n","    ctp = preds[labels==1].sum()\n","    cfp = preds[labels==0].sum()\n","    beta_squared = beta * beta\n","    c_precision = ctp / (ctp + cfp)\n","    c_recall = ctp / y_true_count\n","    if (c_precision > 0 and c_recall > 0):\n","        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n","        return result\n","    else:\n","        return 0.0\n","# fold=3\n","# valid_df = df[df['fold']==fold].reset_index(drop=True)\n","# valid_dataset = BreastDataset(valid_df, transforms=data_transforms['valid'])\n","\n","valid_loader = DataLoader(valid_dataset, batch_size = CFG.valid_bs, \n","                                num_workers=1, shuffle=False, drop_last=False)\n","set_seed(1)\n","out_file = 'swa_model_fold3_5.pth' \n","iteration = [\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4625_0.367.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4766_0.251.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_12_0.4824_0.297.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_13_0.4771_0.241.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_15_0.4878_0.242.pth'\n","    'foldsensemble/tf_efficientnetv2_b2_fold_3_model_epoch_6_0.4648_0.444.pth',\n","    'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_7_0.4545_0.354.pth',\n","    'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_2_0.4528_0.320.pth',\n","    'foldsensemble/tf_efficientnetv2_b2_fold_3_model_epoch_8_0.4471_0.371.pth',\n","    'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_4_0.4379_0.392.pth',\n","    'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_3_0.4317_0.364.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_3_0.4224_0.288.pth',\n","    # 'foldsensemble/tf_efficientnetv2_b2_fold_3_model_epoch_7_0.4192_0.270.pth',\n","    # 'foldsensemble/tf_efficientnetv2_b2_fold_3_model_epoch_4_0.4103_0.343.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_2_0.4528_0.320.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_3_0.4317_0.364.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_4_0.4311_0.361.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_6_0.4304_0.332.pth'\n","]\n","\n","criterion = nn.CrossEntropyLoss().to(CFG.device)\n","best_metric = 0\n","torch.cuda.empty_cache()\n","def objective(trial):\n","#     a2 = 0.12003546043452194 \n","#     a3 = 0.8649578775769542\n","#     a1 = 0.020317850755860567 \n","#     a2 = 0.1293785181217534 \n","#     a3 = 0.850303631122386\n","    # a1 = 0.2\n","    # a2 = 0.2    \n","    # a3 = 0.2\n","    # a4 = 0.2\n","    # a5 = 0.2\n","    # a1 = 1\n","    a1 = trial.suggest_uniform('a1', 0.001, 0.99)\n","    a2 = trial.suggest_uniform('a2', 0.0009, 1-a1-0.001)\n","    a3 = trial.suggest_loguniform('a3', 0.00009, 1-a1-a2-0.001)\n","    # a4 = 1-a1-a2-a3\n","    a4 = trial.suggest_loguniform('a4', 0.000009, 1-a1-a2-a3-0.001)\n","    # a5 = 1-a1-a2-a3-a4\n","    a5 = trial.suggest_loguniform('a5', 0.0000009, 1-a1-a2-a3-a4-0.001)\n","    a6 = 1-a1-a2-a3-a4-a5\n","    # a4 = 1-a1-a2-a3\n","    # a1 = 0.4700450486328235 \n","    # a2 = 0.23862687145742947 \n","    # a3 = 0.2913280799097471\n","    state_dict = None\n","    for i in iteration:\n","        f = i\n","        # print(f)\n","        f = torch.load(f, map_location=lambda storage, loc: storage)\n","        if state_dict is None:\n","            print(\"none: \", i)\n","            state_dict = f['state_dict']\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = f['state_dict'][k]*a1\n","        elif i=='fold3/tf_efficientnetv2_b2_fold_3_model_epoch_7_0.4545_0.354.pth': \n","            print(\"hehe\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a2*f['state_dict'][k]\n","        elif i=='fold3/tf_efficientnetv2_b2_fold_3_model_epoch_2_0.4528_0.320.pth': \n","            print(\"hehe\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a3*f['state_dict'][k]\n","        elif i=='foldsensemble/tf_efficientnetv2_b2_fold_3_model_epoch_8_0.4471_0.371.pth':\n","            print(\"noob\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a4*f['state_dict'][k]\n","        elif i=='fold3/tf_efficientnetv2_b2_fold_3_model_epoch_4_0.4379_0.392.pth':\n","            print(\"noobie\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a5*f['state_dict'][k]\n","        elif i=='fold3/tf_efficientnetv2_b2_fold_3_model_epoch_3_0.4317_0.364.pth':\n","            print(\"noobie\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a6*f['state_dict'][k]\n","    print(a1, a2, a3, a4, a5, a6)\n","    # for k in key:\n","    #     state_dict[k] = state_dict[k] / len(iteration)\n","    print('')\n","\n","    # print(out_file)\n","    torch.save({'state_dict': state_dict}, out_file)\n","\n","    model = Model(model_name=CFG.model_name).to(CFG.device)\n","    checkpoint = torch.load(\"swa_model_fold3_5.pth\")\n","    model.load_state_dict(checkpoint['state_dict'])\n","#     model = nn.DataParallel(model)\n","\n","    loss_valid, valid_preds, _ = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","    valid_preds = valid_preds[:, 1]\n","    valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n","    valid_preds = np.array(valid_preds).flatten()\n","    \n","    valid_df['raw_pred'] = valid_preds\n","    LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n","    grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n","    grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n","    valid_labels_mean = grp_df['cancer'].values\n","    valid_preds_mean = grp_df['raw_pred'].values\n","    # print(valid_labels[:5], valid_preds_mean[:5])\n","    val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n","    LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n","    best_metric_mean_at_epoch = 0\n","    best_metric = 0\n","    \n","    best_threshold_mean = 0\n","    best_auc = 0\n","    best_cf = None\n","    for i in np.arange(0.001, 0.599, 0.001):\n","        valid_argmax = (valid_preds_mean>i).astype(np.int32)\n","        val_metric = pfbeta_np(valid_labels_mean, valid_argmax)\n","        val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n","        val_f1 = f1_score(valid_labels_mean, valid_argmax)\n","        val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n","        cf = confusion_matrix(valid_labels_mean, valid_argmax)\n","        if val_metric> best_metric:\n","            best_metric = val_metric\n","            # best_metric_mean_at_epoch = val_metric\n","            best_threshold_mean = i\n","            best_auc = val_auc\n","            best_cf = cf\n","    if best_metric>0.51:\n","        state = {'state_dict': model.state_dict()}\n","        path = f'swa_{CFG.model_name}_fold_{fold}_model_{best_metric:.4f}_{best_threshold_mean:.3f}.pth'\n","        torch.save(state, path)\n","    \n","    LOGGER.info(f\"Best metric at: {best_metric:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n","    LOGGER.info(f\"Cf: {best_cf}\")\n","    torch.cuda.empty_cache()\n","    return best_metric\n","\n","study = optuna.create_study(direction='maximize', sampler = TPESampler(seed=666))\n","study.optimize(func=objective, n_trials=200)\n","study.best_params"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'tungenv' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n tungenv ipykernel --update-deps --force-reinstall'"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'tungenv' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n tungenv ipykernel --update-deps --force-reinstall'"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'tungenv' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n tungenv ipykernel --update-deps --force-reinstall'"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'tungenv' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'conda install -n tungenv ipykernel --update-deps --force-reinstall'"]}],"source":[]}],"metadata":{"kernelspec":{"display_name":"tungenv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"vscode":{"interpreter":{"hash":"f4a9d4f6fddb06d6117084e7970542ce818766d35fe0783188f4d61f666212c3"}}},"nbformat":4,"nbformat_minor":4}
