{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:20.757433Z","iopub.status.busy":"2022-12-30T08:23:20.756596Z","iopub.status.idle":"2022-12-30T08:23:20.769292Z","shell.execute_reply":"2022-12-30T08:23:20.768338Z","shell.execute_reply.started":"2022-12-30T08:23:20.757395Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/tungnx/miniconda3/envs/zaloenv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import random\n","from glob import glob\n","import os, shutil\n","from tqdm import tqdm\n","tqdm.pandas()\n","import time\n","import copy\n","import joblib\n","from collections import defaultdict\n","import gc\n","from IPython import display as ipd\n","import math\n","# visualization\n","import cv2\n","from glob import glob\n","# Sklearn\n","from sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\n","from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix, roc_curve\n","import timm\n","# PyTorch \n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","from torch.cuda.amp import autocast, GradScaler\n","import torch.nn.functional as F\n","from torch.optim.swa_utils import AveragedModel, SWALR\n","from transformers import get_cosine_schedule_with_warmup\n","from collections import defaultdict\n","# import matplotlib.pyplot as plt\n","# Albumentations for augmentations\n","import albumentations as A\n","import albumentations\n","import albumentations as albu\n","from albumentations.pytorch import ToTensorV2\n","from datetime import datetime\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:20.771750Z","iopub.status.busy":"2022-12-30T08:23:20.771281Z","iopub.status.idle":"2022-12-30T08:23:20.782962Z","shell.execute_reply":"2022-12-30T08:23:20.782013Z","shell.execute_reply.started":"2022-12-30T08:23:20.771715Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["class CFG:\n","    seed = 1\n","    model_name = \"tf_efficientnetv2_b2\"\n","    train_bs = 16\n","    valid_bs = train_bs*4\n","    image_size = 1024\n","    epochs = 25\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","print(CFG.device)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:20.784720Z","iopub.status.busy":"2022-12-30T08:23:20.784325Z","iopub.status.idle":"2022-12-30T08:23:20.912644Z","shell.execute_reply":"2022-12-30T08:23:20.911668Z","shell.execute_reply.started":"2022-12-30T08:23:20.784684Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>site_id</th>\n","      <th>patient_id</th>\n","      <th>image_id</th>\n","      <th>laterality</th>\n","      <th>view</th>\n","      <th>age</th>\n","      <th>cancer</th>\n","      <th>biopsy</th>\n","      <th>invasive</th>\n","      <th>BIRADS</th>\n","      <th>implant</th>\n","      <th>density</th>\n","      <th>machine_id</th>\n","      <th>difficult_negative_case</th>\n","      <th>split</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>10006</td>\n","      <td>462822612</td>\n","      <td>L</td>\n","      <td>CC</td>\n","      <td>61.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>29</td>\n","      <td>False</td>\n","      <td>10006_L</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>10006</td>\n","      <td>1459541791</td>\n","      <td>L</td>\n","      <td>MLO</td>\n","      <td>61.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>29</td>\n","      <td>False</td>\n","      <td>10006_L</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>10006</td>\n","      <td>1864590858</td>\n","      <td>R</td>\n","      <td>MLO</td>\n","      <td>61.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>29</td>\n","      <td>False</td>\n","      <td>10006_R</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>10006</td>\n","      <td>1874946579</td>\n","      <td>R</td>\n","      <td>CC</td>\n","      <td>61.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>29</td>\n","      <td>False</td>\n","      <td>10006_R</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>10011</td>\n","      <td>220375232</td>\n","      <td>L</td>\n","      <td>CC</td>\n","      <td>55.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>21</td>\n","      <td>True</td>\n","      <td>10011_L</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   site_id  patient_id    image_id laterality view   age  cancer  biopsy  \\\n","0        2       10006   462822612          L   CC  61.0       0       0   \n","1        2       10006  1459541791          L  MLO  61.0       0       0   \n","2        2       10006  1864590858          R  MLO  61.0       0       0   \n","3        2       10006  1874946579          R   CC  61.0       0       0   \n","4        2       10011   220375232          L   CC  55.0       0       0   \n","\n","   invasive  BIRADS  implant density  machine_id  difficult_negative_case  \\\n","0         0     NaN        0     NaN          29                    False   \n","1         0     NaN        0     NaN          29                    False   \n","2         0     NaN        0     NaN          29                    False   \n","3         0     NaN        0     NaN          29                    False   \n","4         0     0.0        0     NaN          21                     True   \n","\n","     split  fold  \n","0  10006_L     0  \n","1  10006_L     0  \n","2  10006_R     2  \n","3  10006_R     2  \n","4  10011_L     5  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\"train_10folds.csv\")\n","df.head()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["55864\n"]}],"source":["is_hol = df['cancer'] == 1\n","df_try = df[is_hol]\n","df1 = df.append([df_try]*1,ignore_index=True)\n","print(len(df1))"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Date :02/15/2023, 03:46:22\n"]}],"source":["def init_logger(log_file='train1.log'):\n","    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=log_file)\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = init_logger()\n","now = datetime.now()\n","datetime_now = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n","LOGGER.info(f\"Date :{datetime_now}\")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["train transformCompose([\n","  VerticalFlip(always_apply=False, p=0.5),\n","  ColorJitter(always_apply=False, p=0.5, brightness=[0.8, 1.2], contrast=[0.8, 1.2], saturation=[0.8, 1.2], hue=[-0.2, 0.2]),\n","  ShiftScaleRotate(always_apply=False, p=0.5, shift_limit_x=(-0.0625, 0.0625), shift_limit_y=(-0.0625, 0.0625), scale_limit=(-0.050000000000000044, 0.050000000000000044), rotate_limit=(-10, 10), interpolation=1, border_mode=4, value=None, mask_value=None, rotate_method='largest_box'),\n","  HorizontalFlip(always_apply=False, p=0.5),\n","  Cutout(always_apply=False, p=0.5, num_holes=5, max_h_size=102, max_w_size=102),\n","  ToTensorV2(always_apply=True, p=1.0, transpose_mask=False),\n","], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={})\n"]}],"source":["from albumentations import DualTransform\n","image_size = 1024\n","def isotropically_resize_image(img, size, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC):\n","    h, w = img.shape[:2]\n","    if max(w, h) == size:\n","        return img\n","    if w > h:\n","        scale = size / w\n","        h = h * scale\n","        w = size\n","    else:\n","        scale = size / h\n","        w = w * scale\n","        h = size\n","    interpolation = interpolation_up if scale > 1 else interpolation_down\n","    resized = cv2.resize(img, (int(w), int(h)), interpolation=interpolation)\n","    return resized\n","\n","\n","class IsotropicResize(DualTransform):\n","    def __init__(self, max_side, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC,\n","                 always_apply=False, p=1):\n","        super(IsotropicResize, self).__init__(always_apply, p)\n","        self.max_side = max_side\n","        self.interpolation_down = interpolation_down\n","        self.interpolation_up = interpolation_up\n","\n","    def apply(self, img, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC, **params):\n","        return isotropically_resize_image(img, size=self.max_side, interpolation_down=interpolation_down,\n","                                          interpolation_up=interpolation_up)\n","\n","    def apply_to_mask(self, img, **params):\n","        return self.apply(img, interpolation_down=cv2.INTER_NEAREST, interpolation_up=cv2.INTER_NEAREST, **params)\n","\n","    def get_transform_init_args_names(self):\n","        return (\"max_side\", \"interpolation_down\", \"interpolation_up\")\n","    \n","data_transforms = {\n","    \"train\": A.Compose([\n","        # A.Resize(image_size, image_size),\n","        # IsotropicResize(max_side = image_size),\n","        # A.PadIfNeeded(min_height=image_size, min_width=image_size, border_mode=cv2.BORDER_CONSTANT),\n","        # A.RandomBrightnessContrast(),\n","        A.VerticalFlip(p=0.5),   \n","        A.ColorJitter(p=0.5),\n","        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n","        A.HorizontalFlip(p=0.5),\n","        A.Cutout(max_h_size=int(image_size*0.1), max_w_size=int(image_size*0.1), num_holes=5, p=0.5), \n","        # A.OneOf([\n","        #         A.OpticalDistortion(),\n","        #         A.IAAPiecewiseAffine(),\n","        #     ], p=0.1),\n","        # A.OneOf([\n","        #     A.GaussNoise(),\n","        #     A.MotionBlur(blur_limit=(3, 5)),\n","        # ], p=0.1),\n","        # A.ColorJitter(),\n","        # A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n","        # A.HorizontalFlip(p=0.5),\n","        # A.Cutout(max_h_size=102, max_w_size=102, num_holes=5, p=0.5),\n","        # A.CLAHE(p=1.0),\n","        # albumentations.HorizontalFlip(p=0.5),\n","        # # albumentations.VerticalFlip(p=0.5),\n","        # albumentations.RandomBrightness(limit=0.2, p=0.75),\n","        # albumentations.RandomContrast(limit=0.2, p=0.75),\n","\n","        # albumentations.OneOf([\n","        #     albumentations.OpticalDistortion(distort_limit=1.),\n","        #     albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n","        # ], p=0.75),\n","\n","        # albumentations.HueSaturationValue(hue_shift_limit=40, sat_shift_limit=40, val_shift_limit=0, p=0.75),\n","        # albumentations.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.3, rotate_limit=30, border_mode=0, p=0.75),\n","        # A.Cutout(always_apply=False, p=0.5, num_holes=1, max_h_size=409, max_w_size=409),\n","        # A.OneOf([ \n","        # A.OpticalDistortion(distort_limit=1.0), \n","        # A.GridDistortion(num_steps=5, distort_limit=1.),\n","        # A.ElasticTransform(alpha=3), ], p=0.2),\n","        # A.OneOf([\n","        #     # A.GaussNoise(var_limit=[10, 50]),\n","        #     A.GaussianBlur(),\n","        #     A.MotionBlur(),\n","        #     A.MedianBlur(), ], p=0.2),\n","        # A.OneOf([\n","        #     A.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n","        #     A.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=1.0),\n","        #     A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n","        # ], p=0.25),\n","        # A.CoarseDropout(max_holes=8, max_height=image_size//20, max_width=image_size//20,\n","        #                  min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n","        # A.Normalize(mean=0, std=1),\n","        ToTensorV2(),], p=1.0),\n","    \n","    \"valid\": A.Compose([\n","        # IsotropicResize(max_side =image_size),\n","        # A.PadIfNeeded(min_height=image_size, min_width=image_size, border_mode=cv2.BORDER_CONSTANT),\n","        # A.Normalize(mean=0, std=1),\n","        # A.Resize(image_size, image_size),\n","        ToTensorV2(),\n","        ], p=1.0)\n","}\n","\n","LOGGER.info(f\"train transform{data_transforms['train']}\")\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:20.915927Z","iopub.status.busy":"2022-12-30T08:23:20.915346Z","iopub.status.idle":"2022-12-30T08:23:20.931477Z","shell.execute_reply":"2022-12-30T08:23:20.930433Z","shell.execute_reply.started":"2022-12-30T08:23:20.915890Z"},"trusted":true},"outputs":[],"source":["# from albumentations import DualTransform\n","# image_size = 1024\n","# def isotropically_resize_image(img, size, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC):\n","#     h, w = img.shape[:2]\n","#     if max(w, h) == size:\n","#         return img\n","#     if w > h:\n","#         scale = size / w\n","#         h = h * scale\n","#         w = size\n","#     else:\n","#         scale = size / h\n","#         w = w * scale\n","#         h = size\n","#     interpolation = interpolation_up if scale > 1 else interpolation_down\n","#     resized = cv2.resize(img, (int(w), int(h)), interpolation=interpolation)\n","#     return resized\n","\n","\n","# class IsotropicResize(DualTransform):\n","#     def __init__(self, max_side, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC,\n","#                  always_apply=False, p=1):\n","#         super(IsotropicResize, self).__init__(always_apply, p)\n","#         self.max_side = max_side\n","#         self.interpolation_down = interpolation_down\n","#         self.interpolation_up = interpolation_up\n","\n","#     def apply(self, img, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC, **params):\n","#         return isotropically_resize_image(img, size=self.max_side, interpolation_down=interpolation_down,\n","#                                           interpolation_up=interpolation_up)\n","\n","#     def apply_to_mask(self, img, **params):\n","#         return self.apply(img, interpolation_down=cv2.INTER_NEAREST, interpolation_up=cv2.INTER_NEAREST, **params)\n","\n","#     def get_transform_init_args_names(self):\n","#         return (\"max_side\", \"interpolation_down\", \"interpolation_up\")\n","    \n","# data_transforms = {\n","#     \"train\": A.Compose([\n","# #         A.Resize(image_size, image_size),\n","#         # IsotropicResize(max_side = image_size),\n","#        A.PadIfNeeded(min_width=image_size, border_mode=cv2.BORDER_CONSTANT),\n","#         albumentations.HorizontalFlip(p=0.5),\n","#         # albumentations.VerticalFlip(p=0.5),\n","#         albumentations.RandomBrightness(limit=0.2, p=0.75),\n","#         albumentations.RandomContrast(limit=0.2, p=0.75),\n","\n","#         albumentations.OneOf([\n","#             albumentations.OpticalDistortion(distort_limit=1.),\n","#             albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n","#         ], p=0.75),\n","\n","#         albumentations.HueSaturationValue(hue_shift_limit=40, sat_shift_limit=40, val_shift_limit=0, p=0.75),\n","#         albumentations.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.3, rotate_limit=30, border_mode=0, p=0.75),\n","#         A.Cutout(always_apply=False, p=0.5, num_holes=1, max_h_size=409, max_w_size=409),\n","#         # A.RandomBrightnessContrast(),\n","#         # A.VerticalFlip(p=0.5),   \n","#         A.ColorJitter(p = 0.7),\n","#         # A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n","#         # A.HorizontalFlip(p=0.5),\n","#         # A.Cutout(max_h_size=int(image_size * 0.1), max_w_size=int(image_size * 0.1), num_holes=5, p=0.5),\n","#         # albumentations.RandomBrightness(limit=0.2, p=0.75),\n","#         # albumentations.RandomContrast(limit=0.2, p=0.75),\n","\n","#         # albumentations.OneOf([\n","#         #     albumentations.OpticalDistortion(distort_limit=1.),\n","#         #     albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n","#         # ], p=0.75),\n","\n","#         # albumentations.HueSaturationValue(hue_shift_limit=40, sat_shift_limit=40, val_shift_limit=0, p=0.75),\n","#         # albumentations.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.3, rotate_limit=30, border_mode=0, p=0.75),\n","#         # A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=10, val_shift_limit=10, p=0.7),\n","#         # A.RandomBrightnessContrast(brightness_limit=(-0.2,0.2), contrast_limit=(-0.2, 0.2), p=0.7),\n","#         # A.CLAHE(p=0.5),\n","#         # albumentations.OneOf([\n","#         # albumentations.OpticalDistortion(distort_limit=1.),\n","#         # albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n","#         # ], p=0.75),\n","#         # A.OneOf([\n","#         # A.GaussianBlur(),\n","#         # A.MotionBlur(),\n","#         # A.MedianBlur(), ], p=0.5),\n","#         # A.IAASharpen(p = 0.2),\n","#         # A.JpegCompression(p=0.2),\n","#         # A.Downscale(scale_min=0.5, scale_max=0.75),\n","#         # A.OneOf([ A.JpegCompression(), A.Downscale(scale_min=0.1, scale_max=0.15), ], p=0.2), \n","#         # A.IAAPiecewiseAffine(),\n","# #         A.OneOf([ \n","# #         A.OpticalDistortion(distort_limit=1.0), \n","# #         A.GridDistortion(num_steps=5, distort_limit=1.),\n","# #         A.ElasticTransform(alpha=3), ], p=0.2),\n","# #         A.OneOf([\n","# #             A.GaussNoise(var_limit=[10, 50]),\n","# #             A.GaussianBlur(),\n","# #             A.MotionBlur(),\n","# #             A.MedianBlur(), ], p=0.2),\n","#         # A.OneOf([\n","#         #     A.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n","#         #     A.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=1.0),\n","#         #     A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n","#         # ], p=0.25),\n","#         # A.CoarseDropout(max_holes=8, max_height=image_size//20, max_width=image_size//20,\n","#         #                  min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n","#         # A.Normalize(mean=0, std=1),\n","#         ToTensorV2(),], p=1.0),\n","    \n","#     \"valid\": A.Compose([\n","#         # IsotropicResize(max_side = image_size),\n","#         A.PadIfNeeded(min_height=image_size, min_width=image_size, border_mode=cv2.BORDER_CONSTANT),\n","#         # A.Normalize(mean=0, std=1),\n","# #         A.Resize(image_size, image_size),\n","#         ToTensorV2(),\n","#         ], p=1.0)\n","# }\n","\n","# LOGGER.info(f\"train transform{data_transforms['train']}\")\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:20.934703Z","iopub.status.busy":"2022-12-30T08:23:20.933649Z","iopub.status.idle":"2022-12-30T08:23:21.010802Z","shell.execute_reply":"2022-12-30T08:23:21.009678Z","shell.execute_reply.started":"2022-12-30T08:23:20.934663Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3, 1344, 840]) tensor(0)\n","tensor(255.)\n"]}],"source":["def pad(array, target_shape):\n","    return np.pad(\n","        array,\n","        [(0, target_shape[i] - array.shape[i]) for i in range(len(array.shape))],\n","        \"constant\",\n","    )\n","    \n","def load_img(img_path):\n","    image = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n","    image = image[:, :, None]\n","    # image = cv2.imread(img_path)\n","    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    # print(image.shape)\n","    \n","    # print(image.shape)\n","    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    # image = pad(image, (1024, 800, 3))\n","        # img = img.reshape((*resize))\n","    return image\n","#     image = cv2.resize(image, (320, 320), cv2.INTER_NEAREST)\n","#     image = image.astype(np.float32)\n","#     mx = np.max(image)\n","#     if mx:\n","#         image/=mx\n","#     image = image /255.0\n","    \n","\n","def load_img1(img_path):\n","    image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","    image = image[:, :, None]\n","    return image\n","\n","def load_img2(img_path):\n","    image = cv2.imread(img_path)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    return image\n","class BreastDataset(Dataset):\n","    def __init__(self, df, transforms=None):\n","        self.df = df\n","        self.transforms = transforms\n","        \n","    def __getitem__(self, index):\n","        row = self.df.iloc[index]\n","        img_path = f\"flip/{row.patient_id}_{row.image_id}.png\"\n","        img = load_img2(img_path)\n","        label = row['cancer']\n","        # img = np.transpose(img, (2, 0, 1))\n","        data = self.transforms(image=img)\n","        img  = data['image']\n","        # img = img/255\n","        return torch.tensor(img).float(), torch.tensor(label).long()\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","fold0 = df[df['fold']==0]\n","train_dataset = BreastDataset(fold0, transforms = data_transforms['train'])\n","image, label = train_dataset[0]\n","print(image.shape, label)\n","print(image.max())"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["\n","# from pylab import rcParams\n","\n","# f, axarr = plt.subplots(1,15, figsize = (20, 20))\n","# imgs = []\n","# for p in range(15):\n","#     img, label = train_dataset[p]\n","#     img = img.transpose(0, 1).transpose(1,2).cpu().numpy()\n","#     img = img.astype(np.uint8)\n","#     imgs.append(img)\n","#     axarr[p].imshow(img)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:21.012682Z","iopub.status.busy":"2022-12-30T08:23:21.012267Z","iopub.status.idle":"2022-12-30T08:23:21.020148Z","shell.execute_reply":"2022-12-30T08:23:21.019023Z","shell.execute_reply.started":"2022-12-30T08:23:21.012626Z"},"trusted":true},"outputs":[],"source":["\n","\n","class ModelNextVit(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.checkpoint = torch.load('nextvit_small_in1k_384.pth')\n","        self.backbone = nextvit_small()\n","        self.backbone.load_state_dict(self.checkpoint['model'])\n","        self.backbone.proj_head = nn.Linear(1024, 2)\n","\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        return x\n","\n","class PAM_Module(nn.Module):\n","    \"\"\" Position attention module\"\"\"\n","    #Ref from SAGAN\n","    def __init__(self, in_dim):\n","        super(PAM_Module, self).__init__()\n","        self.chanel_in = in_dim\n","\n","        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n","        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n","        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1)\n","        self.gamma = nn.Parameter(torch.zeros(1))\n","\n","    def forward(self, x):\n","        \"\"\"\n","            inputs :\n","                x : input feature maps( B X C X H X W)\n","            returns :\n","                out : attention value + input feature\n","                attention: B X (HxW) X (HxW)\n","        \"\"\"\n","        m_batchsize, C, height, width = x.size()\n","        proj_query = self.query_conv(x).view(m_batchsize, -1, width*height).permute(0, 2, 1)\n","        proj_key = self.key_conv(x).view(m_batchsize, -1, width*height)\n","        energy = torch.bmm(proj_query, proj_key)\n","        attention = torch.softmax(energy, dim=-1)\n","        proj_value = self.value_conv(x).view(m_batchsize, -1, width*height)\n","\n","        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n","        out = out.view(m_batchsize, C, height, width)\n","\n","        out = self.gamma*out + x\n","        return out\n","\n","\n","class CAM_Module(nn.Module):\n","    \"\"\" Channel attention module\"\"\"\n","    def __init__(self, in_dim):\n","        super(CAM_Module, self).__init__()\n","        self.chanel_in = in_dim\n","        self.gamma = nn.Parameter(torch.zeros(1))\n","\n","    def forward(self,x):\n","        \"\"\"\n","            inputs :\n","                x : input feature maps( B X C X H X W)\n","            returns :\n","                out : attention value + input feature\n","                attention: B X C X C\n","        \"\"\"\n","        m_batchsize, C, height, width = x.size()\n","        proj_query = x.view(m_batchsize, C, -1)\n","        proj_key = x.view(m_batchsize, C, -1).permute(0, 2, 1)\n","        energy = torch.bmm(proj_query, proj_key)\n","        energy_new = torch.max(energy, -1, keepdim=True)[0].expand_as(energy)-energy\n","        attention = torch.softmax(energy_new, dim=-1)\n","        proj_value = x.view(m_batchsize, C, -1)\n","\n","        out = torch.bmm(attention, proj_value)\n","        out = out.view(m_batchsize, C, height, width)\n","\n","        out = self.gamma*out + x\n","        return out\n","\n","\n","class CBAM(nn.Module):\n","    def __init__(self, in_channels):\n","        # def __init__(self):\n","        super(CBAM, self).__init__()\n","        inter_channels = in_channels // 4\n","        self.conv1_c = nn.Sequential(nn.Conv2d(in_channels, inter_channels, 3, padding=1, bias=False),\n","                                     nn.BatchNorm2d(inter_channels),\n","                                     nn.ReLU())\n","        \n","        self.conv1_s = nn.Sequential(nn.Conv2d(in_channels, inter_channels, 3, padding=1, bias=False),\n","                                     nn.BatchNorm2d(inter_channels),\n","                                     nn.ReLU())\n","\n","        self.channel_gate = CAM_Module(inter_channels)\n","        self.spatial_gate = PAM_Module(inter_channels)\n","\n","        self.conv2_c = nn.Sequential(nn.Conv2d(inter_channels, in_channels, 3, padding=1, bias=False),\n","                                     nn.BatchNorm2d(in_channels),\n","                                     nn.ReLU())\n","        self.conv2_a = nn.Sequential(nn.Conv2d(inter_channels, in_channels, 3, padding=1, bias=False),\n","                                     nn.BatchNorm2d(in_channels),\n","                                     nn.ReLU())\n","\n","    def forward(self, x):\n","        feat1 = self.conv1_c(x)\n","        chnl_att = self.channel_gate(feat1)\n","        chnl_att = self.conv2_c(chnl_att)\n","\n","        feat2 = self.conv1_s(x)\n","        spat_att = self.spatial_gate(feat2)\n","        spat_att = self.conv2_a(spat_att)\n","\n","        x_out = chnl_att + spat_att\n","\n","        return x_out\n","    \n","class Model(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(CFG.model_name, pretrained=True,drop_rate = 0.3, drop_path_rate = 0.2)\n","        self.fc = nn.Linear(self.backbone.classifier.in_features,2)\n","        self.dropout = nn.Dropout(0.5)\n","#         self.backbone.classifier = nn.Identity()\n","        n_features = 1408\n","        target_size = 2\n","        self.local_fe = CBAM(n_features)\n","        self.dropout = nn.Dropout(0.1)\n","        self.classifier = nn.Sequential(nn.Linear(n_features + n_features, n_features),\n","                                        nn.BatchNorm1d(n_features),\n","                                        nn.Dropout(0.1),\n","                                        nn.ReLU(),\n","                                        nn.Linear(n_features, target_size))\n","    def forward(self, x):\n","        enc_feas = self.backbone.forward_features(x)\n","        global_feas = F.adaptive_avg_pool2d(enc_feas, 1)\n","        global_feas = global_feas.reshape(-1, 1408)\n","        global_feas = self.dropout(global_feas)\n","#         print(global_feas.shape)\n","        local_feas = self.local_fe(enc_feas)\n","        local_feas = torch.sum(local_feas, dim=[2,3])\n","        local_feas = self.dropout(local_feas)\n","#         print(local_feas.shape)\n","        all_feas = torch.cat([global_feas, local_feas], dim=1)\n","#         print(all_feas.shape)\n","        x = self.classifier(all_feas)\n","#         x = self.fc(self.dropout(x))\n","        return x\n","\n","class ModelNfNet(nn.Module):\n","    def __init__(self, model_name='dm_nfnet_f0'):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(model_name, pretrained=True,drop_rate = 0.3, drop_path_rate = 0.2)\n","        self.fc = nn.Linear(self.backbone.head.fc.in_features,2)\n","        self.backbone.head.fc = nn.Identity()\n","        self.dropout = nn.Dropout(0.5)\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.fc(self.dropout(x))\n","        return x\n","\n","class SpatialAttention(nn.Module):\n","    def __init__(self, kernel_size=7):\n","        super(SpatialAttention, self).__init__()\n","\n","        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n","        padding = 3 if kernel_size == 7 else 1\n","\n","        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        avg_out = torch.mean(x, dim=1, keepdim=True)\n","        max_out, _ = torch.max(x, dim=1, keepdim=True)\n","        x = torch.cat([avg_out, max_out], dim=1)\n","        x = self.conv(x)\n","        return self.sigmoid(x)\n","\n","class ModelEffNetAttention(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(model_name, pretrained=True,drop_rate = 0.4, drop_path_rate = 0.2)\n","        self.attention = SpatialAttention()\n","        self.fc = nn.Linear(self.backbone.classifier.in_features,2)\n","        # self.backbone.classifier = nn.Identity()\n","        self.dropout = nn.Dropout(0.5)\n","    def forward(self, x):\n","        x = self.backbone.forward_features(x)\n","        att = self.attention(x)\n","        x = x*att\n","        x = self.backbone.global_pool(x)\n","        x = self.fc(self.dropout(x))\n","        return x\n","\n","class ModelOld(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(CFG.model_name, pretrained=True,drop_rate = 0.3, drop_path_rate = 0.2)\n","        self.fc = nn.Linear(self.backbone.classifier.in_features,2)\n","        self.dropout = nn.Dropout(0.5)\n","        self.backbone.classifier = nn.Identity()\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.fc(self.dropout(x))\n","        return x\n","\n","class ModelNew(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(CFG.model_name, pretrained=True,drop_rate = 0.4, drop_path_rate = 0.2)\n","        self.fc = nn.Linear(self.backbone.classifier.in_features,2)\n","        self.dropout = nn.Dropout(0.5)\n","        self.backbone.classifier = nn.Identity()\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.fc(self.dropout(x))\n","        return x\n","\n","class ModelNoDropRate(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(CFG.model_name, pretrained=True)\n","        self.fc = nn.Linear(self.backbone.classifier.in_features,2)\n","        self.dropout = nn.Dropout(0.5)\n","        self.backbone.classifier = nn.Identity()\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.fc(self.dropout(x))\n","        return x\n","\n","def gem(x, p=3, eps=1e-6):\n","    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1.0 / p)\n","\n","class GeM(nn.Module):\n","    def __init__(self, p=3, eps=1e-6):\n","        super(GeM, self).__init__()\n","        # if p_trainable:\n","        self.p = nn.Parameter(torch.ones(1) * p)\n","        # else:\n","            # self.p = p\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        ret = gem(x, p=self.p, eps=self.eps)\n","        return ret\n","\n","    def __repr__(self):\n","        return (self.__class__.__name__  + f\"(p={self.p.data.tolist()[0]:.4f},eps={self.eps})\")\n","\n","class ModelOneChannelAvgGem(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(CFG.model_name, pretrained=True, num_classes = 0, global_pool=\"\",in_chans = 1,drop_rate = 0.3, drop_path_rate = 0.2)\n","        self.fc = nn.Linear(1408,2)\n","        self.dropout = nn.Dropout(0.5)\n","        self.global_pool = GeM()\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.global_pool(x)\n","        x = x[:,:,0,0]\n","\n","        x = self.fc(self.dropout(x))\n","        return x\n","\n","class ModelOneChannelAvgPool(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(CFG.model_name, pretrained=True, in_chans = 1,drop_rate = 0.3, drop_path_rate = 0.2)\n","        self.fc = nn.Linear(1408,2)\n","        self.dropout = nn.Dropout(0.5)\n","        self.backbone.classifier = nn.Identity()\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.fc(self.dropout(x))\n","        return x\n","\n","class ModelThreeChannelAvgGem(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(CFG.model_name, pretrained=True, num_classes = 0, global_pool=\"\",in_chans = 3,drop_rate = 0.3, drop_path_rate = 0.2)\n","        self.fc = nn.Linear(1408,2)\n","        self.dropout = nn.Dropout(0.5)\n","        self.global_pool = GeM()\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.global_pool(x)\n","        x = x[:,:,0,0]\n","\n","        x = self.fc(self.dropout(x))\n","        return x\n","\n","class ModelThreeChannelAvgPool(nn.Module):\n","    def __init__(self, model_name):\n","        super().__init__()\n","        # ,drop_rate = 0.3, drop_path_rate = 0.2\n","        self.backbone = timm.create_model(CFG.model_name, pretrained=True, num_classes = 0, global_pool=\"\",in_chans = 3,drop_rate = 0.3, drop_path_rate = 0.2)\n","        self.fc = nn.Linear(1408,2)\n","        self.dropout = nn.Dropout(0.5)\n","        # self.backbone.classifier = nn.Identity()\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = F.adaptive_avg_pool2d(x, 1)\n","        x = x[:,:,0,0]\n","\n","        x = self.fc(self.dropout(x))\n","        return x\n","# inp = torch.rand(2, 1, 1344, 840).to(CFG.device)\n","# model = ModelOneChannelAvgPool(CFG.model_name).to(CFG.device)\n","# output = model(inp)\n","# print(output.shape)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:21.022923Z","iopub.status.busy":"2022-12-30T08:23:21.022147Z","iopub.status.idle":"2022-12-30T08:23:21.032555Z","shell.execute_reply":"2022-12-30T08:23:21.031346Z","shell.execute_reply.started":"2022-12-30T08:23:21.022887Z"},"trusted":true},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim.optimizer import Optimizer, required\n","import math\n","\n","class AdamP(Optimizer):\n","    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n","                 weight_decay=0, delta=0.1, wd_ratio=0.1, nesterov=False):\n","        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay,\n","                        delta=delta, wd_ratio=wd_ratio, nesterov=nesterov)\n","        super(AdamP, self).__init__(params, defaults)\n","\n","    def _channel_view(self, x):\n","        return x.view(x.size(0), -1)\n","\n","    def _layer_view(self, x):\n","        return x.view(1, -1)\n","\n","    def _cosine_similarity(self, x, y, eps, view_func):\n","        x = view_func(x)\n","        y = view_func(y)\n","\n","        return F.cosine_similarity(x, y, dim=1, eps=eps).abs_()\n","\n","    def _projection(self, p, grad, perturb, delta, wd_ratio, eps):\n","        wd = 1\n","        expand_size = [-1] + [1] * (len(p.shape) - 1)\n","        for view_func in [self._channel_view, self._layer_view]:\n","\n","            cosine_sim = self._cosine_similarity(grad, p.data, eps, view_func)\n","\n","            if cosine_sim.max() < delta / math.sqrt(view_func(p.data).size(1)):\n","                p_n = p.data / view_func(p.data).norm(dim=1).view(expand_size).add_(eps)\n","                perturb -= p_n * view_func(p_n * perturb).sum(dim=1).view(expand_size)\n","                wd = wd_ratio\n","\n","                return perturb, wd\n","\n","        return perturb, wd\n","\n","    def step(self, closure=None):\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","\n","                grad = p.grad.data\n","                beta1, beta2 = group['betas']\n","                nesterov = group['nesterov']\n","\n","                state = self.state[p]\n","\n","                # State initialization\n","                if len(state) == 0:\n","                    state['step'] = 0\n","                    state['exp_avg'] = torch.zeros_like(p.data)\n","                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n","\n","                # Adam\n","                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n","\n","                state['step'] += 1\n","                bias_correction1 = 1 - beta1 ** state['step']\n","                bias_correction2 = 1 - beta2 ** state['step']\n","\n","                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n","                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n","\n","                denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n","                step_size = group['lr'] / bias_correction1\n","\n","                if nesterov:\n","                    perturb = (beta1 * exp_avg + (1 - beta1) * grad) / denom\n","                else:\n","                    perturb = exp_avg / denom\n","\n","                # Projection\n","                wd_ratio = 1\n","                if len(p.shape) > 1:\n","                    perturb, wd_ratio = self._projection(p, grad, perturb, group['delta'], group['wd_ratio'], group['eps'])\n","\n","                # Weight decay\n","                if group['weight_decay'] > 0:\n","                    p.data.mul_(1 - group['lr'] * group['weight_decay'] * wd_ratio)\n","\n","                # Step\n","                p.data.add_(perturb, alpha=-step_size)\n","\n","        return loss\n","\n","class SGDP(Optimizer):\n","    def __init__(self, params, lr=required, momentum=0, dampening=0,\n","                 weight_decay=0, nesterov=False, eps=1e-8, delta=0.1, wd_ratio=0.1):\n","        defaults = dict(lr=lr, momentum=momentum, dampening=dampening, weight_decay=weight_decay,\n","                        nesterov=nesterov, eps=eps, delta=delta, wd_ratio=wd_ratio)\n","        super(SGDP, self).__init__(params, defaults)\n","\n","    def _channel_view(self, x):\n","        return x.view(x.size(0), -1)\n","\n","    def _layer_view(self, x):\n","        return x.view(1, -1)\n","\n","    def _cosine_similarity(self, x, y, eps, view_func):\n","        x = view_func(x)\n","        y = view_func(y)\n","\n","        return F.cosine_similarity(x, y, dim=1, eps=eps).abs_()\n","\n","    def _projection(self, p, grad, perturb, delta, wd_ratio, eps):\n","        wd = 1\n","        expand_size = [-1] + [1] * (len(p.shape) - 1)\n","        for view_func in [self._channel_view, self._layer_view]:\n","\n","            cosine_sim = self._cosine_similarity(grad, p.data, eps, view_func)\n","\n","            if cosine_sim.max() < delta / math.sqrt(view_func(p.data).size(1)):\n","                p_n = p.data / view_func(p.data).norm(dim=1).view(expand_size).add_(eps)\n","                perturb -= p_n * view_func(p_n * perturb).sum(dim=1).view(expand_size)\n","                wd = wd_ratio\n","\n","                return perturb, wd\n","\n","        return perturb, wd\n","\n","    def step(self, closure=None):\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","            momentum = group['momentum']\n","            dampening = group['dampening']\n","            nesterov = group['nesterov']\n","\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                grad = p.grad.data\n","                state = self.state[p]\n","\n","                # State initialization\n","                if len(state) == 0:\n","                    state['momentum'] = torch.zeros_like(p.data)\n","\n","                # SGD\n","                buf = state['momentum']\n","                buf.mul_(momentum).add_(grad, alpha=1 - dampening)\n","                if nesterov:\n","                    d_p = grad + momentum * buf\n","                else:\n","                    d_p = buf\n","\n","                # Projection\n","                wd_ratio = 1\n","                if len(p.shape) > 1:\n","                    d_p, wd_ratio = self._projection(p, grad, d_p, group['delta'], group['wd_ratio'], group['eps'])\n","\n","                # Weight decay\n","                if group['weight_decay'] > 0:\n","                    p.data.mul_(1 - group['lr'] * group['weight_decay'] * wd_ratio / (1-momentum))\n","\n","                # Step\n","                p.data.add_(d_p, alpha=-group['lr'])\n","\n","        return loss\n","\n","class SAM(torch.optim.Optimizer):\n","    def __init__(self, params, base_optimizer, rho=0.05, **kwargs):\n","        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n","\n","        defaults = dict(rho=rho, **kwargs)\n","        super(SAM, self).__init__(params, defaults)\n","\n","        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n","        self.param_groups = self.base_optimizer.param_groups\n","\n","    @torch.no_grad()\n","    def first_step(self, zero_grad=False):\n","        grad_norm = self._grad_norm()\n","        for group in self.param_groups:\n","            scale = group[\"rho\"] / (grad_norm + 1e-12)\n","\n","            for p in group[\"params\"]:\n","                if p.grad is None: continue\n","                e_w = p.grad * scale.to(p)\n","                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n","                self.state[p][\"e_w\"] = e_w\n","\n","        if zero_grad: self.zero_grad()\n","\n","    @torch.no_grad()\n","    def second_step(self, zero_grad=False):\n","        for group in self.param_groups:\n","            for p in group[\"params\"]:\n","                if p.grad is None: continue\n","                p.sub_(self.state[p][\"e_w\"])  # get back to \"w\" from \"w + e(w)\"\n","\n","        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n","\n","        if zero_grad: self.zero_grad()\n","\n","    def step(self, closure=None):\n","        raise NotImplementedError(\"SAM doesn't work like the other optimizers, you should first call `first_step` and the `second_step`; see the documentation for more info.\")\n","\n","    def _grad_norm(self):\n","        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n","        norm = torch.norm(\n","                    torch.stack([\n","                        p.grad.norm(p=2).to(shared_device)\n","                        for group in self.param_groups for p in group[\"params\"]\n","                        if p.grad is not None\n","                    ]),\n","                    p=2\n","               )\n","        return norm"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["from torch.optim.lr_scheduler import _LRScheduler\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","\n","class GradualWarmupScheduler(_LRScheduler):\n","    \"\"\" Gradually warm-up(increasing) learning rate in optimizer.\n","    Proposed in 'Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour'.\n","    Args:\n","        optimizer (Optimizer): Wrapped optimizer.\n","        multiplier: target learning rate = base lr * multiplier if multiplier > 1.0. if multiplier = 1.0, lr starts from 0 and ends up with the base_lr.\n","        total_epoch: target learning rate is reached at total_epoch, gradually\n","        after_scheduler: after target_epoch, use this scheduler(eg. ReduceLROnPlateau)\n","    \"\"\"\n","\n","    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n","        self.multiplier = multiplier\n","        if self.multiplier < 1.:\n","            raise ValueError('multiplier should be greater thant or equal to 1.')\n","        self.total_epoch = total_epoch\n","        self.after_scheduler = after_scheduler\n","        self.finished = False\n","        super(GradualWarmupScheduler, self).__init__(optimizer)\n","\n","    def get_lr(self):\n","        if self.last_epoch > self.total_epoch:\n","            if self.after_scheduler:\n","                if not self.finished:\n","                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n","                    self.finished = True\n","                return self.after_scheduler.get_last_lr()\n","            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n","\n","        if self.multiplier == 1.0:\n","            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n","        else:\n","            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n","\n","    def step_ReduceLROnPlateau(self, metrics, epoch=None):\n","        if epoch is None:\n","            epoch = self.last_epoch + 1\n","        self.last_epoch = epoch if epoch != 0 else 1  # ReduceLROnPlateau is called at the end of epoch, whereas others are called at beginning\n","        if self.last_epoch <= self.total_epoch:\n","            warmup_lr = [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n","            for param_group, lr in zip(self.optimizer.param_groups, warmup_lr):\n","                param_group['lr'] = lr\n","        else:\n","            if epoch is None:\n","                self.after_scheduler.step(metrics, None)\n","            else:\n","                self.after_scheduler.step(metrics, epoch - self.total_epoch)\n","\n","    def step(self, epoch=None, metrics=None):\n","        if type(self.after_scheduler) != ReduceLROnPlateau:\n","            if self.finished and self.after_scheduler:\n","                if epoch is None:\n","                    self.after_scheduler.step(None)\n","                else:\n","                    self.after_scheduler.step(epoch - self.total_epoch)\n","                self._last_lr = self.after_scheduler.get_last_lr()\n","            else:\n","                return super(GradualWarmupScheduler, self).step(epoch)\n","        else:\n","            self.step_ReduceLROnPlateau(metrics, epoch)\n","\n","class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n","    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n","        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n","    def get_lr(self):\n","        if self.last_epoch > self.total_epoch:\n","            if self.after_scheduler:\n","                if not self.finished:\n","                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n","                    self.finished = True\n","                return self.after_scheduler.get_lr()\n","            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n","        if self.multiplier == 1.0:\n","            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n","        else:\n","            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n","\n","class Lookahead(optim.Optimizer):\n","    def __init__(self, base_optimizer, alpha=0.5, k=6):\n","        if not 0.0 <= alpha <= 1.0:\n","            raise ValueError(f'Invalid slow update rate: {alpha}')\n","        if not 1 <= k:\n","            raise ValueError(f'Invalid lookahead steps: {k}')\n","        defaults = dict(lookahead_alpha=alpha, lookahead_k=k, lookahead_step=0)\n","        self.base_optimizer = base_optimizer\n","        self.param_groups = self.base_optimizer.param_groups\n","        self.defaults = base_optimizer.defaults\n","        self.defaults.update(defaults)\n","        self.state = defaultdict(dict)\n","        # manually add our defaults to the param groups\n","        for name, default in defaults.items():\n","            for group in self.param_groups:\n","                group.setdefault(name, default)\n","\n","    def update_slow(self, group):\n","        for fast_p in group[\"params\"]:\n","            if fast_p.grad is None:\n","                continue\n","            param_state = self.state[fast_p]\n","            if 'slow_buffer' not in param_state:\n","                param_state['slow_buffer'] = torch.empty_like(fast_p.data)\n","                param_state['slow_buffer'].copy_(fast_p.data)\n","            slow = param_state['slow_buffer']\n","            slow.add_(group['lookahead_alpha'], fast_p.data - slow)\n","            fast_p.data.copy_(slow)\n","\n","    def sync_lookahead(self):\n","        for group in self.param_groups:\n","            self.update_slow(group)\n","\n","    def step(self, closure=None):\n","        #assert id(self.param_groups) == id(self.base_optimizer.param_groups)\n","        loss = self.base_optimizer.step(closure)\n","        for group in self.param_groups:\n","            group['lookahead_step'] += 1\n","            if group['lookahead_step'] % group['lookahead_k'] == 0:\n","                self.update_slow(group)\n","        return loss\n","\n","    def state_dict(self):\n","        fast_state_dict = self.base_optimizer.state_dict()\n","        slow_state = {\n","            (id(k) if isinstance(k, torch.Tensor) else k): v\n","            for k, v in self.state.items()\n","        }\n","        fast_state = fast_state_dict['state']\n","        param_groups = fast_state_dict['param_groups']\n","        return {\n","            'state': fast_state,\n","            'slow_state': slow_state,\n","            'param_groups': param_groups,\n","        }\n","\n","    def load_state_dict(self, state_dict):\n","        fast_state_dict = {\n","            'state': state_dict['state'],\n","            'param_groups': state_dict['param_groups'],\n","        }\n","        self.base_optimizer.load_state_dict(fast_state_dict)\n","\n","        # We want to restore the slow state, but share param_groups reference\n","        # with base_optimizer. This is a bit redundant but least code\n","        slow_state_new = False\n","        if 'slow_state' not in state_dict:\n","            print('Loading state_dict from optimizer without Lookahead applied.')\n","            state_dict['slow_state'] = defaultdict(dict)\n","            slow_state_new = True\n","        slow_state_dict = {\n","            'state': state_dict['slow_state'],\n","            'param_groups': state_dict['param_groups'],  # this is pointless but saves code\n","        }\n","        super(Lookahead, self).load_state_dict(slow_state_dict)\n","        self.param_groups = self.base_optimizer.param_groups  # make both ref same container\n","        if slow_state_new:\n","            # reapply defaults to catch missing lookahead specific ones\n","            for name, default in self.defaults.items():\n","                for group in self.param_groups:\n","                    group.setdefault(name, default)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def log_t(u, t):\n","    \"\"\"Compute log_t for `u'.\"\"\"\n","    if t==1.0:\n","        return u.log()\n","    else:\n","        return (u.pow(1.0 - t) - 1.0) / (1.0 - t)\n","\n","def exp_t(u, t):\n","    \"\"\"Compute exp_t for `u'.\"\"\"\n","    if t==1:\n","        return u.exp()\n","    else:\n","        return (1.0 + (1.0-t)*u).relu().pow(1.0 / (1.0 - t))\n","\n","def compute_normalization_fixed_point(activations, t, num_iters):\n","\n","    \"\"\"Returns the normalization value for each example (t > 1.0).\n","    Args:\n","      activations: A multi-dimensional tensor with last dimension `num_classes`.\n","      t: Temperature 2 (> 1.0 for tail heaviness).\n","      num_iters: Number of iterations to run the method.\n","    Return: A tensor of same shape as activation with the last dimension being 1.\n","    \"\"\"\n","    mu, _ = torch.max(activations, -1, keepdim=True)\n","    normalized_activations_step_0 = activations - mu\n","\n","    normalized_activations = normalized_activations_step_0\n","\n","    for _ in range(num_iters):\n","        logt_partition = torch.sum(\n","                exp_t(normalized_activations, t), -1, keepdim=True)\n","        normalized_activations = normalized_activations_step_0 * \\\n","                logt_partition.pow(1.0-t)\n","\n","    logt_partition = torch.sum(\n","            exp_t(normalized_activations, t), -1, keepdim=True)\n","    normalization_constants = - log_t(1.0 / logt_partition, t) + mu\n","\n","    return normalization_constants\n","\n","def compute_normalization_binary_search(activations, t, num_iters):\n","\n","    \"\"\"Returns the normalization value for each example (t < 1.0).\n","    Args:\n","      activations: A multi-dimensional tensor with last dimension `num_classes`.\n","      t: Temperature 2 (< 1.0 for finite support).\n","      num_iters: Number of iterations to run the method.\n","    Return: A tensor of same rank as activation with the last dimension being 1.\n","    \"\"\"\n","\n","    mu, _ = torch.max(activations, -1, keepdim=True)\n","    normalized_activations = activations - mu\n","\n","    effective_dim = \\\n","        torch.sum(\n","                (normalized_activations > -1.0 / (1.0-t)).to(torch.int32),\n","            dim=-1, keepdim=True).to(activations.dtype)\n","\n","    shape_partition = activations.shape[:-1] + (1,)\n","    lower = torch.zeros(shape_partition, dtype=activations.dtype, device=activations.device)\n","    upper = -log_t(1.0/effective_dim, t) * torch.ones_like(lower)\n","\n","    for _ in range(num_iters):\n","        logt_partition = (upper + lower)/2.0\n","        sum_probs = torch.sum(\n","                exp_t(normalized_activations - logt_partition, t),\n","                dim=-1, keepdim=True)\n","        update = (sum_probs < 1.0).to(activations.dtype)\n","        lower = torch.reshape(\n","                lower * update + (1.0-update) * logt_partition,\n","                shape_partition)\n","        upper = torch.reshape(\n","                upper * (1.0 - update) + update * logt_partition,\n","                shape_partition)\n","\n","    logt_partition = (upper + lower)/2.0\n","    return logt_partition + mu\n","\n","class ComputeNormalization(torch.autograd.Function):\n","    \"\"\"\n","    Class implementing custom backward pass for compute_normalization. See compute_normalization.\n","    \"\"\"\n","    @staticmethod\n","    def forward(ctx, activations, t, num_iters):\n","        if t < 1.0:\n","            normalization_constants = compute_normalization_binary_search(activations, t, num_iters)\n","        else:\n","            normalization_constants = compute_normalization_fixed_point(activations, t, num_iters)\n","\n","        ctx.save_for_backward(activations, normalization_constants)\n","        ctx.t=t\n","        return normalization_constants\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        activations, normalization_constants = ctx.saved_tensors\n","        t = ctx.t\n","        normalized_activations = activations - normalization_constants \n","        probabilities = exp_t(normalized_activations, t)\n","        escorts = probabilities.pow(t)\n","        escorts = escorts / escorts.sum(dim=-1, keepdim=True)\n","        grad_input = escorts * grad_output\n","        \n","        return grad_input, None, None\n","\n","def compute_normalization(activations, t, num_iters=5):\n","    \"\"\"Returns the normalization value for each example. \n","    Backward pass is implemented.\n","    Args:\n","      activations: A multi-dimensional tensor with last dimension `num_classes`.\n","      t: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n","      num_iters: Number of iterations to run the method.\n","    Return: A tensor of same rank as activation with the last dimension being 1.\n","    \"\"\"\n","    return ComputeNormalization.apply(activations, t, num_iters)\n","\n","def tempered_sigmoid(activations, t, num_iters = 5):\n","    \"\"\"Tempered sigmoid function.\n","    Args:\n","      activations: Activations for the positive class for binary classification.\n","      t: Temperature tensor > 0.0.\n","      num_iters: Number of iterations to run the method.\n","    Returns:\n","      A probabilities tensor.\n","    \"\"\"\n","    internal_activations = torch.stack([activations,\n","        torch.zeros_like(activations)],\n","        dim=-1)\n","    internal_probabilities = tempered_softmax(internal_activations, t, num_iters)\n","    return internal_probabilities[..., 0]\n","\n","\n","def tempered_softmax(activations, t, num_iters=5):\n","    \"\"\"Tempered softmax function.\n","    Args:\n","      activations: A multi-dimensional tensor with last dimension `num_classes`.\n","      t: Temperature > 1.0.\n","      num_iters: Number of iterations to run the method.\n","    Returns:\n","      A probabilities tensor.\n","    \"\"\"\n","    if t == 1.0:\n","        return activations.softmax(dim=-1)\n","\n","    normalization_constants = compute_normalization(activations, t, num_iters)\n","    return exp_t(activations - normalization_constants, t)\n","\n","def bi_tempered_binary_logistic_loss(activations,\n","        labels,\n","        t1,\n","        t2,\n","        label_smoothing = 0.0,\n","        num_iters=5,\n","        reduction='mean'):\n","\n","    \"\"\"Bi-Tempered binary logistic loss.\n","    Args:\n","      activations: A tensor containing activations for class 1.\n","      labels: A tensor with shape as activations, containing probabilities for class 1\n","      t1: Temperature 1 (< 1.0 for boundedness).\n","      t2: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n","      label_smoothing: Label smoothing\n","      num_iters: Number of iterations to run the method.\n","    Returns:\n","      A loss tensor.\n","    \"\"\"\n","    internal_activations = torch.stack([activations,\n","        torch.zeros_like(activations)],\n","        dim=-1)\n","    internal_labels = torch.stack([labels.to(activations.dtype),\n","        1.0 - labels.to(activations.dtype)],\n","        dim=-1)\n","    return bi_tempered_logistic_loss(internal_activations, \n","            internal_labels,\n","            t1,\n","            t2,\n","            label_smoothing = label_smoothing,\n","            num_iters = num_iters,\n","            reduction = reduction)\n","\n","def bi_tempered_logistic_loss(activations,\n","        labels,\n","        t1,\n","        t2,\n","        label_smoothing=0.0,\n","        num_iters=5,\n","        reduction = 'mean'):\n","\n","    \"\"\"Bi-Tempered Logistic Loss.\n","    Args:\n","      activations: A multi-dimensional tensor with last dimension `num_classes`.\n","      labels: A tensor with shape and dtype as activations (onehot), \n","        or a long tensor of one dimension less than activations (pytorch standard)\n","      t1: Temperature 1 (< 1.0 for boundedness).\n","      t2: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n","      label_smoothing: Label smoothing parameter between [0, 1). Default 0.0.\n","      num_iters: Number of iterations to run the method. Default 5.\n","      reduction: ``'none'`` | ``'mean'`` | ``'sum'``. Default ``'mean'``.\n","        ``'none'``: No reduction is applied, return shape is shape of\n","        activations without the last dimension.\n","        ``'mean'``: Loss is averaged over minibatch. Return shape (1,)\n","        ``'sum'``: Loss is summed over minibatch. Return shape (1,)\n","    Returns:\n","      A loss tensor.\n","    \"\"\"\n","\n","    if len(labels.shape)<len(activations.shape): #not one-hot\n","        labels_onehot = torch.zeros_like(activations)\n","        labels_onehot.scatter_(1, labels[..., None], 1)\n","    else:\n","        labels_onehot = labels\n","\n","    if label_smoothing > 0:\n","        num_classes = labels_onehot.shape[-1]\n","        labels_onehot = ( 1 - label_smoothing * num_classes / (num_classes - 1) ) \\\n","                * labels_onehot + \\\n","                label_smoothing / (num_classes - 1)\n","\n","    probabilities = tempered_softmax(activations, t2, num_iters)\n","\n","    loss_values = labels_onehot * log_t(labels_onehot + 1e-10, t1) \\\n","            - labels_onehot * log_t(probabilities, t1) \\\n","            - labels_onehot.pow(2.0 - t1) / (2.0 - t1) \\\n","            + probabilities.pow(2.0 - t1) / (2.0 - t1)\n","    loss_values = loss_values.sum(dim = -1) #sum over classes\n","\n","    if reduction == 'none':\n","        return loss_values\n","    if reduction == 'sum':\n","        return loss_values.sum()\n","    if reduction == 'mean':\n","        return loss_values.mean()\n","\n","class BiTemperedLogisticLoss(nn.Module): \n","    def __init__(self, t1, t2, smoothing=0.0): \n","        super(BiTemperedLogisticLoss, self).__init__() \n","        self.t1 = t1\n","        self.t2 = t2\n","        self.smoothing = smoothing\n","    def forward(self, logit_label, truth_label):\n","        loss_label = bi_tempered_logistic_loss(\n","            logit_label, truth_label,\n","            t1=self.t1, t2=self.t2,\n","            label_smoothing=self.smoothing,\n","            reduction='none'\n","        )\n","        \n","        loss_label = loss_label.mean()\n","        return loss_label"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:23:21.036233Z","iopub.status.busy":"2022-12-30T08:23:21.035928Z","iopub.status.idle":"2022-12-30T08:23:21.059619Z","shell.execute_reply":"2022-12-30T08:23:21.058523Z","shell.execute_reply.started":"2022-12-30T08:23:21.036197Z"},"trusted":true},"outputs":[],"source":["\n","def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    # switch to train mode\n","    model.train()\n","    start = end = time.time()\n","    truth = []\n","    pred = []\n","    global_step = 0\n","    scaler = GradScaler()\n","    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc='Train')\n","    for step, (images, labels) in pbar:\n","        optimizer.zero_grad()\n","        data_time.update(time.time() - end)\n","        images = images.to(device, non_blocking=True)\n","        \n","        \n","        labels = labels.to(device, non_blocking=True)\n","        batch_size = labels.size(0)\n","        with autocast():\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            # loss.backward()\n","            # optimizer.first_step(zero_grad=True)\n","            # criterion(model(images), labels).backward()\n","            # optimizer.second_step(zero_grad=True)\n","            # record loss\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        # global_step += 1\n","        scheduler.step()\n","            # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","#         if step % 100 == 0 or step == (len(train_loader)-1):\n","#             print('Epoch: [{0}][{1}/{2}] '\n","#                       'Data {data_time.val:.6f} ({data_time.avg:.6f}) '\n","#                       'Elapsed {remain:s} '\n","#                       'Loss: {loss.val:.6f}({loss.avg:.6f}) '\n","#                       'LR: {lr:.6f}  '\n","#                       .format(\n","#                        epoch+1, step, len(train_loader), batch_time=batch_time,\n","#                        data_time=data_time, loss=losses,\n","#                        remain=timeSince(start, float(step+1)/len(train_loader)),\n","#                        lr=scheduler.get_lr()[0],\n","#                        ))\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","        current_lr = optimizer.param_groups[0]['lr']\n","        pbar.set_postfix(train_loss=f'{losses.avg:0.4f}',\n","                        lr=f'{current_lr:0.8f}',\n","                        gpu_mem=f'{mem:0.2f} GB')\n","\n","    return losses.avg\n","\n","def valid_fn_no_sigmoid(val_dataloader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    truth = []\n","    preds = []\n","    valid_labels = []\n","    start = end = time.time()\n","    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n","    for step, (images, labels) in pbar:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            outputs = model(images)\n","        valid_labels.append(labels.cpu().numpy())\n","        loss = criterion(outputs, labels)\n","#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n","        losses.update(loss.item(), batch_size)\n","#         print(outputs)\n","        preds.append((outputs).to('cpu').numpy())\n","        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n","                        gpu_mem=f'{mem:0.2f} GB')\n","    predictions = np.concatenate(preds)\n","    valid_labels = np.concatenate(valid_labels)\n","    return losses.avg, predictions, valid_labels\n","\n","\n","def valid_fn(val_dataloader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    truth = []\n","    preds = []\n","    valid_labels = []\n","    start = end = time.time()\n","    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n","    for step, (images, labels) in pbar:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            outputs = model(images)\n","        valid_labels.append(labels.cpu().numpy())\n","        loss = criterion(outputs, labels)\n","#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n","        losses.update(loss.item(), batch_size)\n","#         print(outputs)\n","        preds.append(torch.sigmoid(outputs).to('cpu').numpy())\n","        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n","                        gpu_mem=f'{mem:0.2f} GB')\n","    predictions = np.concatenate(preds)\n","    valid_labels = np.concatenate(valid_labels)\n","    return losses.avg, predictions, valid_labels\n","def valid_fn_two(val_dataloader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    truth = []\n","    preds = []\n","    valid_labels = []\n","    start = end = time.time()\n","    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n","    for step, (images, labels) in pbar:\n","        images = images.to(device, non_blocking=True)\n","        labels = labels.to(device, non_blocking=True)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            outputs = model(images)\n","        valid_labels.append(labels.cpu().numpy())\n","        loss = criterion(outputs, labels)\n","#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n","        losses.update(loss.item(), batch_size)\n","#         print(outputs)\n","        preds.append(F.softmax(outputs).to('cpu').numpy())\n","        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n","                        gpu_mem=f'{mem:0.2f} GB')\n","    predictions = np.concatenate(preds)\n","    valid_labels = np.concatenate(valid_labels)\n","    return losses.avg, predictions, valid_labels\n","\n","def valid_fn_two_flip(val_dataloader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    truth = []\n","    preds = []\n","    valid_labels = []\n","    start = end = time.time()\n","    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n","    for step, (images, labels) in pbar:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        images = torch.flip(images, [3])\n","        with torch.no_grad():\n","            outputs = model(images)\n","        valid_labels.append(labels.cpu().numpy())\n","        loss = criterion(outputs, labels)\n","#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n","        losses.update(loss.item(), batch_size)\n","#         print(outputs)\n","        preds.append(F.softmax(outputs).to('cpu').numpy())\n","        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n","                        gpu_mem=f'{mem:0.2f} GB')\n","    predictions = np.concatenate(preds)\n","    valid_labels = np.concatenate(valid_labels)\n","    return losses.avg, predictions, valid_labels\n","\n","def valid_fn_flip(val_dataloader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    truth = []\n","    preds = []\n","    valid_labels = []\n","    start = end = time.time()\n","    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n","    for step, (images, labels) in pbar:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        images = torch.flip(images, [3])\n","        with torch.no_grad():\n","            outputs = model(images)\n","        valid_labels.append(labels.cpu().numpy())\n","        loss = criterion(outputs, labels)\n","#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n","        losses.update(loss.item(), batch_size)\n","#         print(outputs)\n","        preds.append(torch.sigmoid(outputs).to('cpu').numpy())\n","        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n","                        gpu_mem=f'{mem:0.2f} GB')\n","    predictions = np.concatenate(preds)\n","    valid_labels = np.concatenate(valid_labels)\n","    return losses.avg, predictions, valid_labels"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-12-30T08:32:56.198968Z","iopub.status.busy":"2022-12-30T08:32:56.198538Z","iopub.status.idle":"2022-12-30T08:38:54.946641Z","shell.execute_reply":"2022-12-30T08:38:54.945288Z","shell.execute_reply.started":"2022-12-30T08:32:56.198933Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["5 fold\n","Fold: 0\n","Model name: tf_efficientnetv2_b2\n","Len train df: 50278\n","Len valid df: 5471\n"]},{"name":"stdout","output_type":"stream","text":["> SEEDING DONE\n"]},{"name":"stderr","output_type":"stream","text":["Train bs: 16\n","ModelOld\n","optimizer: AdamW (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    eps: 1e-08\n","    foreach: None\n","    initial_lr: 0.0001\n","    lr: 0.0\n","    maximize: False\n","    weight_decay: 0.0004\n",")\n","total_epoch :15\n","Warmup: 1\n","Epoch: 1/15\n","Train: 100%|| 3142/3142 [1:15:16<00:00,  1.44s/it, gpu_mem=0.48 GB, lr=0.00010000, train_loss=0.2165]\n","Val: 100%|| 86/86 [14:43<00:00, 10.27s/it, eval_loss=0.1024, gpu_mem=11.47 GB]\n","Train loss:0.2165, Valid loss:0.1024\n","Val metric mean prob: 0.0471\n","Best metric at epoch 1: 0.2051 0.1160  0.5771\n","Cf: [[2313   21]\n"," [  41    8]]\n","Model improve: 0.0000 -> 0.2051\n","Epoch: 2/15\n","Train: 100%|| 3142/3142 [56:19<00:00,  1.08s/it, gpu_mem=0.48 GB, lr=0.00009875, train_loss=0.1559] \n","Val: 100%|| 86/86 [12:37<00:00,  8.81s/it, eval_loss=0.0869, gpu_mem=11.47 GB]\n","Train loss:0.1559, Valid loss:0.0869\n","Val metric mean prob: 0.1385\n","Best metric at epoch 2: 0.4835 0.2210  0.7202\n","Cf: [[2314   20]\n"," [  27   22]]\n","Model improve: 0.2051 -> 0.4835\n","Epoch: 3/15\n","Train: 100%|| 3142/3142 [57:52<00:00,  1.11s/it, gpu_mem=0.48 GB, lr=0.00009505, train_loss=0.1392] \n","Val: 100%|| 86/86 [10:45<00:00,  7.50s/it, eval_loss=0.0937, gpu_mem=11.47 GB]\n","Train loss:0.1392, Valid loss:0.0937\n","Val metric mean prob: 0.1885\n","Best metric at epoch 3: 0.5306 0.3210  0.7604\n","Cf: [[2311   23]\n"," [  23   26]]\n","Model improve: 0.4835 -> 0.5306\n","Epoch: 4/15\n","Train: 100%|| 3142/3142 [59:00<00:00,  1.13s/it, gpu_mem=0.48 GB, lr=0.00008909, train_loss=0.1266]  \n","Val: 100%|| 86/86 [10:39<00:00,  7.43s/it, eval_loss=0.0735, gpu_mem=11.47 GB]\n","Train loss:0.1266, Valid loss:0.0735\n","Val metric mean prob: 0.2644\n","Best metric at epoch 4: 0.5435 0.2890  0.7512\n","Cf: [[2316   18]\n"," [  24   25]]\n","Model improve: 0.5306 -> 0.5435\n","Epoch: 5/15\n","Train: 100%|| 3142/3142 [59:35<00:00,  1.14s/it, gpu_mem=0.48 GB, lr=0.00008117, train_loss=0.1176] \n","Val: 100%|| 86/86 [12:53<00:00,  8.99s/it, eval_loss=0.0684, gpu_mem=11.47 GB]\n","Train loss:0.1176, Valid loss:0.0684\n","Val metric mean prob: 0.2736\n","Best metric at epoch 5: 0.5825 0.1370  0.8010\n","Cf: [[2310   24]\n"," [  19   30]]\n","Model improve: 0.5435 -> 0.5825\n","Epoch: 6/15\n","Train:  39%|      | 1240/3142 [52:06<2:04:48,  3.94s/it, gpu_mem=0.48 GB, lr=0.00007759, train_loss=0.1089] "]}],"source":["from exhaustive_weighted_random_sampler import ExhaustiveWeightedRandomSampler\n","def pfbeta(labels, predictions, beta=1):\n","    y_true_count = 0\n","    ctp = 0\n","    cfp = 0\n","\n","    for idx in range(len(labels)):\n","        prediction = min(max(predictions[idx], 0), 1)\n","        if (labels[idx]):\n","            y_true_count += 1\n","            ctp += prediction\n","        else:\n","            cfp += prediction\n","\n","    beta_squared = beta * beta\n","    c_precision = ctp / (ctp + cfp)\n","    c_recall = ctp / y_true_count\n","    if (c_precision > 0 and c_recall > 0):\n","        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n","        return result\n","    else:\n","        return 0\n","\n","def pfbeta_np(labels, preds, beta=1):\n","    preds = preds.clip(0, 1)\n","    y_true_count = labels.sum()\n","    ctp = preds[labels==1].sum()\n","    cfp = preds[labels==0].sum()\n","    beta_squared = beta * beta\n","    c_precision = ctp / (ctp + cfp)\n","    c_recall = ctp / y_true_count\n","    if (c_precision > 0 and c_recall > 0):\n","        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n","        return result\n","    else:\n","        return 0.0\n","    \n","def dfs_freeze(module):\n","    for param in module.parameters():\n","        param.requires_grad = False\n","        \n","def dfs_unfreeze(module):\n","    for param in module.parameters():\n","        param.requires_grad = True\n","    \n","def set_seed(seed = 42):\n","    '''Sets the seed of the entire notebook so results are the same every time we run.\n","    This is for REPRODUCIBILITY.'''\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    # When running on the CuDNN backend, two further options must be set\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    # Set a fixed value for the hash seed\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    print('> SEEDING DONE')\n","\n","def sigmoid(x):\n","  return 1 / (1 + math.exp(-x))\n","\n","set_seed(1)\n","gc.collect()\n","torch.cuda.empty_cache()\n","for fold in [0]:\n","    LOGGER.info(\"5 fold\")\n","    LOGGER.info(f\"Fold: {fold}\")\n","    LOGGER.info(f\"Model name: {CFG.model_name}\")\n","    # model = ModelNfNet().to(device)\n","    # model = ModelEffNetAttention(model_name=CFG.model_name).to(device)\n","    # model = ModelOneChannelAvgGem(model_name=CFG.model_name).to(CFG.device)\n","    \n","    # model = ModelVIT().to(CFG.device)\n","    train_df = df1[df1['fold']!=fold].reset_index(drop=True)\n","    valid_df = df[df['fold']==fold].reset_index(drop=True)\n","    # print(len(valid_df))\n","    LOGGER.info(f\"Len train df: {len(train_df)}\")\n","    LOGGER.info(f\"Len valid df: {len(valid_df)}\")\n","    train_dataset = BreastDataset(train_df, transforms=data_transforms['train'])\n","\n","    train_loader = DataLoader(train_dataset, batch_size = CFG.train_bs,\n","                                  num_workers=1, shuffle=True, pin_memory=True, drop_last=True)\n","    \n","    valid_dataset = BreastDataset(valid_df, transforms=data_transforms['valid'])\n","\n","    valid_loader = DataLoader(valid_dataset, batch_size = CFG.valid_bs, \n","                                  num_workers=1, shuffle=False, pin_memory=True, drop_last=False)\n","    # model = Model(model_name=CFG.model_name).to(device)\n","    LEN_DL_TRAIN = len(train_loader)\n","    best_f1 = 0\n","    best_metric = 0\n","    total_epoch = 15\n","    warmup = 1\n","    model = ModelOld(model_name=CFG.model_name).to(CFG.device)\n","    # checkpoint = torch.load(\"swa_model_fold1_10.pth\")\n","    # model.load_state_dict(checkpoint['state_dict'])\n","    optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-4, weight_decay=4e-4)\n","    # optimizer.load_state_dict(checkpoint['optimizer'])\n","    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps = warmup*LEN_DL_TRAIN, num_training_steps =total_epoch*LEN_DL_TRAIN)\n","    # scheduler = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n","    # scheduler.load_state_dict(checkpoint['scheduler'])\n","    criterion = nn.CrossEntropyLoss().to(CFG.device)\n","    LOGGER.info(f\"Train bs: {CFG.train_bs}\")\n","    # LOGGER.info(f\"Model: {model}\")\n","    LOGGER.info(f\"{model.__class__.__name__}\")\n","    LOGGER.info(f\"optimizer: {optimizer}\")\n","    LOGGER.info(f\"total_epoch :{total_epoch}\")\n","    LOGGER.info(f\"Warmup: {warmup}\")\n","    for epoch in range(1, total_epoch+1):\n","        LOGGER.info(f\"Epoch: {epoch}/{total_epoch}\")\n","        loss_train = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, CFG.device)\n","        loss_valid, valid_preds, valid_labels = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","        valid_preds = valid_preds[:, 1]\n","        valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n","        valid_preds = np.array(valid_preds).flatten()\n","        \n","        valid_df['raw_pred'] = valid_preds\n","        # LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n","        LOGGER.info(f\"Train loss:{loss_train:.4f}, Valid loss:{loss_valid:.4f}\")\n","        # print(valid_df.head())\n","        grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n","        grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n","        valid_labels_mean = grp_df['cancer'].values\n","        valid_preds_mean = grp_df['raw_pred'].values\n","        # print(valid_labels[:5], valid_preds_mean[:5])\n","        val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n","        LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n","        best_metric_mean_at_epoch = 0\n","        best_metric1 = 0\n","        best_threshold_mean = 0\n","        best_auc = 0\n","        best_cf = None\n","        for i in np.arange(0.001, 0.599, 0.001):\n","            valid_argmax = (valid_preds_mean>i).astype(np.int32)\n","    #             print(valid_argmax)\n","            # val_metric = pfbeta(valid_labels_mean, valid_argmax)\n","            val_metric1 = pfbeta_np(valid_labels_mean, valid_argmax)\n","            val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n","            val_f1 = f1_score(valid_labels_mean, valid_argmax)\n","            val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n","            cf = confusion_matrix(valid_labels_mean, valid_argmax)\n","            if val_metric1> best_metric1:\n","                best_metric1 = val_metric1\n","                # best_metric_mean_at_epoch = val_metric\n","                best_threshold_mean = i\n","                best_auc = val_auc\n","                best_cf = cf\n","        LOGGER.info(f\"Best metric at epoch {epoch}: {best_metric1:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n","        LOGGER.info(f\"Cf: {best_cf}\")\n","        if best_metric1> best_metric:\n","\n","            LOGGER.info(f\"Model improve: {best_metric:.4f} -> {best_metric1:.4f}\")\n","            best_metric = best_metric1\n","        state = {'epoch': epoch, 'state_dict': model.state_dict()}\n","        # state = {'epoch': epoch, 'state_dict': model.state_dict(),'optimizer': optimizer.state_dict(), 'scheduler':scheduler.state_dict()}\n","        path = f'foldtest/{CFG.model_name}_fold_{fold}_model_epoch_{epoch}_{best_metric1:.4f}_{best_threshold_mean:.3f}.pth'\n","        torch.save(state, path)\n","\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2023-02-15 03:14:01,420]\u001b[0m A new study created in memory with name: no-name-e2dd68e3-d3b0-44c7-9d56-55418b9aff19\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["> SEEDING DONE\n","fold0/tf_efficientnetv2_b2_fold_0_model_epoch_2_0.5510_0.151.pth\n","none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_2_0.5510_0.151.pth\n","fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","0.5563409550491111 0.4436590449508889\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 86/86 [04:47<00:00,  3.34s/it, eval_loss=0.0767, gpu_mem=7.75 GB]\n","Valid loss:0.0767\n","Val metric mean prob: 0.2882\n","Best metric at: 0.5591 0.3410  0.7615\n","Cf: [[2316   18]\n"," [  23   26]]\n","\u001b[32m[I 2023-02-15 03:19:15,897]\u001b[0m Trial 0 finished with value: 0.5591397849462366 and parameters: {'a1': 0.5563409550491111}. Best is trial 0 with value: 0.5591397849462366.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["fold0/tf_efficientnetv2_b2_fold_0_model_epoch_2_0.5510_0.151.pth\n","none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_2_0.5510_0.151.pth\n","fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","0.668465581423339 0.331534418576661\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 86/86 [04:53<00:00,  3.42s/it, eval_loss=0.0756, gpu_mem=7.75 GB]\n","Valid loss:0.0756\n","Val metric mean prob: 0.2541\n","Best metric at: 0.5714 0.2860  0.7619\n","Cf: [[2318   16]\n"," [  23   26]]\n","\u001b[32m[I 2023-02-15 03:24:30,747]\u001b[0m Trial 1 finished with value: 0.5714285714285714 and parameters: {'a1': 0.668465581423339}. Best is trial 1 with value: 0.5714285714285714.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["fold0/tf_efficientnetv2_b2_fold_0_model_epoch_2_0.5510_0.151.pth\n","none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_2_0.5510_0.151.pth\n","fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","0.5376811820313478 0.46231881796865215\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val: 100%|| 86/86 [04:58<00:00,  3.47s/it, eval_loss=0.0770, gpu_mem=7.75 GB]\n","Valid loss:0.0770\n","Val metric mean prob: 0.2932\n","Best metric at: 0.5476 0.4070  0.7321\n","Cf: [[2322   12]\n"," [  26   23]]\n","\u001b[32m[I 2023-02-15 03:29:50,677]\u001b[0m Trial 2 finished with value: 0.5476190476190477 and parameters: {'a1': 0.5376811820313478}. Best is trial 1 with value: 0.5714285714285714.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["fold0/tf_efficientnetv2_b2_fold_0_model_epoch_2_0.5510_0.151.pth\n","none:  fold0/tf_efficientnetv2_b2_fold_0_model_epoch_2_0.5510_0.151.pth\n","fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","hehe fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth\n","0.5777292846534984 0.4222707153465016\n","\n"]},{"name":"stderr","output_type":"stream","text":["Val:  17%|        | 15/86 [00:54<04:26,  3.75s/it, eval_loss=0.0681, gpu_mem=7.75 GB]"]}],"source":["import optuna\n","from optuna.samplers import TPESampler\n","\n","def valid_fn_two(val_dataloader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc='Val')\n","    for step, (images, labels) in pbar:\n","        images = images.to(device, non_blocking=True)\n","        labels = labels.to(device, non_blocking=True)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            with autocast(enabled=True):\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","#         loss = bi_tempered_logistic_loss(outputs, labels, t1=0.8, t2 = 1.4)\n","        losses.update(loss.item(), batch_size)\n","#         print(outputs)\n","        preds.append(F.softmax(outputs).to('cpu').numpy())\n","        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n","        pbar.set_postfix(eval_loss=f'{losses.avg:0.4f}',\n","                        gpu_mem=f'{mem:0.2f} GB')\n","    predictions = np.concatenate(preds)\n","    return losses.avg, predictions\n","set_seed(1)\n","out_file = 'swa_model_fold0_10.pth' \n","iteration = [\n","    'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_2_0.5510_0.151.pth',\n","    'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth',\n","#     '/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth'\n","]\n","\n","criterion = nn.CrossEntropyLoss().to(CFG.device)\n","best_metric = 0\n","torch.cuda.empty_cache()\n","def objective(trial):\n","    # a1 = 0.4962849464623993 \n","    # a2 = 0.5037150535376007\n","#     a1 = 0.1689507073116359 \n","#     a2 = 0.47142151346976024 \n","#     a3 = 0.3596277792186039\n","    a1 = trial.suggest_uniform('a1', 0.01, 0.79)\n","    a2 = 1-a1\n","#     a2 = trial.suggest_uniform('a2', 0.1, 1-a1)\n","#     a3 = 1-a1-a2\n","    state_dict = None\n","    for i in iteration:\n","        f = i\n","        print(f)\n","        f = torch.load(f, map_location=lambda storage, loc: storage)\n","        if state_dict is None:\n","            print(\"none: \", i)\n","            state_dict = f['state_dict']\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = f['state_dict'][k]*a1\n","        elif i=='fold0/tf_efficientnetv2_b2_fold_0_model_epoch_13_0.5750_0.437.pth': \n","            print(\"hehe\", i)\n","            key = list(f['state_dict'].keys())\n","            for k in key:\n","                state_dict[k] = state_dict[k] + a2*f['state_dict'][k]\n","#         elif i=='/kaggle/input/10folds/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth':\n","#             print(\"noob\", i)\n","#             key = list(f['state_dict'].keys())\n","#             for k in key:\n","#                 state_dict[k] = state_dict[k] + a3*f['state_dict'][k]\n","    print(a1, a2)\n","    # for k in key:\n","    #     state_dict[k] = state_dict[k] / len(iteration)\n","    print('')\n","\n","    # print(out_file)\n","    torch.save({'state_dict': state_dict}, out_file)\n","\n","    model = ModelOld(model_name=CFG.model_name).to(CFG.device)\n","    checkpoint = torch.load(\"swa_model_fold0_10.pth\")\n","    model.load_state_dict(checkpoint['state_dict'])\n","#     model = nn.DataParallel(model)\n","\n","    loss_valid, valid_preds = valid_fn_two(valid_loader, model, criterion, CFG.device)\n","    valid_preds = valid_preds[:, 1]\n","    valid_df['prediction_id'] = valid_df['patient_id'].astype(str) + '_' + valid_df['laterality'].astype(str)\n","    valid_preds = np.array(valid_preds).flatten()\n","    \n","    valid_df['raw_pred'] = valid_preds\n","    LOGGER.info(f\"Valid loss:{loss_valid:.4f}\")\n","    grp_df = valid_df.groupby('prediction_id')['raw_pred', 'cancer'].mean()\n","    grp_df['cancer'] = grp_df['cancer'].astype(np.int)\n","    valid_labels_mean = grp_df['cancer'].values\n","    valid_preds_mean = grp_df['raw_pred'].values\n","    # print(valid_labels[:5], valid_preds_mean[:5])\n","    val_metric_mean = pfbeta(valid_labels_mean, valid_preds_mean)\n","    LOGGER.info(f\"Val metric mean prob: {val_metric_mean:.4f}\")\n","    best_metric_mean_at_epoch = 0\n","    best_metric = 0\n","    \n","    best_threshold_mean = 0\n","    best_auc = 0\n","    best_cf = None\n","    for i in np.arange(0.001, 0.599, 0.001):\n","        valid_argmax = (valid_preds_mean>i).astype(np.int32)\n","        val_metric = pfbeta_np(valid_labels_mean, valid_argmax)\n","        val_acc = accuracy_score(valid_labels_mean, valid_argmax)\n","        val_f1 = f1_score(valid_labels_mean, valid_argmax)\n","        val_auc = roc_auc_score(valid_labels_mean, valid_argmax)\n","        cf = confusion_matrix(valid_labels_mean, valid_argmax)\n","        if val_metric> best_metric:\n","            best_metric = val_metric\n","            # best_metric_mean_at_epoch = val_metric\n","            best_threshold_mean = i\n","            best_auc = val_auc\n","            best_cf = cf\n","    state = {'state_dict': model.state_dict()}\n","    path = f'swa_{CFG.model_name}_fold_{fold}_model_{best_metric:.4f}_{best_threshold_mean:.4f}.pth'\n","    torch.save(state, path)\n","    \n","    LOGGER.info(f\"Best metric at: {best_metric:.4f} {best_threshold_mean:.4f}  {best_auc:.4f}\")\n","    LOGGER.info(f\"Cf: {best_cf}\")\n","    return best_metric\n","\n","study = optuna.create_study(direction='maximize', sampler = TPESampler(seed=666))\n","study.optimize(func=objective, n_trials=40)\n","study.best_params\n","# # 0.5563409550491111 0.4436590449508889 fold 0\n","# # 0.12634002523631388 0.8351954705276587 0.03846450423602743 0.5393 \n","# # 0.583301614081906 0.3673525472043472 0.04934583871374687 fold 2 0.50\n","# # 0.1689507073116359 0.47142151346976024 0.3596277792186039 fold 2 0.5055 0.5055 0.3670  0.7261"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# train_loader = DataLoader(train_dataset, batch_size = CFG.train_bs,\n","#                                   num_workers=1, shuffle=True, pin_memory=True, drop_last=True)\n","# for step, (images, labels) in tqdm(enumerate(train_loader)):\n","#     image0 = images[0, :, :, :]\n","#     image0 = torch.permute(image0, (1, 2, 0))\n","#     image0 = image0.cpu().numpy().astype(np.uint8)\n","#     plt.imshow(image0)\n","#     plt.show()\n","#     break"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 10folds b2v2 x1 summary:\n","### epoch 13 fold 0/10 epoch 2 vs 13 (0.673170477524555 0.3268295224754445) 0.5979 cv\n","### epoch 3,4,5,6,7,8 fold 1/10 needs retrain? because stop at epoch 4\n","### 2/3/2023 epoch 3, 5, 6, 8, fold 1/10 better CV\n","### epoch 7 fold 2/10\n","### no epoch fold 3/10\n","### epoch 7,8 fold 4/10 needs retrain because starts after fold 3\n","### epoch 6 fold 4 better CV\n","### epoch 5,8,11,13 fold 5/10\n","### epoch 6,7,9 fold 6/10\n","### epoch 7 fold 7/10 \n","### epoch ~ fold 8/10\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 10folds b2ns x1 summary\n","### epoch 5,7 fold 0/10 0.6304, 4, 7 fold 0/10 6263 \n","### epoch 2,7 fold 1/10\n","### epoch 4,7 fold 2/10"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 5 fold summaries:\n","### all good"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["foldtest/tf_efficientnetv2_b2_fold_1_model_epoch_3_0.5055_0.360.pth\n","foldtest/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4865_0.324.pth\n","\n","swa_model_fold1_10.pth\n"]}],"source":["out_file = 'swa_model_fold1_10.pth' \n","iteration = [\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4385_0.205.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4393_0.278.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4432_0.319.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4231_0.320.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4578_0.382.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_10_0.4339_0.246.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_11_0.4211_0.242.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4568_0.290.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4762_0.152.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_4_0.4151_0.352.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_5_0.4757_0.230.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_6_0.4520_0.128.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.4510_0.266.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_8_0.4403_0.415.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_9_0.4713_0.430.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_10_0.4569_0.259.pth',\n","    # 'fold0/tf_efficientnetv2_b2_fold_0_model_epoch_11_0.4387_0.436.pth'\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4000_0.122.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4585_0.236.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4149_0.131.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_6_0.4516_0.188.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4557_0.241.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_8_0.4455_0.208.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_9_0.4681_0.319.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_10_0.4550_0.245.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_11_0.4500_0.373.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_12_0.4457_0.298.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_3_0.3867_0.302.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_4_0.3924_0.275.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_6_0.4030_0.339.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_5_0.3850_0.161.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_7_0.4192_0.270.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_8_0.3913_0.362.pth'\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_4_0.4103_0.343.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_5_0.4041_0.141.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_6_0.4648_0.444.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_7_0.4103_0.310.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_8_0.4471_0.371.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_10_0.4062_0.202.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_7_0.4192_0.270.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_11_0.4309_0.199.pth',\n","    # 'fold3/tf_efficientnetv2_b2_fold_3_model_epoch_12_0.4074_0.278.pth'\n","    # 'fold4/tf_efficientnetv2_b2_fold_4_model_epoch_5_0.3889_0.407.pth',\n","    # 'fold4/tf_efficientnetv2_b2_fold_4_model_epoch_4_0.4276_0.403.pth',\n","    # 'fold4/tf_efficientnetv2_b2_fold_4_model_epoch_6_0.4000_0.586.pth',\n","    # 'fold4/tf_efficientnetv2_b2_fold_4_model_epoch_7_0.3913_0.444.pth',\n","    # 'fold4/tf_efficientnetv2_b2_fold_4_model_epoch_8_0.3916_0.483.pth'\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_3_0.4444_0.273.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_4_0.4533_0.439.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4416_0.357.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4400_0.230.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4118_0.398.pth',\n","    # 'fold1/tf_efficientnetv2_b2_fold_1_model_epoch_7_0.4000_0.442.pth'\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_3_0.4615_0.250.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_4_0.4272_0.261.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_5_0.4598_0.286.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_6_0.4118_0.425.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_7_0.4848_0.266.pth',\n","    # 'fold2/tf_efficientnetv2_b2_fold_2_model_epoch_10_0.4314_0.241.pth',\n","    # 'fold4/tf_efficientnetv2_b2_fold_4_model_epoch_6_0.4675_0.377.pth',\n","    # 'fold4/tf_efficientnetv2_b2_fold_4_model_epoch_8_0.4722_0.472.pth',\n","    # 'fold4/tf_efficientnetv2_b2_fold_4_model_epoch_7_0.4810_0.474.pth',\n","    # 'fold6/tf_efficientnetv2_b2_fold_6_model_epoch_6_0.5128_0.307.pth',\n","    # 'fold6/tf_efficientnetv2_b2_fold_6_model_epoch_7_0.5385_0.423.pth',\n","    # 'fold6/tf_efficientnetv2_b2_fold_6_model_epoch_9_0.5135_0.338.pth'\n","    # 'fold14/tf_efficientnetv2_b2_fold_1_model_epoch_3_0.4524_0.331.pth',\n","    # 'fold14/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4510_0.228.pth',\n","    # 'fold14/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4337_0.284.pth',\n","    # 'fold14/tf_efficientnetv2_b2_fold_1_model_epoch_8_0.4211_0.231.pth'\n","    # 'fold14/tf_efficientnetv2_b2_fold_4_model_epoch_6_0.5349_0.350.pth',\n","    # 'fold14/tf_efficientnetv2_b2_fold_4_model_epoch_10_0.5349_0.352.pth'\n","    # 'fold14/tf_efficientnetv2_b2_fold_4_model_epoch_8_0.5316_0.367.pth',\n","    # 'fold14/tf_efficientnetv2_b2_fold_4_model_epoch_9_0.5195_0.395.pth',\n","    # 'fold14/tf_efficientnetv2_b2_fold_4_model_epoch_11_0.5287_0.326.pth',\n","    # 'fold14/tf_efficientnetv2_b2_fold_4_model_epoch_12_0.5055_0.308.pth',\n","    # 'fold14/tf_efficientnetv2_b2_fold_4_model_epoch_13_0.5176_0.328.pth'\n","    # 'fold8/tf_efficientnetv2_b2_fold_8_model_epoch_5_0.4675_0.175.pth',\n","    # 'fold8/tf_efficientnetv2_b2_fold_8_model_epoch_13_0.4742_0.337.pth',\n","    # 'fold8/tf_efficientnetv2_b2_fold_8_model_epoch_8_0.4658_0.412.pth'\n","    # 'foldtest/tf_efficientnet_b2_ns_fold_0_model_epoch_4_0.5778_0.326.pth',\n","    # 'foldtest/tf_efficientnet_b2_ns_fold_0_model_epoch_5_0.5783_0.535.pth',\n","    # 'foldtest/tf_efficientnet_b2_ns_fold_0_model_epoch_7_0.5895_0.270.pth',\n","    # 'foldtest/tf_efficientnet_b2_ns_fold_1_model_epoch_2_0.4706_0.370.pth',\n","    # 'foldtest/tf_efficientnet_b2_ns_fold_1_model_epoch_7_0.4557_0.426.pth',\n","    # 'foldtest/tf_efficientnet_b2_ns_fold_2_model_epoch_4_0.5234_0.334.pth',\n","    # 'foldtest/tf_efficientnet_b2_ns_fold_2_model_epoch_7_0.5000_0.234.pth',\n","    # 'foldonechannel/tf_efficientnetv2_b2_fold_0_model_epoch_4_0.5679_0.383.pth',\n","    # 'foldonechannel/tf_efficientnetv2_b2_fold_0_model_epoch_7_0.5636_0.153.pth',\n","    # 'foldonechannel/tf_efficientnetv2_b2_fold_0_model_epoch_8_0.5581_0.387.pth',\n","    # 'foldonechannel/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4837_0.455.pth',\n","    # 'foldonechannel/tf_efficientnetv2_b2_fold_1_model_epoch_6_0.4636_0.454.pth'\n","    'foldtest/tf_efficientnetv2_b2_fold_1_model_epoch_3_0.5055_0.360.pth',\n","    'foldtest/tf_efficientnetv2_b2_fold_1_model_epoch_5_0.4865_0.324.pth'\n","]\n","#46789101112 4824\n","state_dict = None\n","for i in iteration:\n","    f = i\n","    print(f)\n","    f = torch.load(f, map_location=lambda storage, loc: storage)\n","    if state_dict is None:\n","        state_dict = f['state_dict']\n","    else:\n","        key = list(f['state_dict'].keys())\n","        for k in key:\n","            state_dict[k] = state_dict[k] + f['state_dict'][k]\n","\n","for k in key:\n","    state_dict[k] = state_dict[k] / len(iteration)\n","print('')\n","\n","print(out_file)\n","torch.save({'state_dict': state_dict}, out_file)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# for fold in [0, 1, 2, 3, 4]:\n","#     LOGGER.info(f\"Fold: {fold}\")\n","#     model = Model(model_name=CFG.model_name).to(device)\n","#     # model = ModelVIT().to(CFG.device)\n","#     train_df = df1[df1['fold']!=fold].reset_index(drop=True)\n","#     valid_df = df[df['fold']==fold].reset_index(drop=True)\n","#     # print(len(valid_df))\n","#     LOGGER.info(f\"Len train df: {len(train_df)}\")\n","#     LOGGER.info(f\"Len valid df: {len(valid_df)}\")"]}],"metadata":{"kernelspec":{"display_name":"zaloenv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"d81213625f550c7b434bbb4e964cd1250716e6d81b88f327aa7e418dc0078b84"}}},"nbformat":4,"nbformat_minor":4}
