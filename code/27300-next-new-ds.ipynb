{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -qU python-gdcm pydicom pylibjpeg","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport glob\nimport gdcm\nimport pydicom\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom tqdm.notebook import tqdm\nfrom joblib import Parallel, delayed","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = glob.glob(\"/kaggle/input/rsna-breast-cancer-detection/train_images/*/*.dcm\")\n\nlen(train_images)  # 54706","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crop_image(img, show=True):\n    # Binarize the image\n    bin_pixels = cv2.threshold(img, 20, 255, cv2.THRESH_BINARY)[1]\n   \n    # Make contours around the binarized image, keep only the largest contour\n    contours, _ = cv2.findContours(bin_pixels, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n    contour = max(contours, key=cv2.contourArea)\n\n    # Create a mask from the largest contour\n    mask = np.zeros(img.shape, np.uint8)\n    cv2.drawContours(mask, [contour], -1, 255, cv2.FILLED)\n   \n    # Use bitwise_and to get masked part of the original image\n    out = cv2.bitwise_and(img, mask)\n    \n    # get bounding box of contour\n    y1, y2 = np.min(contour[:, :, 1]), np.max(contour[:, :, 1])\n    x1, x2 = np.min(contour[:, :, 0]), np.max(contour[:, :, 0])\n    \n    x1 = int(0.99 * x1)\n    x2 = int(1.01 * x2)\n    y1 = int(0.99 * y1)\n    y2 = int(1.01 * y2)\n    \n    if show:\n        plt.imshow(out[y1:y2, x1:x2], cmap=\"gray\") ; \n\n    return out[y1:y2, x1:x2]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATASET_NAME = f'RSNA-cropped-png-1344x960-test'\nSAVE_FOLDER = f\"/kaggle/working/{DATASET_NAME}\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs(SAVE_FOLDER, exist_ok=True)\nos.makedirs(SAVE_FOLDER + '/images/', exist_ok=True)\n\nwith open('/kaggle/input/myjson/kaggle.json') as f:\n    kaggle_creds = json.load(f)\n    \nos.environ['KAGGLE_USERNAME'] = kaggle_creds['username']\nos.environ['KAGGLE_KEY'] = kaggle_creds['key']\n\n!kaggle datasets init -p '{SAVE_FOLDER}'\n\nwith open(f'{SAVE_FOLDER}/dataset-metadata.json') as f:\n    dataset_meta = json.load(f)\n    \ndataset_meta['id'] = f'fabiendaniel/{DATASET_NAME}'\ndataset_meta['title'] = DATASET_NAME\n\nwith open(f'{SAVE_FOLDER}/dataset-metadata.json', \"w\") as outfile:\n    json.dump(dataset_meta, outfile)\nprint(dataset_meta)\n\n!cp '{SAVE_FOLDER}'/dataset-metadata.json '{SAVE_FOLDER}'/meta.json\n!ls '{SAVE_FOLDER}'\n\n!kaggle datasets create -u -p '{SAVE_FOLDER}'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TARGET_HEIGHT = 1344\nTARGET_WIDTH = 960\nN_CHANNELS = 1\nINPUT_SHAPE = (TARGET_HEIGHT, TARGET_WIDTH, N_CHANNELS)\nTARGET_HEIGHT_WIDTH_RATIO = TARGET_HEIGHT / TARGET_WIDTH\ndef process(f, save_folder=\"\", extension=\"png\"):\n    a = 0\n    patient = f.split('/')[-2]\n    image = f.split('/')[-1][:-4]\n#     img_dicom_sdl = dicoml.open(f)\n#     img = img_dicom_sdl.pixelData()\n    dicom = pydicom.dcmread(f)\n    img = dicom.pixel_array\n    \n    img = (img - img.min()) / (img.max() - img.min())\n    img = img*255\n    img = np.uint8(img) \n    if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        img = 1 - img\n    h0, w0 = img.shape\n    if img[:,int(-w0 * 0.10):].sum() > img[:,:int(w0 * 0.10)].sum():\n        img = np.flip(img, axis=1)\n    h0, w0 = img.shape\n    img = img[int(h0 * 2e-2):-int(h0 * 2e-2),int(w0 * 2e-2):-int(w0 * 2e-2)]\n    img = crop_image(img)\n    h, w = img.shape\n    if (h / w) > TARGET_HEIGHT_WIDTH_RATIO:\n        print(\"Larger than 1.4\")\n        pad = int(h / TARGET_HEIGHT_WIDTH_RATIO - w)\n        img = np.pad(img, [[0,0], [0, pad]])\n        h, w = img.shape\n    else:\n        print(\"not larger than 1.4\")\n        pad = int(0.50 * (w * TARGET_HEIGHT_WIDTH_RATIO - h))\n        img = np.pad(img, [[pad, pad], [0,0]])\n        h, w = img.shape\n    # Resize\n    img = cv2.resize(img, (TARGET_WIDTH, TARGET_HEIGHT), interpolation=cv2.INTER_AREA)\n    print(img.shape)\n    \n    img = (img - img.min()) / (img.max() - img.min())\n    cv2.imwrite(save_folder + f\"/images/{patient}_{image}.{extension}\", (img * 255).astype(np.uint8))\n    print(len(os.listdir(\"/kaggle/working/output\")))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_ = Parallel(n_jobs=4)(\n    delayed(process)(uid, save_folder=SAVE_FOLDER, extension=EXTENSION)\n    for uid in tqdm(train_images[:10])\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\nversion_name = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nprint(version_name)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_images = glob.glob(f\"{SAVE_FOLDER}/images/*.png\")\n\nlen(output_images)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!kaggle datasets version -m {version_name} -p \"{SAVE_FOLDER}\"  -r tar -r zip","metadata":{},"execution_count":null,"outputs":[]}]}